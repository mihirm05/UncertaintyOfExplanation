{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_ResNet20_06_08_21.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSD59fzx2NwB",
        "outputId": "7e67331e-757b-4bfb-b15f-2a06e8afd580"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmXI6jeS1-t9"
      },
      "source": [
        "import tensorflow as tf \n",
        "import os \n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation, Dropout\n",
        "from tensorflow.keras.layers import Input, Flatten, AveragePooling2D, Add\n",
        "from tensorflow.keras import backend as K \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10 \n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zROr-05a2Gkd"
      },
      "source": [
        "batch_size=32 \n",
        "epochs=100 \n",
        "num_classes=10 \n",
        "depth=20 "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALLQbtz2cA4b"
      },
      "source": [
        "model_type = 'ResNet%d' % (depth)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft7a2_0T7dk0",
        "outputId": "146dd009-584d-4389-b08c-d769a95baf15"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
        "x_train = x_train/255 \n",
        "x_test = x_test/255 \n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes) \n",
        "input_shape=x_train.shape[1:]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geI2YTs_8Sfz"
      },
      "source": [
        "def resnet_layer(inputs, num_filters=16, kernel_size=3, strides=1, activation='relu', batch_normalization=True, conv_first=True):\n",
        "    conv = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')\n",
        "    x = inputs \n",
        "    if conv_first:\n",
        "        x = conv(x) \n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x) \n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "\n",
        "    else: \n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x) \n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x) \n",
        "        x = conv(x) \n",
        "    return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTatFBthCAG9"
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    if (depth - 2)%6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20,32, 44 in [a])')\n",
        "\n",
        "    # model definition \n",
        "    num_filters = 16 \n",
        "    num_res_blocks = int((depth-2)/6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs) \n",
        "\n",
        "    ## instantiate the stack of residual units \n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1 \n",
        "            if stack > 0 and res_block ==0: # first layer but not first stack \n",
        "                strides = 2 # downsample\n",
        "            y = resnet_layer(inputs=x, num_filters=num_filters, strides=strides)\n",
        "            y = resnet_layer(inputs=y, num_filters=num_filters, activation=None)\n",
        "            if stack > 0 and res_block == 0: # first layer but not first stack \n",
        "                # linear projection residual shortcut connection to match changed dimes \n",
        "                x = resnet_layer(inputs=x, num_filters=num_filters, kernel_size=1, strides=strides, activation=None, batch_normalization=False)\n",
        "            x = tf.keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x) \n",
        "            x = Dropout(rate=0.25)(x) \n",
        "        num_filters *= 2 \n",
        "\n",
        "    # Add classifier on top \n",
        "    # v1 does not use BN after last shortcut connection to match changed dims \n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x) \n",
        "\n",
        "    outputs = Dense(num_classes, activation='softmax')(y)\n",
        "\n",
        "    # Instantiate model \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model          "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhA6KOZ-V-Zl"
      },
      "source": [
        "model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I3Q5TJ-WFee"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Q1NrNaWapd",
        "outputId": "571531ff-db23-400f-bd90-3c0108853d51"
      },
      "source": [
        "model.summary() \n",
        "print(model_type)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 16)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           dropout[0][0]                    \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 16)   0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           dropout_1[0][0]                  \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 16)   0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 32)   4640        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 32)   544         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 32)   0           conv2d_9[0][0]                   \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 32)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 16, 16, 32)   0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 32)   9248        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 32)   0           dropout_3[0][0]                  \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 16, 16, 32)   0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           dropout_4[0][0]                  \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 16, 16, 32)   0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 64)     18496       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 64)     36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 64)     2112        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 64)     0           conv2d_16[0][0]                  \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 64)     0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 8, 8, 64)     0           activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 64)     36928       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 64)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 64)     0           dropout_6[0][0]                  \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 8, 8, 64)     0           activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 64)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 64)     0           dropout_7[0][0]                  \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 8, 8, 64)     0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yEUNWxvWgrl"
      },
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models') \n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5'%model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ_VTtsJXTWg"
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_accuracy', verbose=2, save_best_only=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FB9ARxQXca9"
      },
      "source": [
        "callbacks = [checkpoint] "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vC3MVxoYXjh",
        "outputId": "1e1b6ea1-7eec-415f-d3c6-872b969be4f3"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, shuffle=True, callbacks=callbacks)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1250/1250 [==============================] - 50s 14ms/step - loss: 1.6573 - accuracy: 0.3819 - val_loss: 2.1462 - val_accuracy: 0.3184\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.31840, saving model to /content/saved_models/cifar10_ResNet20_model.001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 1.3075 - accuracy: 0.5251 - val_loss: 1.4892 - val_accuracy: 0.4717\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.31840 to 0.47170, saving model to /content/saved_models/cifar10_ResNet20_model.002.h5\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 1.1312 - accuracy: 0.5956 - val_loss: 1.0990 - val_accuracy: 0.6220\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.47170 to 0.62200, saving model to /content/saved_models/cifar10_ResNet20_model.003.h5\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 1.0399 - accuracy: 0.6304 - val_loss: 1.1341 - val_accuracy: 0.6085\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.62200\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.9762 - accuracy: 0.6557 - val_loss: 0.9715 - val_accuracy: 0.6515\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.62200 to 0.65150, saving model to /content/saved_models/cifar10_ResNet20_model.005.h5\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.9287 - accuracy: 0.6693 - val_loss: 1.0926 - val_accuracy: 0.6507\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.65150\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.8837 - accuracy: 0.6878 - val_loss: 0.8415 - val_accuracy: 0.7036\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.65150 to 0.70360, saving model to /content/saved_models/cifar10_ResNet20_model.007.h5\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.8420 - accuracy: 0.7053 - val_loss: 0.9077 - val_accuracy: 0.6806\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.70360\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 16s 12ms/step - loss: 0.8107 - accuracy: 0.7145 - val_loss: 0.8423 - val_accuracy: 0.7115\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.70360 to 0.71150, saving model to /content/saved_models/cifar10_ResNet20_model.009.h5\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7764 - accuracy: 0.7276 - val_loss: 0.9980 - val_accuracy: 0.6550\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.71150\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7496 - accuracy: 0.7376 - val_loss: 0.8505 - val_accuracy: 0.7088\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.71150\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.7249 - accuracy: 0.7444 - val_loss: 0.6757 - val_accuracy: 0.7727\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.71150 to 0.77270, saving model to /content/saved_models/cifar10_ResNet20_model.012.h5\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 16s 12ms/step - loss: 0.6888 - accuracy: 0.7595 - val_loss: 0.7236 - val_accuracy: 0.7480\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.77270\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6680 - accuracy: 0.7652 - val_loss: 0.7085 - val_accuracy: 0.7618\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.77270\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.6504 - accuracy: 0.7727 - val_loss: 0.5921 - val_accuracy: 0.7939\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.77270 to 0.79390, saving model to /content/saved_models/cifar10_ResNet20_model.015.h5\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.6371 - accuracy: 0.7783 - val_loss: 0.6095 - val_accuracy: 0.7883\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.79390\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 16s 12ms/step - loss: 0.6232 - accuracy: 0.7804 - val_loss: 0.6149 - val_accuracy: 0.7839\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.79390\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 15s 12ms/step - loss: 0.6051 - accuracy: 0.7908 - val_loss: 0.5818 - val_accuracy: 0.7990\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.79390 to 0.79900, saving model to /content/saved_models/cifar10_ResNet20_model.018.h5\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.5957 - accuracy: 0.7935 - val_loss: 0.6313 - val_accuracy: 0.7865\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.79900\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.5814 - accuracy: 0.7974 - val_loss: 0.5994 - val_accuracy: 0.7958\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.79900\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 16s 12ms/step - loss: 0.5707 - accuracy: 0.8008 - val_loss: 0.5736 - val_accuracy: 0.8010\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.79900 to 0.80100, saving model to /content/saved_models/cifar10_ResNet20_model.021.h5\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 16s 12ms/step - loss: 0.5606 - accuracy: 0.8051 - val_loss: 0.5470 - val_accuracy: 0.8146\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.80100 to 0.81460, saving model to /content/saved_models/cifar10_ResNet20_model.022.h5\n",
            "Epoch 23/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.5528 - accuracy: 0.8074 - val_loss: 0.6034 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.81460\n",
            "Epoch 24/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.5371 - accuracy: 0.8111 - val_loss: 0.5904 - val_accuracy: 0.7977\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.81460\n",
            "Epoch 25/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.5278 - accuracy: 0.8144 - val_loss: 0.5758 - val_accuracy: 0.8070\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.81460\n",
            "Epoch 26/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.5222 - accuracy: 0.8166 - val_loss: 0.6340 - val_accuracy: 0.7904\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.81460\n",
            "Epoch 27/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.5150 - accuracy: 0.8202 - val_loss: 0.6495 - val_accuracy: 0.7840\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.81460\n",
            "Epoch 28/100\n",
            "1250/1250 [==============================] - 16s 12ms/step - loss: 0.5056 - accuracy: 0.8230 - val_loss: 0.5897 - val_accuracy: 0.7998\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.81460\n",
            "Epoch 29/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4966 - accuracy: 0.8261 - val_loss: 0.5492 - val_accuracy: 0.8126\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.81460\n",
            "Epoch 30/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4915 - accuracy: 0.8285 - val_loss: 0.5478 - val_accuracy: 0.8149\n",
            "\n",
            "Epoch 00030: val_accuracy improved from 0.81460 to 0.81490, saving model to /content/saved_models/cifar10_ResNet20_model.030.h5\n",
            "Epoch 31/100\n",
            "1250/1250 [==============================] - 16s 12ms/step - loss: 0.4820 - accuracy: 0.8310 - val_loss: 0.5365 - val_accuracy: 0.8200\n",
            "\n",
            "Epoch 00031: val_accuracy improved from 0.81490 to 0.82000, saving model to /content/saved_models/cifar10_ResNet20_model.031.h5\n",
            "Epoch 32/100\n",
            "1250/1250 [==============================] - 16s 12ms/step - loss: 0.4761 - accuracy: 0.8330 - val_loss: 0.5126 - val_accuracy: 0.8229\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.82000 to 0.82290, saving model to /content/saved_models/cifar10_ResNet20_model.032.h5\n",
            "Epoch 33/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4700 - accuracy: 0.8360 - val_loss: 0.5553 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.82290\n",
            "Epoch 34/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4649 - accuracy: 0.8383 - val_loss: 0.5804 - val_accuracy: 0.8117\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.82290\n",
            "Epoch 35/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4645 - accuracy: 0.8364 - val_loss: 0.6031 - val_accuracy: 0.7997\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.82290\n",
            "Epoch 36/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4546 - accuracy: 0.8399 - val_loss: 0.5182 - val_accuracy: 0.8251\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.82290 to 0.82510, saving model to /content/saved_models/cifar10_ResNet20_model.036.h5\n",
            "Epoch 37/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4510 - accuracy: 0.8414 - val_loss: 0.5092 - val_accuracy: 0.8260\n",
            "\n",
            "Epoch 00037: val_accuracy improved from 0.82510 to 0.82600, saving model to /content/saved_models/cifar10_ResNet20_model.037.h5\n",
            "Epoch 38/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.4419 - accuracy: 0.8450 - val_loss: 0.5321 - val_accuracy: 0.8242\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.82600\n",
            "Epoch 39/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4388 - accuracy: 0.8477 - val_loss: 0.5392 - val_accuracy: 0.8196\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.82600\n",
            "Epoch 40/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4377 - accuracy: 0.8472 - val_loss: 0.5966 - val_accuracy: 0.8106\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.82600\n",
            "Epoch 41/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4266 - accuracy: 0.8511 - val_loss: 0.5336 - val_accuracy: 0.8236\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.82600\n",
            "Epoch 42/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.4239 - accuracy: 0.8513 - val_loss: 0.5412 - val_accuracy: 0.8194\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.82600\n",
            "Epoch 43/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4200 - accuracy: 0.8515 - val_loss: 0.5312 - val_accuracy: 0.8264\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.82600 to 0.82640, saving model to /content/saved_models/cifar10_ResNet20_model.043.h5\n",
            "Epoch 44/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.4150 - accuracy: 0.8542 - val_loss: 0.5190 - val_accuracy: 0.8333\n",
            "\n",
            "Epoch 00044: val_accuracy improved from 0.82640 to 0.83330, saving model to /content/saved_models/cifar10_ResNet20_model.044.h5\n",
            "Epoch 45/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4138 - accuracy: 0.8558 - val_loss: 0.4819 - val_accuracy: 0.8391\n",
            "\n",
            "Epoch 00045: val_accuracy improved from 0.83330 to 0.83910, saving model to /content/saved_models/cifar10_ResNet20_model.045.h5\n",
            "Epoch 46/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4072 - accuracy: 0.8558 - val_loss: 0.4791 - val_accuracy: 0.8423\n",
            "\n",
            "Epoch 00046: val_accuracy improved from 0.83910 to 0.84230, saving model to /content/saved_models/cifar10_ResNet20_model.046.h5\n",
            "Epoch 47/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.4064 - accuracy: 0.8585 - val_loss: 0.5398 - val_accuracy: 0.8209\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.84230\n",
            "Epoch 48/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3985 - accuracy: 0.8593 - val_loss: 0.4866 - val_accuracy: 0.8371\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.84230\n",
            "Epoch 49/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3956 - accuracy: 0.8612 - val_loss: 0.5461 - val_accuracy: 0.8187\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.84230\n",
            "Epoch 50/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3951 - accuracy: 0.8597 - val_loss: 0.5799 - val_accuracy: 0.8123\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.84230\n",
            "Epoch 51/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3879 - accuracy: 0.8636 - val_loss: 0.5235 - val_accuracy: 0.8285\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.84230\n",
            "Epoch 52/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3836 - accuracy: 0.8662 - val_loss: 0.5026 - val_accuracy: 0.8328\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.84230\n",
            "Epoch 53/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3847 - accuracy: 0.8648 - val_loss: 0.4684 - val_accuracy: 0.8435\n",
            "\n",
            "Epoch 00053: val_accuracy improved from 0.84230 to 0.84350, saving model to /content/saved_models/cifar10_ResNet20_model.053.h5\n",
            "Epoch 54/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3837 - accuracy: 0.8655 - val_loss: 0.4879 - val_accuracy: 0.8372\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.84350\n",
            "Epoch 55/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3798 - accuracy: 0.8656 - val_loss: 0.4905 - val_accuracy: 0.8409\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.84350\n",
            "Epoch 56/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3779 - accuracy: 0.8662 - val_loss: 0.4907 - val_accuracy: 0.8376\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.84350\n",
            "Epoch 57/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3712 - accuracy: 0.8678 - val_loss: 0.4742 - val_accuracy: 0.8467\n",
            "\n",
            "Epoch 00057: val_accuracy improved from 0.84350 to 0.84670, saving model to /content/saved_models/cifar10_ResNet20_model.057.h5\n",
            "Epoch 58/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3666 - accuracy: 0.8720 - val_loss: 0.5117 - val_accuracy: 0.8344\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.84670\n",
            "Epoch 59/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3693 - accuracy: 0.8690 - val_loss: 0.5534 - val_accuracy: 0.8214\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.84670\n",
            "Epoch 60/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3656 - accuracy: 0.8686 - val_loss: 0.5051 - val_accuracy: 0.8370\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.84670\n",
            "Epoch 61/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3559 - accuracy: 0.8726 - val_loss: 0.5318 - val_accuracy: 0.8313\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.84670\n",
            "Epoch 62/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3565 - accuracy: 0.8750 - val_loss: 0.4838 - val_accuracy: 0.8435\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.84670\n",
            "Epoch 63/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3554 - accuracy: 0.8736 - val_loss: 0.4767 - val_accuracy: 0.8421\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.84670\n",
            "Epoch 64/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3493 - accuracy: 0.8759 - val_loss: 0.4942 - val_accuracy: 0.8412\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.84670\n",
            "Epoch 65/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3483 - accuracy: 0.8769 - val_loss: 0.5676 - val_accuracy: 0.8265\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.84670\n",
            "Epoch 66/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3454 - accuracy: 0.8799 - val_loss: 0.5472 - val_accuracy: 0.8253\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.84670\n",
            "Epoch 67/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3464 - accuracy: 0.8776 - val_loss: 0.5561 - val_accuracy: 0.8206\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.84670\n",
            "Epoch 68/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3438 - accuracy: 0.8792 - val_loss: 0.5104 - val_accuracy: 0.8359\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.84670\n",
            "Epoch 69/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3381 - accuracy: 0.8795 - val_loss: 0.4854 - val_accuracy: 0.8428\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.84670\n",
            "Epoch 70/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3342 - accuracy: 0.8806 - val_loss: 0.5278 - val_accuracy: 0.8323\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.84670\n",
            "Epoch 71/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3326 - accuracy: 0.8816 - val_loss: 0.4840 - val_accuracy: 0.8446\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.84670\n",
            "Epoch 72/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3336 - accuracy: 0.8809 - val_loss: 0.4975 - val_accuracy: 0.8413\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.84670\n",
            "Epoch 73/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3313 - accuracy: 0.8829 - val_loss: 0.4720 - val_accuracy: 0.8503\n",
            "\n",
            "Epoch 00073: val_accuracy improved from 0.84670 to 0.85030, saving model to /content/saved_models/cifar10_ResNet20_model.073.h5\n",
            "Epoch 74/100\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 0.3263 - accuracy: 0.8845 - val_loss: 0.5458 - val_accuracy: 0.8305\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.85030\n",
            "Epoch 75/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3294 - accuracy: 0.8840 - val_loss: 0.5362 - val_accuracy: 0.8311\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.85030\n",
            "Epoch 76/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3201 - accuracy: 0.8870 - val_loss: 0.4873 - val_accuracy: 0.8461\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.85030\n",
            "Epoch 77/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3219 - accuracy: 0.8857 - val_loss: 0.4828 - val_accuracy: 0.8435\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.85030\n",
            "Epoch 78/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3227 - accuracy: 0.8868 - val_loss: 0.5239 - val_accuracy: 0.8361\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.85030\n",
            "Epoch 79/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3203 - accuracy: 0.8856 - val_loss: 0.5109 - val_accuracy: 0.8382\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.85030\n",
            "Epoch 80/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3137 - accuracy: 0.8898 - val_loss: 0.4943 - val_accuracy: 0.8433\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.85030\n",
            "Epoch 81/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3110 - accuracy: 0.8902 - val_loss: 0.5034 - val_accuracy: 0.8402\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.85030\n",
            "Epoch 82/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3152 - accuracy: 0.8885 - val_loss: 0.4975 - val_accuracy: 0.8403\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.85030\n",
            "Epoch 83/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3078 - accuracy: 0.8903 - val_loss: 0.5271 - val_accuracy: 0.8315\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.85030\n",
            "Epoch 84/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3095 - accuracy: 0.8907 - val_loss: 0.5165 - val_accuracy: 0.8405\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.85030\n",
            "Epoch 85/100\n",
            "1250/1250 [==============================] - 17s 14ms/step - loss: 0.3068 - accuracy: 0.8915 - val_loss: 0.4896 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.85030\n",
            "Epoch 86/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3102 - accuracy: 0.8910 - val_loss: 0.5389 - val_accuracy: 0.8336\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.85030\n",
            "Epoch 87/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3037 - accuracy: 0.8919 - val_loss: 0.4630 - val_accuracy: 0.8501\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.85030\n",
            "Epoch 88/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2999 - accuracy: 0.8921 - val_loss: 0.4925 - val_accuracy: 0.8468\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.85030\n",
            "Epoch 89/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.3069 - accuracy: 0.8903 - val_loss: 0.5127 - val_accuracy: 0.8405\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.85030\n",
            "Epoch 90/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2945 - accuracy: 0.8966 - val_loss: 0.4799 - val_accuracy: 0.8459\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.85030\n",
            "Epoch 91/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2998 - accuracy: 0.8934 - val_loss: 0.5201 - val_accuracy: 0.8334\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.85030\n",
            "Epoch 92/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.3004 - accuracy: 0.8927 - val_loss: 0.5575 - val_accuracy: 0.8266\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.85030\n",
            "Epoch 93/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.2943 - accuracy: 0.8944 - val_loss: 0.5104 - val_accuracy: 0.8332\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.85030\n",
            "Epoch 94/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2974 - accuracy: 0.8952 - val_loss: 0.4951 - val_accuracy: 0.8441\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.85030\n",
            "Epoch 95/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2936 - accuracy: 0.8959 - val_loss: 0.5057 - val_accuracy: 0.8406\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.85030\n",
            "Epoch 96/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2965 - accuracy: 0.8948 - val_loss: 0.5035 - val_accuracy: 0.8392\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.85030\n",
            "Epoch 97/100\n",
            "1250/1250 [==============================] - 17s 13ms/step - loss: 0.2874 - accuracy: 0.8985 - val_loss: 0.4876 - val_accuracy: 0.8493\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.85030\n",
            "Epoch 98/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2863 - accuracy: 0.8985 - val_loss: 0.5056 - val_accuracy: 0.8435\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.85030\n",
            "Epoch 99/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2858 - accuracy: 0.8967 - val_loss: 0.5636 - val_accuracy: 0.8281\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.85030\n",
            "Epoch 100/100\n",
            "1250/1250 [==============================] - 16s 13ms/step - loss: 0.2842 - accuracy: 0.8986 - val_loss: 0.5000 - val_accuracy: 0.8448\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.85030\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "cc0aq8wk5m6F",
        "outputId": "24d60cc7-a72b-47fd-9bbe-fe527816e42c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss performance')\n",
        "plt.legend(['train loss', 'validation loss'])\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xV5f3A8c83yU1CJlnMsARkb0QUERQHah1UrQNnq6jVWqvV+utSW21ta9W66h61ilrcinWCOFAZZW8QSMJIyN7rfn9/PCdwgSySQMLN9/163VfuPfM598D3Puf7POc5oqoYY4wJXiGtXQBjjDEHlwV6Y4wJchbojTEmyFmgN8aYIGeB3hhjgpwFemOMCXIW6M0hIyLPi8jdjVx2s4ic1NzttEUicreI7BKRHa1dFtM+hLV2AYxpT0SkJ3AL0EtVM1u7PKZ9sBq9MYeIiIQBPYHspgR5b31jDpgFerMXL2Vyq4gsE5FiEXlGRDqLyAciUigin4hIQsDyZ4nIShHJE5G5IjIoYN4oEVnsrfcqELnPvn4gIku8db8WkeFNLPPVIrJBRHJE5B0R6eZNFxF5QEQyRaRARJaLyFBv3ukissorW4aI/LKObV8hIl+JyCMiki8ia0RkSsD8eO872u5t524RCd1n3QdEJBuYC3wMdBORIhF5vhHf4WYR+ZWILAOKRaSfiKiIXCkiaSKSKyLXishR3jnLE5FHAtbvKyKfiUi2ly56SUQ67rP9X3rr5ovIqyISGTD/bO8cFYjIRhGZ2tBxmzZIVe1lr90vYDPwDdAZ6A5kAouBUbhA/Rlwh7fskUAxcDLgA24DNgDh3msL8Atv3nlAJXC3t+4ob9tHA6HA5d6+IwLKcVIdZXw+YDsnAruA0UAE8DAwz5t3KrAI6AgIMAjo6s3bDkz03icAo+vY1xVAVcBxXADkA4ne/DeBJ4BooBPwHXDNPuv+DJcm7QBMBtIDtl/ndxjwPSwBenjr9wYUeNw7H6cAZcBb3v5rztkkb/1+3rYjgBRgHvDgPuf7O6AbkAisBq715o3zjvVkXKWwOzCwoeO2V9t7tXoB7NW2Xt5//OkBn18H/hnw+WfAW9773wGvBcwLATK8YHY8sA2QgPlfBwTofwJ/3GffawMC1GYaF+ifAf4aMC8G94PSG/cjsA4YD4Tss42twDVAXAPfxxW1HMd3wKW4H8NyoEPAvIuAOQHrbt1ne5PZO9DX+R0GfA8/DpjfGxfouwdMywYu2Oec3VTH8ZwD/G+f831JwOe/Ao97758AHqhlG/Uet73a3stSN6Y2OwPel9byOcZ73w1XawdAVf1AGq7m1w3IUC8KeLYEvO8F3OKlGvJEJA9Xa+12gGXdtwxFuMDXXVU/Ax4BHgUyReRJEYnzFj0XOB3YIiKfi8gx9eyjtuPo5h2DD9gecAxP4Gq4NdIOsPyB32F922jUOfLSbq946ZUC4N9A8j7bCuz9U8Ke89sD2FjLvhtz3KYNsUBvmmMb7j894HLiuOCQgUuNdPem1egZ8D4NuEdVOwa8olR1ZjPLEA0keWVAVR9S1THAYFya5FZv+gJVPRsXnN4CXqtnH7UdxzbvGMqB5IBjiFPVIQHLNjQ8bH3fYWO3UZ8/eesPU9U44BJcGqsx0oC+dUxv6LhNG2KB3jTHa8AZIjJFRHy4boPluBTNfFx++kYR8YnID3E53xpPAdeKyNFeo2m0iJwhIrEHWIaZwJUiMlJEInCB7VtV3ew1UB7tla0Yl8v2i0i4iEwXkXhVrQQKAH89++gUcBzn43L9s1V1O/AR8HcRiROREK/xc9IBlL++77AlxAJFQL6IdMf7oWukZ3Df7RTv2LqLyMAWOm5zCFmgN02mqmtxNcSHcQ2iZwJnqmqFqlYAP8TlqXNwjZhvBKy7ELgal1rJxTVAXtGEMnyCy3O/jruK6Atc6M2Ow/2g5OLSI9nA37x5lwKbvXTGtcD0enbzLdDfO8Z7gPNUNdubdxmu4XmVt59ZQNcDKH+d32Fjt9GAu3AN1fnA+wScg0aU7TvgSuABb/3P2XP10azjNoeW7J16NMYEEpErgKtU9bjWLosxTWU1emOMCXIW6I0xJshZ6sYYY4Kc1eiNMSbItclBkpKTk7V3796tXQxjjDlsLFq0aJeqptQ2r00G+t69e7Nw4cLWLoYxxhw2RGRLXfMsdWOMMUHOAr0xxgQ5C/TGGBPk2mSO3hhz6FVWVpKenk5ZWVlrF8XUIzIyktTUVHw+X6PXsUBvjAEgPT2d2NhYevfuzd6DdZq2QlXJzs4mPT2dPn36NHo9S90YYwAoKysjKSnJgnwbJiIkJSUd8FWXBXpjzG4W5Nu+ppyj4Ar0n/8VNnzS2qUwxpg2JbgC/Vf/gA2ftXYpjDEHKC8vj8cee6xJ655++unk5eU1evk777yT++67r0n7OlwFV6D3RUFlcWuXwhhzgOoL9FVVVfWuO3v2bDp27HgwihU0givQh0dDRUlrl8IYc4Buv/12Nm7cyMiRI7n11luZO3cuEydO5KyzzmLw4MEAnHPOOYwZM4YhQ4bw5JNP7l63d+/e7Nq1i82bNzNo0CCuvvpqhgwZwimnnEJpaWm9+12yZAnjx49n+PDhTJs2jdzcXAAeeughBg8ezPDhw7nwQvfAss8//5yRI0cycuRIRo0aRWFh4UH6NlpecHWvDI+GSgv0xjTXXe+uZNW2ghbd5uBucdxxZu3PD7/33ntZsWIFS5YsAWDu3LksXryYFStW7O5G+Oyzz5KYmEhpaSlHHXUU5557LklJSXttZ/369cycOZOnnnqKH/3oR7z++utccskldZbpsssu4+GHH2bSpEn8/ve/56677uLBBx/k3nvv5fvvvyciImJ3Wui+++7j0UcfZcKECRQVFREZGdkSX8shEVw1el8UVBS1dimMMS1g3Lhxe/UVf+ihhxgxYgTjx48nLS2N9evX77dOnz59GDlyJABjxoxh8+bNdW4/Pz+fvLw8Jk1yzzS//PLLmTdvHgDDhw9n+vTp/Pvf/yYszNWHJ0yYwM0338xDDz1EXl7e7umHg8OnpI0RHmWpG2NaQF0170MpOjp69/u5c+fyySefMH/+fKKiopg8eXKtfckjIiJ2vw8NDW0wdVOX999/n3nz5vHuu+9yzz33sHz5cm6//XbOOOMMZs+ezYQJE/jwww8ZOHBgk7Z/qAVXjT48xlI3xhyGYmNj68155+fnk5CQQFRUFGvWrOGbb75p9j7j4+NJSEjgiy++AODFF19k0qRJ+P1+0tLSOOGEE/jLX/5Cfn4+RUVFbNy4kWHDhvGrX/2Ko446ijVr1jS7DIdKcNXoLXVjzGEpKSmJCRMmMHToUE477TTOOOOMveZPnTqVxx9/nEGDBjFgwADGjx/fIvt94YUXuPbaaykpKeGII47gueeeo7q6mksuuYT8/HxUlRtvvJGOHTvyu9/9jjlz5hASEsKQIUM47bTTWqQMh0KbfGbs2LFjtUkPHnn357BmNty6f+7OGFO/1atXM2jQoNYuhmmE2s6ViCxS1bG1LW+pG2OMCXLBFeh9UVBRDG3wKsUYY1pLcAX68ChAobJpLe3GGBOMgivQ+7zuWJa+McaY3RoM9CLSQ0TmiMgqEVkpIj+vZRkRkYdEZIOILBOR0QHzLheR9d7r8pY+gL2Ee4G+wsa7McaYGo3pXlkF3KKqi0UkFlgkIh+r6qqAZU4D+nuvo4F/AkeLSCJwBzAWUG/dd1Q1t0WPokZ4lPtrgd4YY3ZrsEavqttVdbH3vhBYDXTfZ7GzgX+p8w3QUUS6AqcCH6tqjhfcPwamtugRBLLUjTHtRkxMDADbtm3jvPPOq3WZyZMn01BX7QcffJCSkj0x40CHPa5LWxoO+YBy9CLSGxgFfLvPrO5AWsDndG9aXdNr2/YMEVkoIguzsrIOpFh7WI3emHanW7duzJo1q8nr7xvog3HY40YHehGJAV4HblLVlh3WDlDVJ1V1rKqOTUlJadpGLEdvzGHp9ttv59FHH939uaY2XFRUxJQpUxg9ejTDhg3j7bff3m/dzZs3M3ToUABKS0u58MILGTRoENOmTdtrrJvrrruOsWPHMmTIEO644w7ADZS2bds2TjjhBE444QRgz7DHAPfffz9Dhw5l6NChPPjgg7v3d7gNh9yoIRBExIcL8i+p6hu1LJIB9Aj4nOpNywAm7zN9blMK2iiWujGmZXxwO+xY3rLb7DIMTru31lkXXHABN910E9dffz0Ar732Gh9++CGRkZG8+eabxMXFsWvXLsaPH89ZZ51V53NT//nPfxIVFcXq1atZtmwZo0fv7hfCPffcQ2JiItXV1UyZMoVly5Zx4403cv/99zNnzhySk5P32taiRYt47rnn+Pbbb1FVjj76aCZNmkRCQsJhNxxyY3rdCPAMsFpV769jsXeAy7zeN+OBfFXdDnwInCIiCSKSAJziTTs4LHVjzGFp1KhRZGZmsm3bNpYuXUpCQgI9evRAVfn1r3/N8OHDOemkk8jIyGDnzp11bmfevHm7A+7w4cMZPnz47nmvvfYao0ePZtSoUaxcuZJVq1bVtRkAvvzyS6ZNm0Z0dDQxMTH88Ic/3D0A2uE2HHJjtjABuBRYLiJLvGm/BnoCqOrjwGzgdGADUAJc6c3LEZE/Agu89f6gqjnNLnVdwq1Gb0yLqKPmfTCdf/75zJo1ix07dnDBBRcA8NJLL5GVlcWiRYvw+Xz07t271uGJG/L9999z3333sWDBAhISErjiiiuatJ0ah9twyI3pdfOlqoqqDlfVkd5rtqo+7gV5vN4216tqX1UdpqoLA9Z/VlX7ea/nmlXahtSkbmwES2MOOxdccAGvvPIKs2bN4vzzzwdcbbhTp074fD7mzJnDli1b6t3G8ccfz8svvwzAihUrWLZsGQAFBQVER0cTHx/Pzp07+eCDD3avU9cQyRMnTuStt96ipKSE4uJi3nzzTSZOnHjAx9UWhkMOrmGKw8IhJMwePmLMYWjIkCEUFhbSvXt3unbtCsD06dM588wzGTZsGGPHjm2wZnvddddx5ZVXMmjQIAYNGsSYMWMAGDFiBKNGjWLgwIH06NGDCRMm7F5nxowZTJ06lW7dujFnzpzd00ePHs0VV1zBuHHjALjqqqsYNWpUvWmaurT2cMjBNUwxwJ97wsiL4LS/tGyhjAlyNkzx4aN9D1MMLk9vqRtjjNktCAO9PTfWGGMCBV+g90VZrxtjmqgtpnLN3ppyjoIv0IfHWD96Y5ogMjKS7OxsC/ZtmKqSnZ19wDdRBVevG3Cpm5KD11XfmGCVmppKeno6TR5ryhwSkZGRpKamHtA6wRfofVFQmd7apTDmsOPz+ejTp09rF8McBEGYuom2xlhjjAkQpIHeulcaY0yN4Av01uvGGGP2EnyBPjwaqsrAX93aJTHGmDYh+AK9z4YqNsaYQMEX6G2oYmOM2UvwBnqr0RtjDBCMgb4mdWM1emOMAYIx0FuN3hhj9tLgnbEi8izwAyBTVYfWMv9WYHrA9gYBKd5jBDcDhUA1UFXXWMktygK9McbspTE1+ueBqXXNVNW/1TxiEPg/4PN9ngt7gjf/4Ad5sNSNMcbsozHPjJ0HNHaUsIuAmc0qUXNZjd4YY/bSYjl6EYnC1fxfD5iswEciskhEZjSw/gwRWSgiC5s1ep4FemOM2UtLNsaeCXy1T9rmOFUdDZwGXC8ix9e1sqo+qapjVXVsSkpK00thqRtjjNlLSwb6C9knbaOqGd7fTOBNYFwL7q92u2v0FuiNMQZaKNCLSDwwCXg7YFq0iMTWvAdOAVa0xP7qFRIKoRE2gqUxxnga071yJjAZSBaRdOAOwAegqo97i00DPlLVwMR4Z+BNEanZz8uq+t+WK3o9wqMtdWOMMZ4GA72qXtSIZZ7HdcMMnLYJGNHUgjWLPXzEGGN2C747Y8E1yFrqxhhjgGAN9Ja6McaY3YI30FvqxhhjgCAK9KrKb99azvvLtnuPE7QbpowxBhrRGHu4EBHeWbKNEBHOCI+yO2ONMcYTNDV6gKSYCLKLKyx1Y4wxAYIr0EeHk1NUAb5oS90YY4wnqAJ9YnQ4OcUVYKkbY4zZLagCfVJMuEvd+KLBXwVVFa1dJGOMaXVBFegTo8PJLanAv3sES6vVG2NMkAX6CKr9SimRboKlb4wxJrgCfVJ0OACFfvfXet4YY0ywBfoYF+ALqr1Ab6kbY4wJrkCf6NXo86p8boLV6I0xJrgCfVJ0BAA5ld4Nv5ajN8aY4Ar0CdGuJp9d4dXoLXVjjDHBM9YNQERYKLERYWSVe79flroxxpjgCvQAiTHh7CxT98FSN8YY03DqRkSeFZFMEan1wd4iMllE8kVkiff6fcC8qSKyVkQ2iMjtLVnwuiRFh7Oz1DssS90YY0yjcvTPA1MbWOYLVR3pvf4AICKhwKPAacBg4CIRGdycwjZGYnQE24sBxFI3xhhDIwK9qs4Dcpqw7XHABlXdpKoVwCvA2U3YzgFJig5nV0mV9/ARC/TGGNNSvW6OEZGlIvKBiAzxpnUH0gKWSfem1UpEZojIQhFZmJWV1eSCJMaEk1tcgYbbA8KNMQZaJtAvBnqp6gjgYeCtpmxEVZ9U1bGqOjYlJaXJhUmKDqfKr/jDY6GsoMnbMcaYYNHsQK+qBapa5L2fDfhEJBnIAHoELJrqTTuoau6OrQzvCKVNyTgZY0xwaXagF5EuIiLe+3HeNrOBBUB/EekjIuHAhcA7zd1fQ5Ji3N2xZb6OUGKB3hhjGuxHLyIzgclAsoikA3cAPgBVfRw4D7hORKqAUuBCVVWgSkRuAD4EQoFnVXXlQTmKADUjWBaHxtGxcP3B3p0xxrR5DQZ6Vb2ogfmPAI/UMW82MLtpRWuamtRNocRajd4YYwiysW5gT6DPJcbdMFVV3solMsaY1hV0gT7SF0p0eCjZ/hg3wWr1xph2LugCPbgG2ayqaPfBet4YY9q5oAz0idHh7Kjs4D5Yjd4Y084FZaBPig4nrcwL9FajN8a0c0EZ6BOjw0kri3QfrEZvjGnngjPQx4TzfYm7ccpq9MaY9i4oA31SdDhF1T40rIPV6I0x7V6QBnpXm6+O7Ailua1cGmOMaV1BGegTY9xNUxXhNt6NMcYEZaCvGe+mNCzecvTGmHYvKAN9zTAIxSFxVqM3xrR7QRnoa3L0BRJrNXpjTLsXlIG+Q3goHXyh5BLrGmP9/tYukjHGtJqgDPQAneMi2FkZBeqH8vzWLo4xxrSaoA30/TrF8H2xd9OU5emNMe1YEAf6WNYVes9Vsb70xph2rMFALyLPikimiKyoY/50EVkmIstF5GsRGREwb7M3fYmILGzJgjekf6cYdlXbmPTGGNOYGv3zwNR65n8PTFLVYcAfgSf3mX+Cqo5U1bFNK2LT9O8c454yBdbzxhjTrjXmmbHzRKR3PfO/Dvj4DZDa/GI1X9+UGHI11n2wGr0xph1r6Rz9T4APAj4r8JGILBKRGfWtKCIzRGShiCzMyspqdkGiI8KIjU/CT4jV6I0x7VqLBXoROQEX6H8VMPk4VR0NnAZcLyLH17W+qj6pqmNVdWxKSkqLlKlflzgKJcZq9MaYdq1FAr2IDAeeBs5W1eya6aqa4f3NBN4ExrXE/hqrf6cYsv3R+C3QG2PasWYHehHpCbwBXKqq6wKmR4tIbM174BSg1p47B0v/TrHkagzlBc1PBRljzOGqwcZYEZkJTAaSRSQduAPwAajq48DvgSTgMREBqPJ62HQG3vSmhQEvq+p/D8Ix1Kl/5xiyNYbKomw6HModG2NMG9KYXjcXNTD/KuCqWqZvAkbsv8ah069TDBuJRUq3tWYxjDGmVQXtnbEAsZE+KsLjCa+wsW6MMe1XUAd6gLCYZCK0DCrLWrsoxhjTKoI+0EfFu66a/uLsBpY0xpjgFPSBvmNSZwAyM7e3ckmMMaZ1BH2gT+nUFYDt261B1hjTPgV9oO/atRsAu7K8Gr3fD6qtWCJjjDm0gj7QxyW61E1+9k6oKocXzoRZV7ZyqYwx5tBpsB/9Ya9DIgC7Mrej796IbPnSTVMFdzOXMcYEtaCv0eOLpCq0A2dX/RdZ+gqkDHSjWRbtbO2SGWPMIRH8gR6Q6CS6Sg5rE0+E0//mJu48pMPuGGNMq2kXgT40sQ/f+/pxS+W10Hmom7hz1d4LpX0HC5459IUzxpiDrF0Eei5+lS8nzWRFVhUbisIhthvsXLn3MvPugw9/bT1yjDFBp30E+vBoThrWA4APV+6AzoP3DvT+atj6DVSVQYndQWuMCS7tI9ADXeM7MCI1no9W7oDOQ2DXWqiudDMzV0G5N/BZfnrrFdIYYw6CdhPoAU4Z0oWl6fnkxvSH6grI3uBmbJm/ZyEL9MaYINOuAv3UoV0AmJffyU2oSd9s/Roi4t37goxWKJkxxhw87SrQ902JoV+nGGZuioSQMBfoVV2Nvv/JEBoB+WmtXUxjjGlR7SrQA1x4VA++2VpEaXxfF+hzNkHRDuh1LMR3h3yr0RtjgkujAr2IPCsimSJS611G4jwkIhtEZJmIjA6Yd7mIrPdel7dUwZvqgqN6EBsRxoqqVNcIu9XLz/eaAPGplqM3xgSdxtbonwem1jP/NKC/95oB/BNARBJxDxM/GhgH3CEiCU0tbEuIjfRx8fiezMlNcWmatR+4sW9SBkBcquXojTFBp1GBXlXnATn1LHI28C91vgE6ikhX4FTgY1XNUdVc4GPq/8E4JK48tg/r6Ok+rP0Aeh7jBjiLT4XC7VBd1fBGygth7l/ciJjGGNOGtVSOvjsQ2IqZ7k2ra/p+RGSGiCwUkYVZWVktVKzadYmPpNego9wHrYZex7j38d1B/S7YN2T1ezD3T7BxzsErqDHGtIA20xirqk+q6lhVHZuSknLQ93f+iUeTr1HuQ89j3d/4VPe3MXn6Hcvd3+1LW75wxhjTgloq0GcAPQI+p3rT6pre6gZ2jWd7ZF9KiCA3bqCbGOcF+sbk6Xcsc38t0Btj2riWCvTvAJd5vW/GA/mquh34EDhFRBK8RthTvGltQswJv+AvVRfz1082ugnxXlapob70qnuGObZAb4xp4xr1hCkRmQlMBpJFJB3Xk8YHoKqPA7OB04ENQAlwpTcvR0T+CCzwNvUHVa2vUfeQSh1/LhE5g3lh3ibOH9uD0T0TILJjw33pCzKgNBcS+kDu91C8C6KTD02hjTHmADW2181FqtpVVX2qmqqqz6jq416Qx+ttc72q9lXVYaq6MGDdZ1W1n/d67mAdSFP9fEp/usRF8ps3V1BV7W9cX/qa/Pyo6e7v9iUHt5DGGNMMbaYxtrVER4Rxx5mDWb29gH/N3+ICfUFDgd5L24y42P219I0xpg1r94Ee3GBnkwek8PeP1lIc2bkRNfplkHiEy+kn9LFAb4xp0yzQAyLCH88eil/hg61hLv9eUVz3CjtX7HkkYbeRsM1SN8aYtssCvadHYhS3nHIkX2RGuAk1DbJLX4W/D4QSrw25vNANhNZluPvcdQTkbXE/DsYY0wZZoA9w5YQ+RKX0BqAwczP4/TDvb+5O2YXPuoVqxrDvMsz97TrC/d2+7JCW1RhjGssCfYDQEOGqM44DYPaXC2Djp5C9HjokwHdPQVXFnh43XbzUTdeR7q/l6Y0xbZQF+n307XskirA9bQO7PnkQYrvC2Y+5MetXvuECfYcEiPNuropKhPieFuiNMW1Wo26YaldCfRDbhVNLVpK8cy3Fx/2a6AGnQfIAmP+oezJVl2FutMsaXYdbX3pjTJtlNfpaSHwqg6rXUqY+frN1DAow/jrXrXLbYug8bO8Vuo50DxovK2iN4hpjTL0s0NfGG8VyS/cf8Na6cl5dkAYjLnQPKIE9DbE1ahpkd9b6AC5jjGlVFuhrE+8G3Ox/1q1M6JfEH95bxbKd5XDUT9z8rsP3Xr7zEPc3c9UhLKQxxjSOBfrajJsB579ASJchPPCjkSRGh3PFcwvYOPAauOiVPYG9Rlw3iIiDrLWtU15jjKmHBfradOwBQ84BoFNcJC/+5GhCBC59YRkZnSfvv7yIe+Zs5upDW05jjGkEC/SN0Cc5mhd+PI7CsioufeZbcosr9l8oZYDV6I0xbZIF+kYa0i2eZ644ivScUq799yIqqvx7L5AyCIoz9wyVYIwxbYQF+gMwrk8ifz1vON9+n8Nv31qOqu6ZmeI9jjBrTesUzhhj6mCB/gCdM6o7N07pz2sL03li3qY9Mzp5gd7y9MaYNqZRgV5EporIWhHZICK31zL/ARFZ4r3WiUhewLzqgHnvtGThW8svTurPD4Z35d4P1vDSt1vcxLjuEB5jeXpjTJvT4BAIIhIKPAqcDKQDC0TkHVXd3WlcVX8RsPzPgFEBmyhV1ZEtV+TWJyLcd/4ISiqq+c2bK8grqeSnk/siKQMgy2r0xpi2pTE1+nHABlXdpKoVwCvA2fUsfxEwsyUK15ZF+kJ54tIxnD2yG3/7cC1/mr0aTRloNXpjTJvTmEDfHUgL+JzuTduPiPQC+gCfBUyOFJGFIvKNiJxT105EZIa33MKsrKxGFKv1+UJDeOBHI7n8mF489cX3vJ0RC0U7reeNMaZNaenG2AuBWapaHTCtl6qOBS4GHhSRvrWtqKpPqupYVR2bkpLSwsU6eEJChDvPGsJtUwfwVkYcAPlbl7dyqYwxZo/GBPoMoEfA51RvWm0uZJ+0japmeH83AXPZO38fFESEn07ux2VnnQrAE298QFpOCajC8lmWzjHGtKrGBPoFQH8R6SMi4bhgvl/vGREZCCQA8wOmJYhIhPc+GZgABO3IXyeOG011WBTdKzZz9b8WUr7sDXj9J/DYeHjzWsj5vrWLaIxphxoM9KpaBdwAfAisBl5T1ZUi8gcROStg0QuBV3Svu4gYBCwUkaXAHODewN46QSckhNBOAzm9SwEZOzMpefc2tMswOOYGWPkmPDIWVr/X2qU0xrQzsndcbhvGjh2rCxcubO1iNM2b18HGz1iacDIj0l7k9VHPce7ZP4SC7fD0SW7s+otebu1SGmOCjIgs8tpD92N3xra0TgOhaAfD01/m6/jT+eU3Eby2IA2N7QJ9J8OWr8Dvb3Azxhul7RkAAB7gSURBVBjTUizQtzRvzBuJjGPUlf9gfJ8kbnt9GT+b+T9Kuh0LZXmQubKVC2mMaU8s0Le0riMgLBJOuZsOHTvx76uO5tZTB/DBih1c8ol3I/LmL1u3jMaYdsUCfUuL7QK3b4VRlwAQGiJcf0I/Zl17DDlhndjqT2Hpl++RWVDWygU1xrQXFugPhrCI/SaN6pnAf286noIu4+lZuIQpf5/Dw5+uJ6+kloeYtIbCHTDnz5C1rrVLYoxpYRboD6FIXyhDjz2DBCnih90L+PvH6zj23s/4w7uryMgrbZ1ClebBJ3fBP0bC5/fCB7e2TjmMMQeNBfpDrfcEAO4anssHP5/I1CFd+Nf8zUz66xxu/c9SNmUV1b7ehk/hi/vd3bYtpSgTHjkKvrwfBv0Axl8Pm+ZC2oKW24cxptVZoD/UOvZ0ry1fMqhrHPdfMJLPbzuBS8b34p2l25hy/+fc8tpSsovK96xTkgOvXwWf3gWf3NlyZfnqH1CyC37yMZz7NJzwa+iQAF/c13L7MMa0Ogv0raH3RNi8pz9996KV3Bn/PssGvcjiuNs4dsXvOOXvn7n+96ow98+uW+bAH8BXD8L8R5tfhqIsWPAMDDsfeoxz0yJiXK1+3X9h+9Lm78MY0yZYoG8NvSZAaQ58P9fV1J+eAnPuISJ7DQnd+3NuyOf8KfLf3Pb6Uq67/0X83z1N/tDL4Ef/gkFnwYe/hmWv1b+P3M3wxgw35IK/ev/5Xz8E1eVw/D45+XFXQ0QcfPH3ljraPTZ97q5IaiuPMeagafAJU+Yg6H2c+/viNAiNgONvg2NvgMh4N/2j33Hq1w/xzsgjkY2fkK9RTF5wLD23zednx9/NyaW5yJvXQGUJjLmi9n18cqcbX2fZq5B4BIz/qevy6evg1eafhqHnQXL/vdfr0BHGzXCBPnPNnmfhNocqfPkAfPZHUD8cMdm9DkRxNjx1Apz4Oxh+fvPLZEw7YjX61pDQywW6I6fCT+fDib/ZE+QBTroLhkxj+Jr7GVa5DJnyO37+g3EUllUyY+YKpuX+jJ2dJsC7P3ddIvdtoN2xwgX5CT+H855zeffZv4SHRsG3T7rG18rS/WvzNcb/FHxR8N/bmz9cQ1kBvHqJa18YdJZ7ru6K1w98O/MfhrwtMPdPh/6KQNV1PzXmMGWDmrVVlWXw8o+gqgyu/ABCQqmq9vPO0m088tkGtu7K577I5ziHOew68gKSLngUCfW5dV+ZDt/Pg58vhahEF6g2f+F+FLZ+7ZYZeh6c90zd+1/4LLz3CzjlHne10RR5ae4YstbCKX90PyBvzIANH8Mv10NNeRtSvAseHA7RSZC3FX70Igw+q+H1Wsond8KXD8Jlbx34lYgxh4gNanY48kXCZW/vDvIAYaEh/HB0Kh/fPIlnfnwsnx35ex7zTyN53at8+afTeeCDZWxe9iWsec8NjRyV6LYlAn2Ohytnw6VvwYiLYMrv69//mCthwBkuyDWlYXb7UjdaZ346XPI6HHO9K8fQH0JpruvG2VhfP+TSVBe/Bgl9XIP0oaqgLHrBpZ1E4NM/Hrr9toS8NHh8Inz7xOFV7vZk+9ID+7/QRBbo2zKR3UE+UGiIMOnIFB66eDSX/PopFg/5PyZWf8cx82eQ/p/byCeG3+yYyLtLt1FZ7d97e31PgGmPu/RRQ/s+62GITnYNxhUljS/3ps/h2dMgJAx+/KHbZ42+J0JEfOPTN0VZ8N1TMOw86DTIXV1kLIItXze+PE21aS68f7Mr82l/hYyFsP6jg7/f/HTYtqT521n0HOxYBh/cBi+d59JPJTmw9BV466ew7X/N30d7kb0RXvwhbF/WctusroTXLoOZF7vKz0FkqZtgsXwW+uY1iL+Kt5JmcGfuyeSVVHJEcjS3njqAqUO7ICIHvt1Nc+Ff57icfWS864LZZRiMuhT6TIKQfeoKxdnw2NEQleSuSGK77L/Nt66H1e+49I0vsv79f/Rb1530+u9cw3FlKTwwBFKPgotfdctUFLtG7dAW7FuQvRGePAHiusFPPnTH/8hY1yPpmnnuh/BgKCuAxye4H7gbvnP3XDRFdZX7nroOh/6nuO8xJMx9fzWPdE7qD9d+2fA5aKwdK2DV225/3cfs/2/jcFVRAs+cDDtXQNeRcPVntVbADtj//g1vX+/eT/k9TLylWZuz1E17MOw85OLXYMRFnHPNnSz67ck8ddlYQkOE615azDmPfc3L324lq7C84W0FOmKy69Y5+jLod6IbhnnDp/DiOfDQSNcXP7CyMPsWN6zCuc/UHuQBhk6D8gLY+Gnt83dtcNud9WPXeDzs/D29g3wdYNw1rq//7NtcMP5zKvx9ALx3sxsZ9EAakL97Cp6c7AJgoM/+6ALi9NfcD1yoDybd7mrIq99t/PYP1If/52r0qOtGG0jVtd00xvoPoWiH65U17mr34zTgNDjuFy5QTX8dste7hvmW8tFvYd5f4ZmT4MGh8Nk9rf/sha8f3hNMm0IV3r8Fdq6EsT+B7Uvcv83mqq6EeX9zo90ecYJLr1Ud4P/NA2A1+iBX7VdeX5zOY3M2sDm7BBE4qlciY3onMLRbPEO7x9EzMerAavuVZa4dYMHTsHU+jJwOP3gA1rwPs650XSCP/2U9haqE+450KZ3zng2YXgWf/cHdsQsQ0wX6TIRT7t77R6MkB/4xwuXtu4913VVzNsHaD6CqFDr2gqOuct1Ja9opalNRDA8Og5JsOPkPrpcSuMbjR4+G426Ck+7cs7y/2k0PCYPrvmqZWl2gNe/DKxe7mp0vyv3YXPI69DvJfedvXOV+yK772l1p1OelH7n87y9W1n2l8/rVrnfWtV+4tNi+vn0CYrs2ruE7d7M7J8fcAF2Gw/LXYMMncM7jMPKi2tdRhR3L3b4b2zAfuO53T4G/0nUsiO28/zK71sNjx7hlrv8OUgYc2D4AFj3verdNuh0m3+66RGcsghsW1F2RaYz/vQRv/xQuesUNgvjiNDj70d2j3jZFfTX6RgV6EZkK/AMIBZ5W1Xv3mX8F8Dcgw5v0iKo+7c27HPitN/1uVX2hof1ZoG95qsqaHYX8d8UOPluTyZodBVRWu3OfHBPB0UckMr5PIpMHdKJHYlTjNur3u4HQPv8L9Dja/cdK7AM//qjhNMq7N7k+/mfcD0ee6v7jvv5jlyoac4ULugl96k6RFGW6YBgRs2daeZEL9ouec0/yCuvgfnDq+tGZ/5irQScfCUU74cYl7ofhjWtcCuIXK1wbRaAVr7srjf6nwjmP7T+/qYoyXVCK6wZXfQqo+wxuiIr/XO56ToX4YNCZcP5zdW8rP8PVqI+7Gab8ru7line5dFTykXDlf/dOtaz70PWYCo1wP2r73m+xr8/uhnn3wU3LoWMP92/jmZNdL6mfLYLIuP3X+e4p1+03thscfQ2Mudx1BW6IqvsRrLmpT0JdO8pxN+25R0XVtUts/db9+B9zvfsxr0tVBYSF7z2tpkNB74kw/T/uhz17ozsvg86sv9dafaqr3PceGQczPnfTHp/ofpCum9/klFezAr2IhALrgJOBdGABcFHgQ769QD9WVW/YZ91EYCEwFlBgETBGVettebBAf/CVV1WzfmcRy9Lz+e77bL7ZlMMOb4z8od3jOG1oV04d0oV+nWIa2BKuVvjmdYDCNV9AypENr5O5xv1HzE9z/1EjYl365Iy/w+hLm3dw4PLFc//srjzOexaGnrv3/KpyN2JnUl+Yei88fpxr6B37Y3h4LBx9LUz90/7bVXU13Y9/54LStMddkGkOvx9mXuAasa/5fE/tesMn8O9zIbIjVBTBOf+EnO/dvQSXvV13V8+5f3HL/HwpJPSuf99LXoa3rttTYxVxV0yPjXfHV7jD1YQDen/tp7rKXRl1HgKXzNozPWMxPHWiC7Kn3rP3Ollr4YnjodsoCA2H7z8HXzQc+zP3Ix8eUNkoL3Ipu5r9z73XndvRl7ttL3sVlsyE4kx3BTH8fFj7X/ednnKPa7hPXwA3r9r/yqE4G967yX3Xl7wBvbwf14pieGKS+96v/cp17a0x58+ugjPpdlfemspGdaW74qoqd21UUYnu6nLfSk9Nbv7CmTDwdDdt6avw5gy4+D9w5Cn1n7M6NDfQHwPcqaqnep//D0BV/xywzBXUHugvAiar6jXe5yeAuao6s759WqA/9FSVzdklfLRyB7NX7GBpWh4ARyRHc/Lgzow/IomBXWPpEhdZe5onax2U5UOPow5kp67nx5r3IXM1HH+La8RrKVUV8MKZLj1w9ad7pycWvQDv3giXvukC9Vs/heWzXPDcNBduWlb/pfmO5TDrJ7BrLZz9GIya3vRyzvubqxGffp/Lpwd67TJXu/7Rv9yVT2WZa+wO8bkUzr61UH+1S6Ek9XP9/hui6u5tWP6aC5xn/N0bOuNdl8vPXAVvXgOn/hmO+albfsOnILiUEuwJqrXd3/DOjbDkJRcsa+6yrqpww34UZLgabGxn933Ouw9WvQVx3eGE37h/T2vec+nBsEiXz45OcQ35I6fDWY/sqf2WFcDMi9yV3Kn3uKuF0HB3NbL+Y3jlIpcmGXDanrKt/8SlT0py3HYrS9zVU8qR8M7PYPGLcPk7rmtyoMoyeONqV47oFDj2RijcDsv/A8VZey+b2Nel/wad6bb/+V9h/iOuQ8PVc/ZcsVZXuvOWeARc8V7D560WzQ305wFTVfUq7/OlwNGBQd0L9H8GsnC1/1+oapqI/BKIVNW7veV+B5Sq6n7DI4rIDGAGQM+ePcds2bLlgA/UtJxteaV8snonH63cyTebsqnyu38ncZFhjO2dyGlDu3Dy4M50jApvYEutrGC7qzlGxrn/WJFxey6dO3Tc858tPx0eHuNuUDvqajijESN4VpS4ALL5KxdUa9IG/mo3FlHWGvcfvyjTbRdcoOx93J6a4MbPXLe9YefDD5/cP1VVVeECXkzKnmnrPoKXz4cpd8DEm/dMz89wdzOvfgfOfx6GTGvcd+T3w5y7XSqk02AX3E/8rbtzWhVmXuiuNk66Exb/a88zj6f83qWHXpkO6d/BzatrrzE/PNpt96Q7XJroq3+4eyECa7Q1tnztjqHm3o1OQ2DAVFfDzljsGkWHToMzH9r/CqOy1KXV1s52n2t+xKsr4f5BLr144UtuXs2Pa8ogOPcpd8f2Mye7K4djb3QppeNudmWuS9oCd8f35i/cj8qRU2H4Ba5dozTH/ZDNf8xVBlLHuaujfO/pcyf/cf/2o/mPuuM/95km9YQ6FIE+CShS1XIRuQa4QFVPPJBAH8hq9G1LYVklq7cXsnZHAau2FzJvXRYZeaWEhQijeyYwPDWeYanxjEjtSK+kA2zYPRQ2f+Vq9gm9Xa8hEVdTvODfrqZV45O74JvH4IaFLs/cGKV5LkAUZ7ncuqpLhaR/52rdMZ1crc/XARA3kFzGItfQPPFm174R3cldcYRHN/6YXpnu2iNSj3LPOAiNcAFUq12bxHG3HHiud/GLLo3RdaS7/6Em5VCwDR4dD+X5LjBOuNH9QC3/Dwy/0P099oa6c+A1V0+BxlwBZ/6j9uX91e7O7o49XWotkGr9XVurq+Cj34CEwNQ/75n+0W/hm3/CzWtg8Qsuxz/8AveDURNUMxbD82e4mne30fCTjxpuJFZ1P4yxXWtv+K+ugiX/dummyI7uisl7JkWt22rG/52DnrrZZ/lQIEdV4y11E5xUlWXp+XywYgfffp/Nqm0FlFe5bnQdo3wMT+3I8O7xDOway8AucfROiiIstJV78i6f5VIIhTtdt8PkAXDF+3sHQ7/fjc8f0+nAtp2zCZ6a4oJ5SY7rRXH631wtvbb/uGnfwX//z92AFR4LM+Y03Ni5r+Js+PofLie8bYkL8ANOd8Gtobx8fXZtcFcPgWMvgftxKsl1NeSQEPddffYHd9cwwM8W7x+UA+VtdXn5XevcdzTx5gP7YWuuzDUu5ZV6lMvXD/uRa1/Z96pg/ccuvTLt8fqPpw1qbqAPw6VjpuB61SwALlbVlQHLdFXV7d77acCvVHW81xi7CBjtLboY1xibU98+LdAfXiqr/azbWciy9HyWpuWxJC2P9ZlFVPv3/rcVGiLERYZx8uDO/GB4N47tm9T6PwAtZct810XuiEmuptpQ1zu/311VxHbZ8zyApiovcmmB5H7N205TLHnZpSjqGiCvLXlqivtxHXouTHuyZW+wawNaonvl6cCDuO6Vz6rqPSLyB2Chqr4jIn8GzgKqgBzgOlVd4637Y6Dmzo97VLWefmGOBfrDX1llNRsyi1izo5CM3FKq/X6qVcnILeWT1ZkUlVcRGxnGEcnRpCZE0TMpiuP7p3BU74TDN/hXlnopGtMmpX3netccf+uB99s/DDQ70B9qFuiDW1llNZ+vy2Leuiy25pSQkVtKWm4JldVKxygfJw7oRN9OMXSOi6RzXAQxEWFE+kKJDg8jNaEDISFtrA3AmDagvkAfXNcu5rAQ6Qvl1CFdOHXInvRGcXkV89Zl8dGqnXy+Los3/pdR67qpCR04f0wPzhubSveOVns2pjGsRm/apNKKajILy9hZUE5xRRVlFdXklFQwe/l2vtqQjQh0jYskJTaClNgIunXsQM/EKFITouibEk2f5OjDNwVkTBNYjd4cdjqEh9IrKZpeSXv3zJh+dC/Sckp4e0kG3+8qIauonPTcUr7dlENhedXu5cJDQ+jbKYbuHSOJ9IXSwRdKl/hIRvdKYHTPBOI7BF+O1pi6WKA3h50eiVHccOLe3RFVlfzSSrbmlLAhs4i1OwpZs6OQ7flllFZUU1JRTVZROdV+3X01EOELxRcqJEVHcGzfJCYemcKw7vGEWhuACTKWujHtRnF5FUvT8li4JZetOSVUVPmpqPKTnlfCiowCgN01/5TYCJJjwvGFhhAWEkJ0RCgje3Rk/BFJdLO2AdMGWa8bYxqQXVTOVxuzWbI1j8zCMjILyskuLqeyWqmq9lNQVkWRlxpKTejAgM6x9EmOpmdSFKpQWllNWWU1vtAQIsJC6BAeSufYSHomRdEjIYoO4S08pLEx+7AcvTENSIqJ4KwR3ThrRO3jvFf7lTU7Cvh2Uw6LtuSyMauILzfs2n1HcENiI8KI6+CjY5SPI1JiGNOzI2N6JTKwayw+azQ2B5nV6I1pIr9f2VVUTkiIEBUeSkRYKFV+P2WVfsoqq9meX8bWnBLSckrYVVROfkklOSUVrNleuHtI6LAQoXdyNP1SYoiOCCOrqJxdheX4VUlNiKJHort6OGlwZ5JjIlr5iE1bZqkbY9qYjLxSFm7OYc2OQjZkFrExs4jSymo6xUbsDujp3o1kJRXVhAgc3SeJCf2SEBEqq/2ounsSosJDiesQxuCu8fTrFGONye2UpW6MaWO6d+xA95HdObuB5WqeDDZ7+XbeX76d+z5aV+/yUeGhDOwSS1wHn2sr8IWSHBOxu4HZr0pZpZ/yympiI30kx0aQEhNBn+Roa0cIYhbojWnDRIRBXeMY1DWOm08+kpKKasJCBZ836mZ5lZ/SympyistZnpHP0rR81uwoIKe4gvJKPyWVVWQVllNWWX9bQohAv04xDO0WT99OMfRMjKJnYhQpsRHERIYRHR5GiEBFtUtNhXnpqjY3JLWplaVujAlyqkpBmQv4oSFCpC+E8NAQCsuq2FVUzs6CctbtLGRFRj4rtuWzs6C81u2IuCHTa0SEhZAYHU6X+EgGdI7lyM6xpMRGkFlYzo78UiqrlckDUji2bzLhYdbgfLBZjt4Y02jF5VWk5ZawNbuEnOIKisqrKCirQlWJ9IUSERZClV/JKa4gp7iC9NwS1u4oJLekcvc2In0usJdV+omNDOPoPklU+f0UlFZSWFZFuXcPQ5Vfie8QRlKMSyEN7hbH6J4JjOgRT1T43gkHVSW3pJLYyDDrqVQLy9EbYxotOiKMgV3iGNglrtHrqCq7ilzg7xwXQXwHH+VVfr7asIsPVuzgf1tziY4IIy7SR+e4SCLCQggPCyFEhPzSSrKLK1ixLZ/3l28HXCqpU6xrV0iMDienuILNu4opLK+igy+Uo/okcswRSSTFhFNYVkVhWSW+0BBSYiJ2t0VsyyslI6+M0BAY1SOB0b0SSIze/9GXeSUVZBWW069TTNCmoqxGb4xpM/JKKvjf1jz+l5bHjvxSsgrL2VVU4e4/SI6mR2IUaTklzN+UzbqdRQ1uzxcqqLL7mcepCR3o5d3EFhYqLNycy5odhQAM7hrHFRN6c+bwbmQWlrF6ewEbs4opr6ymolpRlP6dYhnZI54jkmPwq5JVVE5mQTkdo3x069hh95VGZbWf7KIKEqJ9RIQdmkZuS90YY4JOdlE5JRXVxEaGERMRRmW1u68hs7AcEUjt2IHkmAgqqv0sS89n0ZZcVm0vIC2nhPTcEkorqhndK4FxvROJ6+Dj5W+3snZn4X5tESLgCwlBUSqr3YxIXwgVVX4CH6IWItA1vgPlVX6yi8tRhejwUCYP6MQpQzozpFs8UeFugL0InxtaIyxEWuz5ChbojTGmAarK/E3ZzFu3i95JUQzqGseRnWN3dzut9iubsopYkpbH6u2FxESE0jk+kpSYCPJKK0nPKSEtt5RIXwidYiNJjo1g9fYCPl61k6zC2hu4wV11REe4H6tu8R147dpjmlT+ZufoRWQq8A/cowSfVtV795l/M3AV7lGCWcCPVXWLN68aWO4tulVVz2rSURhjzEEkIhzbN5lj+ybXOj80ROjfOZb+nWMPaLt3nz2UJel5pOWU7B5JtaLaT7VfqapWyqqqKS6voqis6qD1Tmow0ItIKPAocDKQDiwQkXdUdVXAYv8DxqpqiYhcB/wVuMCbV6qqI1u43MYYc1gICRFG93TPQWi1MjRimXHABlXdpKoVwCuw9w19qjpHVUu8j98AqS1bTGOMMU3VmEDfHUgL+JzuTavLT4APAj5HishCEflGRM5pQhmNMcY0Q4v2oxeRS4CxwKSAyb1UNUNEjgA+E5HlqrqxlnVnADMAevbs2ZLFMsaYdq0xNfoMoEfA51Rv2l5E5CTgN8BZqrq7iVlVM7y/m4C5wKjadqKqT6rqWFUdm5KS0ugDMMYYU7/GBPoFQH8R6SMi4cCFwDuBC4jIKOAJXJDPDJieICIR3vtkYAIQ2IhrjDHmIGswdaOqVSJyA/Ahrnvls6q6UkT+ACxU1XeAvwExwH+8W4hrulEOAp4QET/uR+XefXrrGGOMOcjshiljjAkC9d0wZUPAGWNMkGuTNXoRyQK2NHH1ZGBXCxbncNAejxna53G3x2OG9nncB3rMvVS11p4sbTLQN4eILKzr8iVYtcdjhvZ53O3xmKF9HndLHrOlbowxJshZoDfGmCAXjIH+ydYuQCtoj8cM7fO42+MxQ/s87hY75qDL0RtjjNlbMNbojTHGBLBAb4wxQS5oAr2ITBWRtSKyQURub+3yHCwi0kNE5ojIKhFZKSI/96YnisjHIrLe+9t6Tzk4SEQkVET+JyLveZ/7iMi33jl/1RuLKaiISEcRmSUia0RktYgcE+znWkR+4f3bXiEiM0UkMhjPtYg8KyKZIrIiYFqt51ach7zjXyYiow9kX0ER6AOegnUaMBi4SEQGt26pDpoq4BZVHQyMB673jvV24FNV7Q986n0ONj8HVgd8/gvwgKr2A3Jxz0IINv8A/quqA4ERuOMP2nMtIt2BG3FPrBuKG1/rQoLzXD8PTN1nWl3n9jSgv/eaAfzzQHYUFIGeRjwFK1io6nZVXey9L8T9x++OO94XvMVeAILqIS8ikgqcATztfRbgRGCWt0gwHnM8cDzwDICqVqhqHkF+rnGDLXYQkTAgCthOEJ5rVZ0H5Owzua5zezbwL3W+ATqKSNfG7itYAv2BPgUrKIhIb9z4/t8CnVV1uzdrB9C5lYp1sDwI3Ab4vc9JQJ6qVnmfg/Gc9wGygOe8lNXTIhJNEJ9r7/kV9wFbcQE+H1hE8J/rGnWd22bFuGAJ9O2OiMQArwM3qWpB4Dx1fWaDpt+siPwAyFTVRa1dlkMsDBgN/FNVRwHF7JOmCcJznYCrvfYBugHR7J/eaBda8twGS6Bv1FOwgoWI+HBB/iVVfcObvLPmUs77m1nX+oehCcBZIrIZl5Y7EZe77uhd3kNwnvN0IF1Vv/U+z8IF/mA+1ycB36tqlqpWAm/gzn+wn+sadZ3bZsW4YAn0DT4FK1h4uelngNWqen/ArHeAy733lwNvH+qyHSyq+n+qmqqqvXHn9jNVnQ7MAc7zFguqYwZQ1R1AmogM8CZNwT2hLWjPNS5lM15Eorx/6zXHHNTnOkBd5/Yd4DKv9814ID8gxdMwVQ2KF3A6sA7YCPymtctzEI/zONzl3DJgifc6HZez/hRYD3wCJLZ2WQ/S8U8G3vPeHwF8B2wA/gNEtHb5DsLxjgQWeuf7LSAh2M81cBewBlgBvAhEBOO5Bmbi2iEqcVdvP6nr3AKC61m4EViO65XU6H3ZEAjGGBPkgiV1Y4wxpg4W6I0xJshZoDfGmCBngd4YY4KcBXpjjAlyFuiNMSbIWaA3xpgg9//kojziYd0vuAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "bOGWA0NL6UF_",
        "outputId": "431d087c-6342-4c4f-8eab-998df33210b2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy performance')\n",
        "plt.legend(['train accuracy', 'validation accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSGatV59isQC",
        "outputId": "bfd2d22b-c835-49a5-c605-c58300eb578e"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.4973 - accuracy: 0.8466\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4973107874393463, 0.8465999960899353]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOeBUFuq6sgn"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}