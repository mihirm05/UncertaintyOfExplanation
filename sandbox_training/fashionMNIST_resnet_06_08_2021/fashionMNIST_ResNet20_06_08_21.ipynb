{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashionMNIST_ResNet20_06_08_21.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFV7xDSkAxm7",
        "outputId": "6b0085d8-3ad2-411a-9a47-3b41347c6cc3"
      },
      "source": [
        "!pip install scipy==1.2.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scipy==1.2.2\n",
            "  Downloading scipy-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 39 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.2.2) (1.19.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSD59fzx2NwB",
        "outputId": "ae3d5ee8-39b4-4409-a869-538f50a4401f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmXI6jeS1-t9"
      },
      "source": [
        "import tensorflow as tf \n",
        "import os \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation, Dropout\n",
        "from tensorflow.keras.layers import Input, Flatten, AveragePooling2D, Add\n",
        "from tensorflow.keras import backend as K \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10 \n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# to resize fashion MNIST from 28x28 to 32x32 \n",
        "from tqdm import tqdm\n",
        "from scipy import misc"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zROr-05a2Gkd"
      },
      "source": [
        "batch_size=32 \n",
        "epochs=100 \n",
        "num_classes=10 \n",
        "depth=20 "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALLQbtz2cA4b"
      },
      "source": [
        "model_type = 'ResNet%d' % (depth)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft7a2_0T7dk0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9269cbf-dd03-491a-9ce4-200ea48abb77"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data() "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "1XAn6inKB5Up",
        "outputId": "2cf5c927-db0c-4883-8498-aa60786361a9"
      },
      "source": [
        "x_train = np.array([misc.imresize(x, (32, 32)).astype(float) for x in tqdm(iter(x_train))])\n",
        "x_train = x_train[:, :, :, np.newaxis]\n",
        "\n",
        "x_test = np.array([misc.imresize(x, (32, 32)).astype(float) for x in tqdm(iter(x_test))])\n",
        "x_test = x_test[:, :, :, np.newaxis]\n",
        "\n",
        "x_train = x_train/255 \n",
        "x_test = x_test/255 \n",
        "\n",
        "idx = np.random.randint(0, 59999)\n",
        "\n",
        "img = x_train[idx].squeeze()\n",
        "\n",
        "plt.imshow(img)\n",
        "print(img.shape)\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes) \n",
        "input_shape=x_train.shape[1:]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
            "    Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "60000it [00:04, 14735.23it/s]\n",
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
            "    Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
            "  after removing the cwd from sys.path.\n",
            "10000it [00:00, 15485.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(32, 32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geI2YTs_8Sfz"
      },
      "source": [
        "def resnet_layer(inputs, num_filters=16, kernel_size=3, strides=1, activation='relu', batch_normalization=True, conv_first=True):\n",
        "    conv = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')\n",
        "    x = inputs \n",
        "    if conv_first:\n",
        "        x = conv(x) \n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x) \n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "\n",
        "    else: \n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x) \n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x) \n",
        "        x = conv(x) \n",
        "    return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTatFBthCAG9"
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    if (depth - 2)%6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20,32, 44 in [a])')\n",
        "\n",
        "    # model definition \n",
        "    num_filters = 16 \n",
        "    num_res_blocks = int((depth-2)/6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs) \n",
        "\n",
        "    ## instantiate the stack of residual units \n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1 \n",
        "            if stack > 0 and res_block ==0: # first layer but not first stack \n",
        "                strides = 2 # downsample\n",
        "            y = resnet_layer(inputs=x, num_filters=num_filters, strides=strides)\n",
        "            y = resnet_layer(inputs=y, num_filters=num_filters, activation=None)\n",
        "            if stack > 0 and res_block == 0: # first layer but not first stack \n",
        "                # linear projection residual shortcut connection to match changed dimes \n",
        "                x = resnet_layer(inputs=x, num_filters=num_filters, kernel_size=1, strides=strides, activation=None, batch_normalization=False)\n",
        "            x = tf.keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x) \n",
        "            x = Dropout(rate=0.25)(x) \n",
        "        num_filters *= 2 \n",
        "\n",
        "    # Add classifier on top \n",
        "    # v1 does not use BN after last shortcut connection to match changed dims \n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x) \n",
        "\n",
        "    outputs = Dense(num_classes, activation='softmax')(y)\n",
        "\n",
        "    # Instantiate model \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model          "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhA6KOZ-V-Zl"
      },
      "source": [
        "model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I3Q5TJ-WFee"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4Q1NrNaWapd",
        "outputId": "227b2753-0723-4cdd-cabf-6ef5547ce54f"
      },
      "source": [
        "model.summary() \n",
        "print(model_type)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   160         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 16)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           dropout[0][0]                    \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 16)   0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           dropout_1[0][0]                  \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 16)   0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 32)   4640        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 32)   544         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 32)   0           conv2d_9[0][0]                   \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 32)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 16, 16, 32)   0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 32)   9248        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 32)   0           dropout_3[0][0]                  \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 16, 16, 32)   0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           dropout_4[0][0]                  \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 16, 16, 32)   0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 64)     18496       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 64)     36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 64)     2112        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 64)     0           conv2d_16[0][0]                  \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 64)     0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 8, 8, 64)     0           activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 64)     36928       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 64)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 64)     0           dropout_6[0][0]                  \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 8, 8, 64)     0           activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 64)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 64)     0           dropout_7[0][0]                  \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 8, 8, 64)     0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 274,154\n",
            "Trainable params: 272,778\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yEUNWxvWgrl"
      },
      "source": [
        "save_dir = os.path.join(os.getcwd(), 'saved_models') \n",
        "model_name = 'fashionMNIST_%s_model.{epoch:03d}.h5'%model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ_VTtsJXTWg"
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_accuracy', verbose=2, save_best_only=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FB9ARxQXca9"
      },
      "source": [
        "callbacks = [checkpoint] "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vC3MVxoYXjh",
        "outputId": "24091535-6605-4602-e496-8212a3eecc79"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2, shuffle=True, callbacks=callbacks)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 52s 12ms/step - loss: 0.6821 - accuracy: 0.7485 - val_loss: 0.4970 - val_accuracy: 0.8155\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.81550, saving model to /content/saved_models/fashionMNIST_ResNet20_model.001.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.4132 - accuracy: 0.8511 - val_loss: 0.4025 - val_accuracy: 0.8569\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.81550 to 0.85692, saving model to /content/saved_models/fashionMNIST_ResNet20_model.002.h5\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.3502 - accuracy: 0.8744 - val_loss: 0.3098 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.85692 to 0.88917, saving model to /content/saved_models/fashionMNIST_ResNet20_model.003.h5\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.3154 - accuracy: 0.8870 - val_loss: 0.2659 - val_accuracy: 0.9022\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.88917 to 0.90217, saving model to /content/saved_models/fashionMNIST_ResNet20_model.004.h5\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.2947 - accuracy: 0.8927 - val_loss: 0.3223 - val_accuracy: 0.8848\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.90217\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.2812 - accuracy: 0.8975 - val_loss: 0.2630 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.90217 to 0.90542, saving model to /content/saved_models/fashionMNIST_ResNet20_model.006.h5\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.2662 - accuracy: 0.9029 - val_loss: 0.2510 - val_accuracy: 0.9056\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.90542 to 0.90558, saving model to /content/saved_models/fashionMNIST_ResNet20_model.007.h5\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.2553 - accuracy: 0.9078 - val_loss: 0.2630 - val_accuracy: 0.9054\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.90558\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.2469 - accuracy: 0.9095 - val_loss: 0.2417 - val_accuracy: 0.9154\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.90558 to 0.91542, saving model to /content/saved_models/fashionMNIST_ResNet20_model.009.h5\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.2388 - accuracy: 0.9115 - val_loss: 0.2513 - val_accuracy: 0.9108\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.91542\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.2332 - accuracy: 0.9154 - val_loss: 0.2266 - val_accuracy: 0.9175\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.91542 to 0.91750, saving model to /content/saved_models/fashionMNIST_ResNet20_model.011.h5\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.2294 - accuracy: 0.9164 - val_loss: 0.2547 - val_accuracy: 0.9080\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.91750\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.2225 - accuracy: 0.9184 - val_loss: 0.2724 - val_accuracy: 0.9047\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.91750\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.2156 - accuracy: 0.9212 - val_loss: 0.2449 - val_accuracy: 0.9138\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.91750\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.2102 - accuracy: 0.9238 - val_loss: 0.2056 - val_accuracy: 0.9237\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.91750 to 0.92367, saving model to /content/saved_models/fashionMNIST_ResNet20_model.015.h5\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.2065 - accuracy: 0.9233 - val_loss: 0.2206 - val_accuracy: 0.9204\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.92367\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.2021 - accuracy: 0.9244 - val_loss: 0.2020 - val_accuracy: 0.9273\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.92367 to 0.92725, saving model to /content/saved_models/fashionMNIST_ResNet20_model.017.h5\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 20s 14ms/step - loss: 0.2000 - accuracy: 0.9248 - val_loss: 0.2063 - val_accuracy: 0.9276\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.92725 to 0.92758, saving model to /content/saved_models/fashionMNIST_ResNet20_model.018.h5\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.1982 - accuracy: 0.9272 - val_loss: 0.2115 - val_accuracy: 0.9226\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.92758\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.1931 - accuracy: 0.9294 - val_loss: 0.2085 - val_accuracy: 0.9225\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.92758\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1905 - accuracy: 0.9300 - val_loss: 0.2057 - val_accuracy: 0.9285\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.92758 to 0.92850, saving model to /content/saved_models/fashionMNIST_ResNet20_model.021.h5\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1862 - accuracy: 0.9300 - val_loss: 0.2008 - val_accuracy: 0.9285\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.92850\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.1866 - accuracy: 0.9309 - val_loss: 0.1948 - val_accuracy: 0.9300\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.92850 to 0.93000, saving model to /content/saved_models/fashionMNIST_ResNet20_model.023.h5\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1817 - accuracy: 0.9344 - val_loss: 0.1934 - val_accuracy: 0.9313\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.93000 to 0.93133, saving model to /content/saved_models/fashionMNIST_ResNet20_model.024.h5\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1776 - accuracy: 0.9340 - val_loss: 0.2049 - val_accuracy: 0.9281\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.93133\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1759 - accuracy: 0.9359 - val_loss: 0.2050 - val_accuracy: 0.9293\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.93133\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1746 - accuracy: 0.9358 - val_loss: 0.1923 - val_accuracy: 0.9306\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.93133\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1717 - accuracy: 0.9368 - val_loss: 0.1902 - val_accuracy: 0.9308\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.93133\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1705 - accuracy: 0.9371 - val_loss: 0.1908 - val_accuracy: 0.9330\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.93133 to 0.93300, saving model to /content/saved_models/fashionMNIST_ResNet20_model.029.h5\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1672 - accuracy: 0.9390 - val_loss: 0.1958 - val_accuracy: 0.9308\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.93300\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.1652 - accuracy: 0.9398 - val_loss: 0.2015 - val_accuracy: 0.9275\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.93300\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.1638 - accuracy: 0.9395 - val_loss: 0.2019 - val_accuracy: 0.9297\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.93300\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1604 - accuracy: 0.9404 - val_loss: 0.2059 - val_accuracy: 0.9270\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.93300\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1604 - accuracy: 0.9400 - val_loss: 0.2090 - val_accuracy: 0.9238\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.93300\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.1552 - accuracy: 0.9430 - val_loss: 0.1964 - val_accuracy: 0.9302\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.93300\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1570 - accuracy: 0.9417 - val_loss: 0.1936 - val_accuracy: 0.9333\n",
            "\n",
            "Epoch 00036: val_accuracy improved from 0.93300 to 0.93325, saving model to /content/saved_models/fashionMNIST_ResNet20_model.036.h5\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 21s 14ms/step - loss: 0.1532 - accuracy: 0.9443 - val_loss: 0.1964 - val_accuracy: 0.9309\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.93325\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1532 - accuracy: 0.9436 - val_loss: 0.1883 - val_accuracy: 0.9329\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.93325\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.1502 - accuracy: 0.9448 - val_loss: 0.1980 - val_accuracy: 0.9306\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.93325\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1483 - accuracy: 0.9454 - val_loss: 0.2030 - val_accuracy: 0.9306\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.93325\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1474 - accuracy: 0.9455 - val_loss: 0.1928 - val_accuracy: 0.9317\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.93325\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1458 - accuracy: 0.9460 - val_loss: 0.1994 - val_accuracy: 0.9299\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.93325\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.1446 - accuracy: 0.9453 - val_loss: 0.1887 - val_accuracy: 0.9357\n",
            "\n",
            "Epoch 00043: val_accuracy improved from 0.93325 to 0.93567, saving model to /content/saved_models/fashionMNIST_ResNet20_model.043.h5\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 21s 14ms/step - loss: 0.1408 - accuracy: 0.9480 - val_loss: 0.1913 - val_accuracy: 0.9343\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.93567\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1419 - accuracy: 0.9480 - val_loss: 0.1907 - val_accuracy: 0.9335\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.93567\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1400 - accuracy: 0.9467 - val_loss: 0.2008 - val_accuracy: 0.9317\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.93567\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.1397 - accuracy: 0.9480 - val_loss: 0.2025 - val_accuracy: 0.9309\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.93567\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.1378 - accuracy: 0.9484 - val_loss: 0.1956 - val_accuracy: 0.9321\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.93567\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1352 - accuracy: 0.9486 - val_loss: 0.1930 - val_accuracy: 0.9327\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.93567\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1350 - accuracy: 0.9497 - val_loss: 0.2033 - val_accuracy: 0.9298\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.93567\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1337 - accuracy: 0.9501 - val_loss: 0.1948 - val_accuracy: 0.9349\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.93567\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1336 - accuracy: 0.9500 - val_loss: 0.1888 - val_accuracy: 0.9340\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.93567\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1336 - accuracy: 0.9501 - val_loss: 0.1924 - val_accuracy: 0.9352\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.93567\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1295 - accuracy: 0.9516 - val_loss: 0.2048 - val_accuracy: 0.9302\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.93567\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1295 - accuracy: 0.9519 - val_loss: 0.1911 - val_accuracy: 0.9355\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.93567\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1288 - accuracy: 0.9519 - val_loss: 0.2010 - val_accuracy: 0.9318\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.93567\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1292 - accuracy: 0.9524 - val_loss: 0.1972 - val_accuracy: 0.9326\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.93567\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1274 - accuracy: 0.9521 - val_loss: 0.1919 - val_accuracy: 0.9337\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.93567\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1249 - accuracy: 0.9522 - val_loss: 0.1963 - val_accuracy: 0.9351\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.93567\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1233 - accuracy: 0.9534 - val_loss: 0.1998 - val_accuracy: 0.9337\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.93567\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1251 - accuracy: 0.9529 - val_loss: 0.1992 - val_accuracy: 0.9352\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.93567\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1231 - accuracy: 0.9534 - val_loss: 0.2167 - val_accuracy: 0.9289\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.93567\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 18s 12ms/step - loss: 0.1222 - accuracy: 0.9543 - val_loss: 0.2117 - val_accuracy: 0.9313\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.93567\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1199 - accuracy: 0.9560 - val_loss: 0.1948 - val_accuracy: 0.9362\n",
            "\n",
            "Epoch 00064: val_accuracy improved from 0.93567 to 0.93625, saving model to /content/saved_models/fashionMNIST_ResNet20_model.064.h5\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.1210 - accuracy: 0.9552 - val_loss: 0.2026 - val_accuracy: 0.9337\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.93625\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1188 - accuracy: 0.9550 - val_loss: 0.2007 - val_accuracy: 0.9343\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.93625\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1160 - accuracy: 0.9576 - val_loss: 0.2062 - val_accuracy: 0.9327\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.93625\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1195 - accuracy: 0.9550 - val_loss: 0.1964 - val_accuracy: 0.9385\n",
            "\n",
            "Epoch 00068: val_accuracy improved from 0.93625 to 0.93850, saving model to /content/saved_models/fashionMNIST_ResNet20_model.068.h5\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1159 - accuracy: 0.9565 - val_loss: 0.1981 - val_accuracy: 0.9366\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.93850\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1165 - accuracy: 0.9567 - val_loss: 0.1911 - val_accuracy: 0.9363\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.93850\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1168 - accuracy: 0.9561 - val_loss: 0.1924 - val_accuracy: 0.9353\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.93850\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.1141 - accuracy: 0.9572 - val_loss: 0.1906 - val_accuracy: 0.9368\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.93850\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1127 - accuracy: 0.9576 - val_loss: 0.2108 - val_accuracy: 0.9313\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.93850\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1140 - accuracy: 0.9574 - val_loss: 0.1981 - val_accuracy: 0.9367\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.93850\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1110 - accuracy: 0.9586 - val_loss: 0.2096 - val_accuracy: 0.9303\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.93850\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1110 - accuracy: 0.9586 - val_loss: 0.1964 - val_accuracy: 0.9385\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.93850\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1082 - accuracy: 0.9598 - val_loss: 0.2253 - val_accuracy: 0.9311\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.93850\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1110 - accuracy: 0.9578 - val_loss: 0.2035 - val_accuracy: 0.9348\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.93850\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.1078 - accuracy: 0.9589 - val_loss: 0.1963 - val_accuracy: 0.9325\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.93850\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1087 - accuracy: 0.9592 - val_loss: 0.2022 - val_accuracy: 0.9360\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.93850\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1058 - accuracy: 0.9605 - val_loss: 0.2000 - val_accuracy: 0.9350\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.93850\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1059 - accuracy: 0.9610 - val_loss: 0.2463 - val_accuracy: 0.9259\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.93850\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1049 - accuracy: 0.9599 - val_loss: 0.1988 - val_accuracy: 0.9347\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.93850\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.1061 - accuracy: 0.9603 - val_loss: 0.1985 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.93850\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1048 - accuracy: 0.9602 - val_loss: 0.2038 - val_accuracy: 0.9362\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.93850\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1034 - accuracy: 0.9615 - val_loss: 0.2008 - val_accuracy: 0.9349\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.93850\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1012 - accuracy: 0.9614 - val_loss: 0.1959 - val_accuracy: 0.9375\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.93850\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1001 - accuracy: 0.9626 - val_loss: 0.2009 - val_accuracy: 0.9373\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.93850\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.1035 - accuracy: 0.9620 - val_loss: 0.2051 - val_accuracy: 0.9371\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.93850\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.1000 - accuracy: 0.9627 - val_loss: 0.2104 - val_accuracy: 0.9315\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.93850\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.0991 - accuracy: 0.9630 - val_loss: 0.2087 - val_accuracy: 0.9377\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.93850\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0968 - accuracy: 0.9638 - val_loss: 0.2156 - val_accuracy: 0.9345\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.93850\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.0984 - accuracy: 0.9631 - val_loss: 0.2127 - val_accuracy: 0.9334\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.93850\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.0981 - accuracy: 0.9639 - val_loss: 0.2085 - val_accuracy: 0.9352\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.93850\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0963 - accuracy: 0.9641 - val_loss: 0.2109 - val_accuracy: 0.9348\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.93850\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.0955 - accuracy: 0.9640 - val_loss: 0.2153 - val_accuracy: 0.9354\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.93850\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0963 - accuracy: 0.9648 - val_loss: 0.2324 - val_accuracy: 0.9299\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.93850\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 19s 12ms/step - loss: 0.0926 - accuracy: 0.9649 - val_loss: 0.2188 - val_accuracy: 0.9337\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.93850\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0994 - accuracy: 0.9621 - val_loss: 0.2027 - val_accuracy: 0.9365\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.93850\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.0928 - accuracy: 0.9651 - val_loss: 0.2094 - val_accuracy: 0.9371\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.93850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "cc0aq8wk5m6F",
        "outputId": "c3a95a6b-0491-4ae8-cf19-8b83cbfa912f"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss performance')\n",
        "plt.legend(['train loss', 'validation loss'])\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "bOGWA0NL6UF_",
        "outputId": "08167f25-c60a-4579-ca7f-d61bf36b8642"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy performance')\n",
        "plt.legend(['train accuracy', 'validation accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSGatV59isQC",
        "outputId": "41aff612-d6c8-42bd-9f05-f24d3172dd32"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.2172 - accuracy: 0.9362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2172386646270752, 0.9362000226974487]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOeBUFuq6sgn"
      },
      "source": [
        "# https://towardsdatascience.com/resnets-for-cifar-10-e63e900524e0\n",
        "# http://www.pabloruizruiz10.com/resources/CNNs/ResNet-PyTorch.html \n",
        "# https://github.com/shoji9x9/Fashion-MNIST-By-ResNet/blob/master/Fashion-MNIST-by-ResNet-50.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}