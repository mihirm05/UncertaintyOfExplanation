{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GBP_CHD_flipout_explanation.ipynb","provenance":[],"authorship_tag":"ABX9TyOYYas5k5CJG9wXs8mbH6ds"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Mount the drive"],"metadata":{"id":"qXoue5Vd64bU"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iJlCiyjl6mBe","executionInfo":{"status":"ok","timestamp":1646557998989,"user_tz":-60,"elapsed":25158,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"0d73ee75-ef31-4c19-f7c1-2ee616db5530"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mount the drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","import tensorflow as tf\n","tf.compat.v1.disable_eager_execution()"]},{"cell_type":"markdown","source":["## Removing the previous plots and explanations"],"metadata":{"id":"lEwlVZ-F7KTZ"}},{"cell_type":"code","source":["import glob, os, os.path\n","mydir = '/content/drive/MyDrive/MasterThesis/CaliforniaHousingDatasetTests/GBP_explanation/flipout/output_plots/'\n","filelist = glob.glob(os.path.join(mydir, \"*.pdf\"))\n","for f in filelist:\n","    print(f'removing file {f}')\n","    os.remove(f)"],"metadata":{"id":"fN5TNFaZ7MsG","executionInfo":{"status":"ok","timestamp":1646558000047,"user_tz":-60,"elapsed":1080,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Installing keras uncertainty"],"metadata":{"id":"LjUoBxcC7Qba"}},{"cell_type":"code","source":["# keras_uncertainty imports\n","# clone and install this library \n","\n","!git clone https://github.com/mvaldenegro/keras-uncertainty.git\n","!pip install --user git+https://github.com/mvaldenegro/keras-uncertainty.git\n","\n","%cd keras-uncertainty"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M00Lb-6Q7R-m","executionInfo":{"status":"ok","timestamp":1646558004484,"user_tz":-60,"elapsed":4447,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"dd25cc34-5cfd-44f1-e2bf-106858555917"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'keras-uncertainty'...\n","remote: Enumerating objects: 755, done.\u001b[K\n","remote: Counting objects: 100% (459/459), done.\u001b[K\n","remote: Compressing objects: 100% (268/268), done.\u001b[K\n","remote: Total 755 (delta 301), reused 344 (delta 189), pack-reused 296\u001b[K\n","Receiving objects: 100% (755/755), 512.11 KiB | 10.04 MiB/s, done.\n","Resolving deltas: 100% (457/457), done.\n","Collecting git+https://github.com/mvaldenegro/keras-uncertainty.git\n","  Cloning https://github.com/mvaldenegro/keras-uncertainty.git to /tmp/pip-req-build-nbb5rr3b\n","  Running command git clone -q https://github.com/mvaldenegro/keras-uncertainty.git /tmp/pip-req-build-nbb5rr3b\n","Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from Keras-Uncertainty==0.0.1) (2.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Keras-Uncertainty==0.0.1) (1.21.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Keras-Uncertainty==0.0.1) (4.63.0)\n","Building wheels for collected packages: Keras-Uncertainty\n","  Building wheel for Keras-Uncertainty (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Keras-Uncertainty: filename=Keras_Uncertainty-0.0.1-py3-none-any.whl size=35003 sha256=d22a763e03a6778e5a78f341b3a38cb334d7e10b63f1e0f296748b52654cb856\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-t5o_qeil/wheels/8c/eb/76/c48d9a3cb2d0fae3e34f358af093c6d126ccd9272e6e887a95\n","Successfully built Keras-Uncertainty\n","Installing collected packages: Keras-Uncertainty\n","Successfully installed Keras-Uncertainty-0.0.1\n","/content/keras-uncertainty\n"]}]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"T6cItNqu7T_5"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np \n","import matplotlib.pyplot as plt \n","import tensorflow as tf\n"],"metadata":{"id":"vVm1t2rH7U1f","executionInfo":{"status":"ok","timestamp":1646558004809,"user_tz":-60,"elapsed":340,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Load Data"],"metadata":{"id":"Li6IaIAr7Yhc"}},{"cell_type":"code","source":["\n","# load the california housing data from csv\n","train_file = '/content/sample_data/california_housing_train.csv'\n","test_file = '/content/sample_data/california_housing_test.csv'\n","\n","train_combined = pd.read_csv(train_file)\n","test = pd.read_csv(test_file)\n","\n","# split the data in validation and test (from test.csv)\n","train, val = train_test_split(train_combined, test_size=0.25)\n","\n","feature_names = list(train_combined.columns)\n","print(feature_names)\n","\n","# assign the target variable\n","target = 'median_house_value'\n","\n","# extract the target label in all sets\n","train_labels_df= train[target]\n","val_labels_df = val[target]\n","test_labels_df = test[target]\n","\n","# extract the data from all sets \n","train_data_df = train.drop(columns=target, axis=1)\n","val_data_df = val.drop(columns=target, axis=1)\n","test_data_df = test.drop(columns=target, axis=1)\n","\n","train_data_unnormalized = train_data_df.to_numpy()\n","train_labels_unnormalized = train_labels_df.to_numpy()\n","\n","val_data_unnormalized = val_data_df.to_numpy()\n","val_labels_unnormalized = val_labels_df.to_numpy()\n","\n","test_data_unnormalized = test_data_df.to_numpy()\n","test_labels_unnormalized = test_labels_df.to_numpy()\n","\n","# normalize the data using minmax \n","minmax = MinMaxScaler() \n","\n","train_data = minmax.fit_transform(train_data_unnormalized)\n","train_label_temp = np.expand_dims(train_labels_unnormalized, axis=1)\n","train_labels = minmax.fit_transform(train_label_temp)\n","\n","val_data = minmax.fit_transform(val_data_unnormalized)\n","val_label_temp = np.expand_dims(val_labels_unnormalized, axis=1)\n","val_labels = minmax.fit_transform(val_label_temp)\n","\n","test_data = minmax.fit_transform(test_data_unnormalized)\n","test_label_temp = np.expand_dims(test_labels_unnormalized, axis=1)\n","test_labels = minmax.fit_transform(test_label_temp)\n","\n","\n","print('Training data shape \\n', train_data.shape)\n","print('Training labels shape \\n', train_labels.shape)\n","#print('Training data \\n ', train_data)\n","#print('Training labels \\n ', train_labels)\n","\n","print('Validation data shape \\n ',val_data.shape)\n","print('Validation labels shape \\n ', val_labels.shape)\n","#print('Validation data \\n ', val_data)\n","#print('Validation labels \\n ', val_labels)\n","\n","print('Test data shape \\n ', test_data.shape)\n","print('Test labels shape \\n ', test_labels.shape)\n","#print('Test data \\n ', test_data)\n","#print('Test labels \\n ', test_labels)# load the california housing data from csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f6Vl_ZBw7aXW","executionInfo":{"status":"ok","timestamp":1646558004810,"user_tz":-60,"elapsed":10,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"3e714705-82f6-4fad-f688-28bd178da72c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value']\n","Training data shape \n"," (12750, 8)\n","Training labels shape \n"," (12750, 1)\n","Validation data shape \n","  (4250, 8)\n","Validation labels shape \n","  (4250, 1)\n","Test data shape \n","  (3000, 8)\n","Test labels shape \n","  (3000, 1)\n"]}]},{"cell_type":"markdown","source":["## Keras uncertainty specific imports "],"metadata":{"id":"dUPhpa_L7jEc"}},{"cell_type":"code","source":["import numpy as np \n","import tensorflow as tf \n","from tensorflow.keras.models import load_model\n","import random\n","import pandas as pd\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","import math \n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Input\n","\n","import keras_uncertainty\n","#from keras_uncertainty.models import StochasticRegressor, TwoHeadStochasticRegressor\n","#from keras_uncertainty.models.DeepEnsembleClassifier import DeepEnsemble\n","\n","#from keras_uncertainty.layers import DropConnectDense, VariationalDense, FlipoutDense, StochasticDropout\n","from keras_uncertainty.metrics import gaussian_interval_score\n","from keras_uncertainty.losses import regression_gaussian_nll_loss, regression_gaussian_beta_nll_loss\n","import matplotlib.pyplot as plt\n","\n","np.set_printoptions(suppress=True) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ulceu5Q7lF3","executionInfo":{"status":"ok","timestamp":1646558005249,"user_tz":-60,"elapsed":446,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"853040bd-402d-40bb-b231-ef4ee70946b7"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Keras Uncertainty will use standalone Keras backend"]}]},{"cell_type":"markdown","source":["## FlipoutModel"],"metadata":{"id":"1o60YVXmn5EX"}},{"cell_type":"code","source":["import numpy as np\n","import keras_uncertainty.backend as K\n","Layer = K.layers.Layer\n","activations = K.activations\n","initializers = K.initializers\n","\n","from keras_uncertainty.distributions import gaussian, rademacher\n","\n","# Code partially based on http://krasserm.github.io/2019/03/14/bayesian-neural-networks/\n","\n","class FlipoutDense(Layer):\n","    def __init__(self,\n","                 units,\n","                 kl_weight,\n","                 activation=None,\n","                 initializer_sigma=0.1,\n","                 prior=True,\n","                 prior_sigma_1=1.5,\n","                 prior_sigma_2=0.1,\n","                 prior_pi=0.5,\n","                 bias_distribution=False,\n","                  **kwargs):\n","        self.units = units\n","        self.kl_weight = kl_weight\n","        self.activation = activations.get(activation)\n","        self.prior = prior\n","        self.prior_sigma_1 = prior_sigma_1\n","        self.prior_sigma_2 = prior_sigma_2\n","        print('PRIOR_PI_1 ', prior_pi)\n","        self.prior_pi_1 = prior_pi\n","        print('PRIOR_PI_1 ', self.prior_pi_1)\n","        self.prior_pi_2 = 1.0 - prior_pi\n","        self.initializer_sigma = initializer_sigma\n","        self.uses_learning_phase = True\n","        self.bias_distribution = bias_distribution\n","\n","        super().__init__(**kwargs)\n","\n","    def compute_output_shape(self, input_shape):\n","        return [(None, self.units)]\n","\n","    def build(self, input_shape):\n","        self.kernel_mu = self.add_weight(name='kernel_mu',\n","                                         shape=(input_shape[1], self.units),\n","                                         initializer=initializers.normal(stddev=self.initializer_sigma),\n","                                         trainable=True)\n","        \n","        self.kernel_rho = self.add_weight(name='kernel_rho',\n","                                          shape=(input_shape[1], self.units),\n","                                          initializer=initializers.normal(mean=-3.0, stddev=self.initializer_sigma),\n","                                          trainable=True)\n","\n","        self.bias_mu = self.add_weight(name='bias_mu',\n","                                       shape=(self.units,),\n","                                       initializer=initializers.normal(stddev=self.initializer_sigma),\n","                                       trainable=True)\n","\n","        self.bias_rho = self.add_weight(name='bias_rho',\n","                                        shape=(self.units,),\n","                                        initializer=initializers.normal(mean=-3.0, stddev=self.initializer_sigma),\n","                                        trainable=self.bias_distribution)\n","        super().build(input_shape)\n","\n","    def call(self, inputs, **kwargs):\n","        kernel_sigma = K.softplus(self.kernel_rho)\n","        kernel_perturb = kernel_sigma * K.random_normal(self.kernel_mu.shape)\n","        kernel = self.kernel_mu + kernel_perturb\n","\n","        if self.bias_distribution:\n","            bias_sigma = K.softplus(self.bias_rho)\n","            bias = self.bias_mu + bias_sigma * K.random_normal(self.bias_mu.shape)\n","        else:\n","            bias = self.bias_mu\n","\n","        loss = self.kl_loss(kernel, self.kernel_mu, kernel_sigma)\n","\n","        if self.bias_distribution:\n","            loss += self.kl_loss(bias, self.bias_mu, bias_sigma)\n","\n","        self.add_loss(K.in_train_phase(loss, 0.0))\n","\n","        input_shape = K.shape(inputs)\n","        batch_shape = input_shape[:-1]\n","        sign_input = rademacher.sample(input_shape)\n","        sign_output = rademacher.sample(K.concatenate([batch_shape, K.expand_dims(self.units, 0)], axis=0))\n","        perturbed_inputs = K.dot(inputs * sign_input, kernel_perturb) * sign_output\n","\n","        outputs = K.dot(inputs, self.kernel_mu)\n","        outputs += perturbed_inputs\n","        outputs += bias\n","\n","        # This always produces stochastic outputs\n","        return self.activation(outputs)\n","\n","    def kl_loss(self, w, mu, sigma):\n","        return self.kl_weight * K.mean(gaussian.log_probability(w, mu, sigma) - self.prior * self.log_prior_prob(w))\n","\n","    def log_prior_prob(self, w):\n","        return K.log(self.prior_pi_1 * gaussian.probability(w, 0.0, self.prior_sigma_1) +\n","                     self.prior_pi_2 * gaussian.probability(w, 0.0, self.prior_sigma_2))\n","\n","    def get_config(self):\n","        config = {'units': self.units,\n","                  'kl_weight': self.kl_weight,\n","                  'activation': self.activation.__name__,\n","                  #'bias': self.bias,\n","                  'prior': self.prior,\n","                  'prior_sigma_1': self.prior_sigma_1,\n","                  'prior_sigma_2': self.prior_sigma_2,\n","                  'prior_pi_1': self.prior_pi_1}\n","        base_config = super(FlipoutDense, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"metadata":{"id":"WO7iEYW0oBrU","executionInfo":{"status":"ok","timestamp":1646558005250,"user_tz":-60,"elapsed":42,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## StochasticRegressor"],"metadata":{"id":"k_7kfwlkoI1A"}},{"cell_type":"code","source":["import numpy as np\n","import keras_uncertainty.backend as K\n","\n","class StochasticModel:\n","    \"\"\"\n","        Stochastic model, requiring several forward passes to produce an estimate of the posterior predictive distribution.\n","        This class just wraps a keras model to enable dropout at inference time.\n","    \"\"\"\n","    def __init__(self, model, num_samples=10):\n","        \"\"\"\n","            Builds a stochastic model from a keras model. The model should already be trained.\n","        \"\"\"\n","        self.model = model\n","        self.num_samples = num_samples\n","    \n","    def predict_samples(self, x, num_samples=None, batch_size=32, multi_output=False, **kwargs):\n","        \"\"\"\n","            Performs num_samples predictions using the model, and returns the produced output samples.\n","        \"\"\"\n","\n","        if num_samples is None:\n","            num_samples = self.num_samples\n","\n","        assert num_samples > 0\n","        samples = [None] * num_samples\n","\n","        if \"verbose\" not in kwargs:\n","            kwargs[\"verbose\"] = 0\n","\n","        for i in range(num_samples):\n","            samples[i] = self.model.predict(x, batch_size=1, **kwargs)\n","\n","        if multi_output:\n","            return samples\n","        else:\n","            return np.array(samples)\n","\n","class  StochasticRegressor(StochasticModel):\n","    def __init__(self, model, num_samples=10):\n","        super().__init__(model, num_samples)\n","\n","    def predict(self, inp, num_samples=None, batch_size=32, output_scaler=None, **kwargs):\n","        \"\"\"\n","            Performs a prediction  given input inp using MC Dropout, and returns the mean and standard deviation of the model output.\n","        \"\"\"\n","        samples = self.predict_samples(inp, num_samples, batch_size=batch_size, **kwargs)\n","\n","        if output_scaler is not None:\n","            samples = list(map(lambda x: output_scaler.inverse_transform(x), samples))\n","\n","        mean_pred = np.mean(samples, axis=0)\n","        std_pred = np.std(samples, axis=0)\n","\n","        return mean_pred, std_pred    "],"metadata":{"id":"BNf6zM6toGaW","executionInfo":{"status":"ok","timestamp":1646558005251,"user_tz":-60,"elapsed":41,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Load the saved model"],"metadata":{"id":"91-rBF-Yo2V9"}},{"cell_type":"code","source":["# error if the custom object containing the stochastic dropout model not passed (Unknown layer: StochasticDropout. Please ensure this object is passed to the `custom_objects` argument)\n","\n","import os\n","\n","dir_name = '/content/drive/MyDrive/MasterThesis/CaliforniaHousingDatasetTests/GBP_explanation/flipout/'\n","test = os.listdir(dir_name)\n","\n","for item in test:\n","    if item.endswith('.h5'):\n","        print('model name : ', item)\n","        \n","        #model_file = '/content/drive/MyDrive/MasterThesis/CaliforniaHousingDatasetTests/GBP_explanation/flipout/'+item\n","        #model.load_weight(model_file)\n","        model = tf.keras.models.load_model('/content/drive/MyDrive/MasterThesis/CaliforniaHousingDatasetTests/GBP_explanation/flipout/'+item,\n","                                           custom_objects={'FlipoutDense':FlipoutDense})\n","#this model has been trained on the chd_regression_training notebook\n","#model = tf.keras.models.load_model('/content/drive/MyDrive/MasterThesis/CaliforniaHousingDatasetTests/training/results/dropout/model.h5', custom_objects={'StochasticDropout':StochasticDropout}) \n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"ehBlFMHJo3zV","executionInfo":{"status":"error","timestamp":1646558006049,"user_tz":-60,"elapsed":808,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"3635027c-19d3-444e-cf8d-b6ca92b5f4c6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["model name :  flipout_model_epochs_2_num_samples_5.h5\n","PRIOR_PI_1  0.5\n","PRIOR_PI_1  0.5\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-1a4485bb5a7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#model.load_weight(model_file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         model = tf.keras.models.load_model('/content/drive/MyDrive/MasterThesis/CaliforniaHousingDatasetTests/GBP_explanation/flipout/'+item,\n\u001b[0;32m---> 15\u001b[0;31m                                            custom_objects={'FlipoutDense':FlipoutDense})\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#this model has been trained on the chd_regression_training notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#model = tf.keras.models.load_model('/content/drive/MyDrive/MasterThesis/CaliforniaHousingDatasetTests/training/results/dropout/model.h5', custom_objects={'StochasticDropout':StochasticDropout})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-2e02450a7901>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, kl_weight, activation, initializer_sigma, prior, prior_sigma_1, prior_sigma_2, prior_pi, bias_distribution, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbias_distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'prior_pi_1')"]}]},{"cell_type":"markdown","source":["## Ground Truth vs prediction plot"],"metadata":{"id":"1gIsZI7BpAdW"}},{"cell_type":"code","source":["# Analysis of the input \n","num_of_samples_to_be_explained = 1\n","start_index = np.random.randint(0, test_data.shape[0])\n","print('start_index : ', start_index)\n","\n","test_input = test_data[start_index:start_index+num_of_samples_to_be_explained]\n","print('test_input shape :', test_input.shape)\n","\n","test_input_adj = np.expand_dims(test_input, axis=-1)\n","print('test_input_adj shape :', test_input_adj.shape)\n","\n","# MODEL PREDICTION AND PLOTTING \n","dropout_model = StochasticRegressor(model)\n","pred_samples, pred_mean, pred_std = dropout_model.predict_output(test_data, num_samples=5)\n","print(pred_samples.shape)\n","print(pred_mean.shape)\n","print(pred_std.shape)"],"metadata":{"id":"etwNoQ_tpCO_","executionInfo":{"status":"aborted","timestamp":1646558006047,"user_tz":-60,"elapsed":255,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}}},"execution_count":null,"outputs":[]}]}