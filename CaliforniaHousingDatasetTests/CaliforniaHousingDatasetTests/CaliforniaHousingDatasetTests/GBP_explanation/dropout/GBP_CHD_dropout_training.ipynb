{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWWXrj_jkvbd"
   },
   "source": [
    "## Mount the drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24123,
     "status": "ok",
     "timestamp": 1646558021178,
     "user": {
      "displayName": "Mihir Mulye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64",
      "userId": "03370256418408681216"
     },
     "user_tz": -60
    },
    "id": "HGYW33I2A8df",
    "outputId": "ffec26b1-3e64-47e3-a178-2ca93e17b1aa"
   },
   "outputs": [],
   "source": [
    "# mount the drive\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-f300Ml2rtc"
   },
   "source": [
    "## Removing previous trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1852,
     "status": "ok",
     "timestamp": 1646558022992,
     "user": {
      "displayName": "Mihir Mulye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64",
      "userId": "03370256418408681216"
     },
     "user_tz": -60
    },
    "id": "HcoPc_uJ3EJi",
    "outputId": "20383798-a0e9-43be-bc3d-0d03e6d49711"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#dir_name = '/content/drive/MyDrive/MasterThesis/CaliforniaHousingDatasetTests/GBP_explanation/dropout/'\n",
    "#test = os.listdir(dir_name)\n",
    "\n",
    "#for item in test:\n",
    "#    if item.endswith('.h5'):\n",
    "#        print(f'deleting {item}')\n",
    "#        os.remove(os.path.join(dir_name, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSVaATowkxp8"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9ynE8tQxE8OQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Mihir\\MT\\Code\\CaliforniaHousingDatasetTests\\CaliforniaHousingDatasetTests\n",
      "D:\\Mihir\\MT\\Code\\CaliforniaHousingDatasetTests\\CaliforniaHousingDatasetTests\\GBP_explanation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time \n",
    "\n",
    "start = time.time()\n",
    "os.listdir(os.getcwd())\n",
    "\n",
    "print(os.path.dirname(os.path.dirname(os.getcwd()))) # much complication\n",
    "print(os.path.dirname(os.getcwd()))\n",
    "\n",
    "path_to_train_file = \"D:\\Mihir\\MT\\Code\\CaliforniaHousingDatasetTests\\california_housing_train.csv\"\n",
    "path_to_test_file = \"D:\\Mihir\\MT\\Code\\CaliforniaHousingDatasetTests\\california_housing_test.csv\"\n",
    "\n",
    "#path_to_keras_uncertainty = \"D:\\Mihir\\MT\\Code\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jc6abzHCapU-"
   },
   "source": [
    "## Installing keras uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6072,
     "status": "ok",
     "timestamp": 1646558031708,
     "user": {
      "displayName": "Mihir Mulye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64",
      "userId": "03370256418408681216"
     },
     "user_tz": -60
    },
    "id": "qR8N7da9arUg",
    "outputId": "b9ad7cbd-435f-45a4-a2b8-33b6ea4c860d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/mvaldenegro/keras-uncertainty.git\n",
      "  Cloning https://github.com/mvaldenegro/keras-uncertainty.git to c:\\users\\ashay\\appdata\\local\\temp\\pip-req-build-yl6ef6rw\n",
      "[WinError 2] The system cannot find the file specified: 'keras-uncertainty'\n",
      "D:\\Mihir\\MT\\Code\\CaliforniaHousingDatasetTests\\CaliforniaHousingDatasetTests\\GBP_explanation\\dropout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/mvaldenegro/keras-uncertainty.git 'C:\\Users\\ashay\\AppData\\Local\\Temp\\pip-req-build-yl6ef6rw'\n",
      "  ERROR: Error [WinError 2] The system cannot find the file specified while executing command git clone -q https://github.com/mvaldenegro/keras-uncertainty.git 'C:\\Users\\ashay\\AppData\\Local\\Temp\\pip-req-build-yl6ef6rw'\n",
      "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
     ]
    }
   ],
   "source": [
    "# keras_uncertainty imports \n",
    "# clone and install this library \n",
    "\n",
    "#!git clone https://github.com/mvaldenegro/keras-uncertainty.git\n",
    "!pip install --user git+https://github.com/mvaldenegro/keras-uncertainty.git\n",
    "\n",
    "%cd keras-uncertainty\n",
    "\n",
    "\n",
    "#WOULD NEED TO SETUP GIT ON THE MACHINE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45EapTjba3OU"
   },
   "source": [
    "## Keras uncertainty specific imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1646558031709,
     "user": {
      "displayName": "Mihir Mulye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64",
      "userId": "03370256418408681216"
     },
     "user_tz": -60
    },
    "id": "c16kKgiVa6bS",
    "outputId": "62857680-e8fc-4e36-f821-717e7b819dc1"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_uncertainty'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e82fac36915a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_uncertainty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m#from keras_uncertainty.models import StochasticRegressor, TwoHeadStochasticRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#from keras_uncertainty.models.DeepEnsembleClassifier import DeepEnsemble\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_uncertainty'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "import pandas as pd \n",
    "import os \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "import keras_uncertainty\n",
    "#from keras_uncertainty.models import StochasticRegressor, TwoHeadStochasticRegressor\n",
    "#from keras_uncertainty.models.DeepEnsembleClassifier import DeepEnsemble\n",
    "\n",
    "#from keras_uncertainty.layers import DropConnectDense, VariationalDense, FlipoutDense, StochasticDropout\n",
    "from keras_uncertainty.metrics import gaussian_interval_score\n",
    "from keras_uncertainty.losses import regression_gaussian_nll_loss, regression_gaussian_beta_nll_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True) \n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.test.is_gpu_available())\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "print('TF VERSION ', tf.__version__)\n",
    "\n",
    "# 28022022 the code works without disabling the eager execution (dont know why) \n",
    "\n",
    "# if eager execution is not disabled following error occurs:\n",
    "# TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), \n",
    "#dtype=tf.float32, name=None), name='Placeholder:0', description=\"created \n",
    "#by layer 'tf.cast_4'\"), an intermediate Keras symbolic input/output, \n",
    "#to a TF API that does not allow registering custom dispatchers, \n",
    "#such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. \n",
    "#Keras Functional model construction only supports TF API calls that \n",
    "#*do* support dispatching, such as `tf.math.add` or `tf.reshape`. \n",
    "#Other APIs cannot be called directly on symbolic Kerasinputs/outputs. \n",
    "#You can work around this limitation by putting the operation in a custom \n",
    "#Keras layer `call` and calling that layer on this symbolic input/output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01aye9sKkzKF"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1646558031710,
     "user": {
      "displayName": "Mihir Mulye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64",
      "userId": "03370256418408681216"
     },
     "user_tz": -60
    },
    "id": "WsqA5_aYEv4h",
    "outputId": "20129e20-c558-47ee-e022-c7e008e31c39"
   },
   "outputs": [],
   "source": [
    "# load the california housing data from csv\n",
    "#train_file = '/content/sample_data/california_housing_train.csv'\n",
    "#test_file = '/content/sample_data/california_housing_test.csv'\n",
    "\n",
    "train_file = path_to_train_file \n",
    "test_file = path_to_test_file \n",
    "\n",
    "train_combined = pd.read_csv(train_file)\n",
    "test = pd.read_csv(test_file)\n",
    "\n",
    "# split the data in validation and test (from test.csv)\n",
    "train, val = train_test_split(train_combined, test_size=0.25)\n",
    "\n",
    "feature_names = list(train_combined.columns)\n",
    "print(feature_names)\n",
    "\n",
    "# assign the target variable\n",
    "target = 'median_house_value'\n",
    "\n",
    "# extract the target label in all sets\n",
    "train_labels_df= train[target]\n",
    "val_labels_df = val[target]\n",
    "test_labels_df = test[target]\n",
    "\n",
    "# extract the data from all sets \n",
    "train_data_df = train.drop(columns=target, axis=1)\n",
    "val_data_df = val.drop(columns=target, axis=1)\n",
    "test_data_df = test.drop(columns=target, axis=1)\n",
    "\n",
    "train_data_unnormalized = train_data_df.to_numpy()\n",
    "train_labels_unnormalized = train_labels_df.to_numpy()\n",
    "\n",
    "val_data_unnormalized = val_data_df.to_numpy()\n",
    "val_labels_unnormalized = val_labels_df.to_numpy()\n",
    "\n",
    "test_data_unnormalized = test_data_df.to_numpy()\n",
    "test_labels_unnormalized = test_labels_df.to_numpy()\n",
    "\n",
    "# normalize the data using minmax \n",
    "minmax = MinMaxScaler() \n",
    "\n",
    "train_data = minmax.fit_transform(train_data_unnormalized)\n",
    "train_label_temp = np.expand_dims(train_labels_unnormalized, axis=1)\n",
    "train_labels = minmax.fit_transform(train_label_temp)\n",
    "\n",
    "val_data = minmax.fit_transform(val_data_unnormalized)\n",
    "val_label_temp = np.expand_dims(val_labels_unnormalized, axis=1)\n",
    "val_labels = minmax.fit_transform(val_label_temp)\n",
    "\n",
    "test_data = minmax.fit_transform(test_data_unnormalized)\n",
    "test_label_temp = np.expand_dims(test_labels_unnormalized, axis=1)\n",
    "test_labels = minmax.fit_transform(test_label_temp)\n",
    "\n",
    "\n",
    "print('Training data shape \\n', train_data.shape)\n",
    "print('Training labels shape \\n', train_labels.shape)\n",
    "#print('Training data \\n ', train_data)\n",
    "#print('Training labels \\n ', train_labels)\n",
    "\n",
    "print('Validation data shape \\n ',val_data.shape)\n",
    "print('Validation labels shape \\n ', val_labels.shape)\n",
    "#print('Validation data \\n ', val_data)\n",
    "#print('Validation labels \\n ', val_labels)\n",
    "\n",
    "print('Test data shape \\n ', test_data.shape)\n",
    "print('Test labels shape \\n ', test_labels.shape)\n",
    "#print('Test data \\n ', test_data)\n",
    "#print('Test labels \\n ', test_labels)# load the california housing data from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSzth4lRjG7O"
   },
   "source": [
    "## StochasticModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6GPH8WfjKtD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras_uncertainty.backend as K\n",
    "Layer = K.layers.Layer\n",
    "Dropout = K.layers.Dropout\n",
    "\n",
    "\n",
    "class StochasticDropout(Dropout):\n",
    "    \"\"\"\n",
    "        Applies Dropout to the input, independent of the training phase.\n",
    "        Used to easily implement MC-Dropout. It is a drop-in replacement for\n",
    "        the standard Keras Dropout layer, but note that this layer applies\n",
    "        dropout at the training and inference phases.\n",
    "    \"\"\"\n",
    "    def __init__(self, rate, noise_shape=None, seed=None, **kwargs):\n",
    "        super(StochasticDropout, self).__init__(rate, noise_shape, seed, **kwargs)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "\n",
    "            return K.dropout(inputs, self.rate, noise_shape, seed=self.seed)\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        # this code is added so that the model can be saved even after making use of a custom layer \n",
    "        # https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object\n",
    "        config = super(StochasticDropout, self).get_config()\n",
    "        config.update({'rate': self.rate})\n",
    "        return config\n",
    "\n",
    "\n",
    "class StochasticModel:\n",
    "    \"\"\"\n",
    "        Stochastic model, requiring several forward passes to produce an estimate of the posterior predictive distribution.\n",
    "        This class just wraps a keras model to enable dropout at inference time.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, num_samples=10, **kwargs):\n",
    "        \"\"\"\n",
    "            Builds a stochastic model from a keras model. The model should already be trained.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.num_samples = num_samples\n",
    "    \n",
    "    def predict_samples(self, x, num_samples=None, batch_size=32, multi_output=False, **kwargs):\n",
    "        \"\"\"\n",
    "            Performs num_samples predictions using the model, and returns the produced output samples.\n",
    "        \"\"\"\n",
    "\n",
    "        if num_samples is None:\n",
    "            num_samples = self.num_samples\n",
    "\n",
    "        assert num_samples > 0\n",
    "        samples = [None] * num_samples\n",
    "\n",
    "        if \"verbose\" not in kwargs:\n",
    "            kwargs[\"verbose\"] = 0\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            samples[i] = self.model.predict(x, batch_size=1, **kwargs)\n",
    "\n",
    "        if multi_output:\n",
    "            return samples\n",
    "        else:\n",
    "            return np.array(samples)\n",
    "            \n",
    "            \n",
    "class  StochasticRegressor(StochasticModel):\n",
    "    def __init__(self, model, num_samples=10, **kwargs):\n",
    "        # https://stackoverflow.com/questions/62280161/saving-keras-models-with-custom-layers\n",
    "        super().__init__(model, num_samples)\n",
    "        self.input = self.model.input\n",
    "        self.output = self.model.output\n",
    "\n",
    "    def predict_output(self, inp, num_samples=None, batch_size=32, output_scaler=None, **kwargs):\n",
    "        \"\"\"\n",
    "            Performs a prediction  given input inp using MC Dropout, and returns the mean and standard deviation of the model output.\n",
    "        \"\"\"\n",
    "        samples = self.predict_samples(inp, num_samples, batch_size=batch_size, **kwargs)\n",
    "\n",
    "        if output_scaler is not None:\n",
    "            samples = list(map(lambda x: output_scaler.inverse_transform(x), samples))\n",
    "\n",
    "        mean_pred = np.mean(samples, axis=0)\n",
    "        std_pred = np.std(samples, axis=0)\n",
    "\n",
    "        return samples, mean_pred, std_pred \n",
    "\n",
    "    def save(self, path):\n",
    "        # stochaticmodel class does not have basic tf function like save(), summary(), get_layer() and so on \n",
    "        # https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object\n",
    "        self.model.save(path)\n",
    "\n",
    "    def summary(self):\n",
    "        return self.model.summary()  \n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        return self.model.evaluate(test_data)\n",
    "\n",
    "    def get_layer(self, name=None, index=None):\n",
    "        # the get_layer() has been taken from ths following source \n",
    "        # https://github.com/keras-team/keras/blob/v2.8.0/keras/engine/training.py#L2797-L2831\n",
    "    \n",
    "        \"\"\"Retrieves a layer based on either its name (unique) or index.\n",
    "        If `name` and `index` are both provided, `index` will take precedence.\n",
    "        Indices are based on order of horizontal graph traversal (bottom-up).\n",
    "        Args:\n",
    "            name: String, name of layer.\n",
    "            index: Integer, index of layer.\n",
    "        Returns:\n",
    "            A layer instance.\n",
    "        \"\"\"\n",
    "        # TODO(fchollet): We could build a dictionary based on layer names\n",
    "        # since they are constant, but we have not done that yet.\n",
    "        if index is not None and name is not None:\n",
    "            raise ValueError('Provide only a layer name or a layer index. Received: '\n",
    "                        f'index={index}, name={name}.')\n",
    "\n",
    "        if index is not None:\n",
    "            if len(self.layers) <= index:\n",
    "                raise ValueError(f'Was asked to retrieve layer at index {index}'\n",
    "                            f' but model only has {len(self.layers)}'\n",
    "                            ' layers.')\n",
    "            else:\n",
    "                return self.model.layers[index]\n",
    "\n",
    "        if name is not None:\n",
    "            for layer in self.model.layers:\n",
    "                if layer.name == name:\n",
    "                    return layer\n",
    "            raise ValueError(f'No such layer: {name}. Existing layers are: '\n",
    "                        f'{list(layer.name for layer in self.model.layers)}.')\n",
    "        raise ValueError('Provide either a layer name or layer index at '\n",
    "                     '`get_layer`.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztKTiRtSk18m"
   },
   "source": [
    "## Define Dropout model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 118750,
     "status": "ok",
     "timestamp": 1646558150819,
     "user": {
      "displayName": "Mihir Mulye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64",
      "userId": "03370256418408681216"
     },
     "user_tz": -60
    },
    "id": "s-S4V_Mr_nS6",
    "outputId": "5b7c956a-75b9-453e-afa0-a2b173254f01"
   },
   "outputs": [],
   "source": [
    "# DROPOUT MODEL\n",
    "def train_dropout_model(x_train, y_train, x_val, y_val, x_test, epochs, num_samples, prob):\n",
    "    #obtained from hyperparameter optimization\n",
    "    K.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(8, )))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(StochasticDropout(prob))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(StochasticDropout(prob))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='sgd', metrics=['mae'])\n",
    "\n",
    "    # train a model with stochasticdropout() layer\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_val, y_val), verbose=2, epochs=epochs)\n",
    "    #saving the model that has custom layers\n",
    "    #model.save('/content/drive/MyDrive/MasterThesis/CaliforniaHousingDatasetTests/GBP_explanation/dropout/dropout_model_epochs_'+str(epochs)+'_num_samples_'+str(num_samples)+'.h5') \n",
    "    model.summary()\n",
    "\n",
    "    # plotting the training and validation curves\n",
    "    plt.plot(history.history['loss'], label='train loss')\n",
    "    plt.plot(history.history['val_loss'], label='val loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('loss curves')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['mae'], label='train mae')\n",
    "    plt.plot(history.history['val_mae'], label='val mae')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('mae')\n",
    "    plt.title('mae curves')\n",
    "    plt.show()\n",
    "\n",
    "    # call the stochasticregressor class and pass the trained model that contains the stochasticdropout layer \n",
    "    mc_model = StochasticRegressor(model)\n",
    "    pred_samples, pred_mean, pred_std = mc_model.predict_output(x_test, num_samples=num_samples)\n",
    "    print('pred_samples shape ', pred_samples.shape)\n",
    "    print('pred_mean shape ', pred_mean.shape)\n",
    "    print('pred_std shape ', pred_std.shape)\n",
    "\n",
    "    # return the predicted_samples, predicted_mean, predicted_std and model \n",
    "    return pred_samples, pred_mean, pred_std, mc_model\n",
    "\n",
    "\n",
    "epochs=100\n",
    "num_samples=20\n",
    "prob=0.1\n",
    "# running this command creates the stochastic dropout model, trains it and generates the predicted_samples, predicted_mean and predicted_std for the test set (all 3000 examples)\n",
    "prediction_samples, prediction_mean, prediction_std, dropout_model = train_dropout_model(train_data, train_labels, val_data, val_labels, test_data, epochs=epochs, num_samples=num_samples, prob=prob)\n",
    "print('prediction mean :\\n', prediction_mean)\n",
    "print('prediction mean shape ', prediction_mean.shape)\n",
    "print('prediction std :\\n', prediction_std)\n",
    "print('prediction std shape ', prediction_std.shape)\n",
    "print('prediction samples :\\n', prediction_samples)\n",
    "print('prediction samples shape ', prediction_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38117,
     "status": "ok",
     "timestamp": 1646558188901,
     "user": {
      "displayName": "Mihir Mulye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64",
      "userId": "03370256418408681216"
     },
     "user_tz": -60
    },
    "id": "9IWPSUxNeoyq",
    "outputId": "bfbb934a-0a1f-484a-b6a5-62b9468f7ce0"
   },
   "outputs": [],
   "source": [
    "# Analysis of the input \n",
    "num_of_samples_to_be_explained = 1\n",
    "start_index = np.random.randint(0, test_data.shape[0])\n",
    "print('start_index : ', start_index)\n",
    "\n",
    "test_input = test_data[start_index:start_index+num_of_samples_to_be_explained]\n",
    "print('test_input shape :', test_input.shape)\n",
    "\n",
    "test_input_adj = np.expand_dims(test_input, axis=-1)\n",
    "print('test_input_adj shape :', test_input_adj.shape)\n",
    "\n",
    "pred_samples, pred_mean, pred_std = dropout_model.predict_output(test_data)\n",
    "print(pred_samples.shape) \n",
    "print(pred_mean.shape)\n",
    "print(pred_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 2303,
     "status": "ok",
     "timestamp": 1646558191180,
     "user": {
      "displayName": "Mihir Mulye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64",
      "userId": "03370256418408681216"
     },
     "user_tz": -60
    },
    "id": "BhK3lqmF8zYw",
    "outputId": "e4530957-bbd7-4361-96bf-fb58e2d1007b"
   },
   "outputs": [],
   "source": [
    "# function to visualize the ground truth with the predicted value and (corridor of uncertainty)\n",
    "\n",
    "def plot(ground_truth, prediction_mean, prediction_std, path, indices_to_be_plotted):\n",
    "    plt.figure(figsize=(30, 4))\n",
    "    plt.plot(range(ground_truth.shape[0]),  ground_truth, color='k', label='ground truth', marker='o')\n",
    "    plt.plot(range(ground_truth.shape[0]), prediction_mean, color='r', label='prediction', marker='o')\n",
    "   \n",
    "    y_pred_mean = prediction_mean.reshape((-1,))\n",
    "    y_pred_std = prediction_std.reshape((-1,))\n",
    "    y_pred_up_1 = y_pred_mean + y_pred_std\n",
    "    y_pred_down_1 = y_pred_mean - y_pred_std\n",
    "\n",
    "    plt.fill_between(range(ground_truth.shape[0]), y_pred_down_1, y_pred_up_1, color=(0, 0, 0.9, 0.7), label='corridor of uncertainty ($\\pm$ 1 $\\sigma$) ', alpha=0.5)\n",
    "    #plt.plot(range(ground_truth.shape[0]), y_pred_mean, '.', color=(0, 0.9, 0.0, 0.8), markersize=0.2, label='Mean')\n",
    "\n",
    "    #plt.set_title('{}\\nInterval Score: {:.2f}'.format(key, score))\n",
    "    #plt.set_ylim([-20.0, 20.0])\n",
    "\n",
    "    #plt.axvline(x=-4.0, color='black', linestyle='dashed')\n",
    "    #plt.axvline(x= 4.0, color='black', linestyle='dashed')\n",
    "    #plt.get_xaxis().set_ticks([])\n",
    "    #plt.get_yaxis().set_ticks([])    \n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xticks(range(len(indices_to_be_plotted)), indices_to_be_plotted, rotation=45)\n",
    "    plt.xlabel('Input sample #')\n",
    "    plt.ylabel('Target Variable (normalized)')\n",
    "    plt.title('Ground Truth and Dropout Model Prediction')\n",
    "    plt.savefig(path)\n",
    "    plt.show()\n",
    "\n",
    "start_index = np.random.randint(test_data.shape[0]-150)\n",
    "random = range(start_index, start_index+100)\n",
    "print('indices to be plotted \\n', random)\n",
    "test_labels_plot= np.asarray([float(test_labels[i]) for i in random])\n",
    "mean_dropout_plot = np.asarray([float(pred_mean[i]) for i in random])\n",
    "std_dropout_plot = np.asarray([float(pred_std[i]) for i in random])\n",
    "\n",
    "#plot(test_labels_plot, mean_dropout_plot, std_dropout_plot, '/content/drive/MyDrive/MasterThesis/CaliforniaHousingDatasetTests/GBP_explanation/dropout/output_plots/dropout_gt_vs_prediction.pdf', random)\n",
    "plot(test_labels_plot, mean_dropout_plot, std_dropout_plot, 'D:\\Mihir\\MT\\Code\\CaliforniaHousingDatasetTests\\CaliforniaHousingDatasetTests\\GBP_explanation/dropout_gt_vs_prediction.pdf', random)\n",
    "\n",
    "end = time.time()\n",
    "print('total time to run the train notebook : ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1646558191182,
     "user": {
      "displayName": "Mihir Mulye",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64",
      "userId": "03370256418408681216"
     },
     "user_tz": -60
    },
    "id": "SLWI8zpSBZ5-",
    "outputId": "896d5611-3214-41f8-8a45-0c50d7e7bd7e"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "##TOY CODE to test the plotting of custom horizontal bar chart \n",
    "#reference for this code below : \n",
    "# https://matplotlib.org/stable/gallery/lines_bars_and_markers/barh.htmlimport matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "plt.figure(figsize=(25,10))\n",
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Example data\n",
    "people = ['Tom', 'Dick', 'Harry', 'Slim', 'Jim']\n",
    "y_pos = np.arange(1, len(people)+1)\n",
    "\n",
    "error = np.random.rand(len(people))\n",
    "performance = 3 + 10 * error\n",
    "\n",
    "print(y_pos)\n",
    "print(people)\n",
    "print(performance)\n",
    "print(error)\n",
    "\n",
    "\n",
    "a = ax.barh(y_pos, performance, xerr=error, align='center', label='performance')\n",
    "\n",
    "for i in range(len(a)):\n",
    "    print(a[i])\n",
    "\n",
    "ax.set_yticks([1, 2, 3, 4, 5])\n",
    "ax.set_yticklabels(labels=['Tom', 'Dick', 'Harry', 'Slim', 'Jim'])\n",
    "\n",
    "labels = ['performance', 'error']\n",
    "colors = ['C0', 'k']\n",
    "legend_colors = list(set(colors))\n",
    "print(legend_colors)\n",
    "\n",
    "error = plt.plot([], label='error', linestyle='-', color='k')\n",
    "performance = plt.Rectangle((0,0),1,1, color='C0')\n",
    "\n",
    "# Create a legend for the first line.\n",
    "first_legend = plt.legend(handles=error)\n",
    "\n",
    "# Add the legend manually to the current Axes. (https://matplotlib.org/2.0.2/users/legend_guide.html)\n",
    "\n",
    "#ax.invert_yaxis()  # labels read top-to-bottom  \n",
    "ax.set_xlabel('Performance') \n",
    "ax.set_title('How fast do you want to go today?')\n",
    "plt.grid(alpha=0.2)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#reference for generating a custom legend \n",
    "# https://matplotlib.org/2.0.2/users/legend_guide.html\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPzkxv23620yTx+Q7lJ6jV+",
   "collapsed_sections": [],
   "name": "GBP_CHD_dropout_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
