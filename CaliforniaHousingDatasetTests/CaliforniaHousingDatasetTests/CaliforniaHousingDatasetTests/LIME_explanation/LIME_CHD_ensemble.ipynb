{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LIME_CHD_ensemble.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPdO9ze94KhTC7zPjnDPF72"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## SUMMARY OF THIS NOTEBOOK\n","\n","Attempt to combine LIME (explanation method) with Ensemble (uncertainty method). The LIME function needs a prediction function that returns some output. This output is then used to generate explanation for the input datapoint in question. Now, the ensemble prediction function used here produces two output, the mean of the ensemble mixture and the standard deviation of the ensemble mixture. An additional function (generate_sample_from_predicted_mean_and_std) is written that produces 1 sample from the mixture mean and mixture standard deviation. From this sample explanation is generated. \n","\n","\n","<br> **STATUS (25_02_2022) : CODE WORKS FINE TILL THIS POINT** <br> \n","\n","\n","Options to move forward: <br> \n","Method 1: use the simple ensemble method and then for individual estimator, generate mean (simple ensemble anyway yield only mean). On this mean, generate explanation. Then combine the explanations generated by different estimators by computing the mean and standard deviation explanations  OR \n","\n","Method 2 : use the mixture_mean and mixture_std (as i have already done in this notebook). However, a small change to be taken into consideration is that rather than working with a single sample (from the mixture_mean and mixture_std) take multiple samples. Generate explanations for these samples and then figure out a way to combine these explanations from multiple samples. \n","\n","\n","Essentially, the combined explanation should have the bar chart with varying length. As in, the length of the bar should have a corridor of uncertainty that itself is centered at the mean and then bounded by standard deviation. \n","\n","sort of what this piece of code does: <br>\n","https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.barh.html <br>\n","https://matplotlib.org/3.1.1/gallery/statistics/errorbar_features.html"],"metadata":{"id":"K-39fuZwios8"}},{"cell_type":"markdown","source":["## Mount the drive"],"metadata":{"id":"VQVblOK_u0Mn"}},{"cell_type":"code","source":["# mount the drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"U6KUFWTuy0_P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645794189689,"user_tz":-60,"elapsed":1759,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"667e5eba-bec0-461d-903c-7c28823a81b1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["## Installing keras uncertainty"],"metadata":{"id":"W38k7BDwInPS"}},{"cell_type":"code","source":["# keras_uncertainty imports \n","# clone and install this library \n","\n","!git clone https://github.com/mvaldenegro/keras-uncertainty.git\n","!pip install --user git+https://github.com/mvaldenegro/keras-uncertainty.git\n","\n","%cd keras-uncertainty"],"metadata":{"id":"8jMtkaJCIq2X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645794197515,"user_tz":-60,"elapsed":7833,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"c99a50ce-d427-4373-be1d-c3bb7e98e0fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'keras-uncertainty' already exists and is not an empty directory.\n","Collecting git+https://github.com/mvaldenegro/keras-uncertainty.git\n","  Cloning https://github.com/mvaldenegro/keras-uncertainty.git to /tmp/pip-req-build-39w3funo\n","  Running command git clone -q https://github.com/mvaldenegro/keras-uncertainty.git /tmp/pip-req-build-39w3funo\n","Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from Keras-Uncertainty==0.0.1) (2.8.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Keras-Uncertainty==0.0.1) (1.21.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Keras-Uncertainty==0.0.1) (4.62.3)\n","/content/keras-uncertainty\n"]}]},{"cell_type":"markdown","source":["## Installing LIME"],"metadata":{"id":"yB1jUau9u2kv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fOejjnOsFX2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645794209817,"user_tz":-60,"elapsed":12315,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"93c91195-b436-44c0-d55b-5b7d04dce6c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lime in /usr/local/lib/python3.7/dist-packages (0.2.0.1)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (1.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.21.5)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.18.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.62.3)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2021.11.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.6.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.2.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (3.0.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.1.0)\n","Name: lime\n","Version: 0.2.0.1\n","Summary: Local Interpretable Model-Agnostic Explanations for machine learning classifiers\n","Home-page: http://github.com/marcotcr/lime\n","Author: Marco Tulio Ribeiro\n","Author-email: marcotcr@gmail.com\n","License: BSD\n","Location: /usr/local/lib/python3.7/dist-packages\n","Requires: scipy, scikit-image, tqdm, numpy, matplotlib, scikit-learn\n","Required-by: \n"]}],"source":["!pip install lime \n","import lime \n","import lime.lime_tabular \n","\n","!pip show lime"]},{"cell_type":"markdown","source":["##  Lime specific imports"],"metadata":{"id":"r6_wBJsLiqVA"}},{"cell_type":"code","source":["!pip install pyDOE2 \n","\n","\"\"\"\n","Functions for explaining classifiers that use tabular data (matrices).\n","\"\"\"\n","import collections\n","import copy\n","from functools import partial\n","import json\n","import warnings\n","from collections import defaultdict\n","\n","import numpy as np\n","import scipy as sp\n","import sklearn\n","import sklearn.preprocessing\n","from sklearn.utils import check_random_state\n","from pyDOE2 import lhs\n","from scipy.stats.distributions import norm\n","from pathlib import Path\n","\n","from lime.discretize import QuartileDiscretizer\n","from lime.discretize import DecileDiscretizer\n","from lime.discretize import EntropyDiscretizer\n","from lime.discretize import BaseDiscretizer\n","from lime.discretize import StatsDiscretizer"],"metadata":{"id":"0YeJW7CiwB20","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645794215154,"user_tz":-60,"elapsed":5363,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"a541ec4f-71fb-415e-8632-d63e792a2ab7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyDOE2 in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyDOE2) (1.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE2) (1.4.1)\n"]}]},{"cell_type":"markdown","source":["## Lime classes "],"metadata":{"id":"vS57FcHXwecT"}},{"cell_type":"markdown","source":["## LIMEBASE "],"metadata":{"id":"9YT5Q_s39Sdc"}},{"cell_type":"code","source":["\"\"\"\n","Contains abstract functionality for learning locally linear sparse model.\n","\"\"\"\n","import numpy as np\n","import scipy as sp\n","from sklearn.linear_model import Ridge, lars_path, LinearRegression\n","from sklearn.utils import check_random_state\n","\n","\n","class LimeBase(object):\n","    \"\"\"Class for learning a locally linear sparse model from perturbed data\"\"\"\n","    def __init__(self,\n","                 kernel_fn,\n","                 verbose=True,\n","                 random_state=None):\n","        \"\"\"Init function\n","        Args:\n","            kernel_fn: function that transforms an array of distances into an\n","                        array of proximity values (floats).\n","            verbose: if true, print local prediction values from linear model.\n","            random_state: an integer or numpy.RandomState that will be used to\n","                generate random numbers. If None, the random state will be\n","                initialized using the internal numpy seed.\n","        \"\"\"\n","        self.kernel_fn = kernel_fn\n","        self.verbose = verbose\n","        self.random_state = check_random_state(random_state)\n","\n","    @staticmethod\n","    def generate_lars_path(weighted_data, weighted_labels):\n","        \"\"\"Generates the lars path for weighted data.\n","        Args:\n","            weighted_data: data that has been weighted by kernel\n","            weighted_label: labels, weighted by kernel\n","        Returns:\n","            (alphas, coefs), both are arrays corresponding to the\n","            regularization parameter and coefficients, respectively\n","        \"\"\"\n","        x_vector = weighted_data\n","        alphas, _, coefs = lars_path(x_vector,\n","                                     weighted_labels,\n","                                     method='lasso',\n","                                     verbose=False)\n","        return alphas, coefs\n","\n","    def forward_selection(self, data, labels, weights, num_features):\n","        \"\"\"Iteratively adds features to the model\"\"\"\n","        clf = Ridge(alpha=0, fit_intercept=True, random_state=self.random_state)\n","        used_features = []\n","        for _ in range(min(num_features, data.shape[1])):\n","            max_ = -100000000\n","            best = 0\n","            for feature in range(data.shape[1]):\n","                if feature in used_features:\n","                    continue\n","                clf.fit(data[:, used_features + [feature]], labels,\n","                        sample_weight=weights)\n","                score = clf.score(data[:, used_features + [feature]],\n","                                  labels,\n","                                  sample_weight=weights)\n","                if score > max_:\n","                    best = feature\n","                    max_ = score\n","            used_features.append(best)\n","        return np.array(used_features)\n","\n","    def feature_selection(self, data, labels, weights, num_features, method):\n","        \"\"\"Selects features for the model. see explain_instance_with_data to\n","           understand the parameters.\"\"\"\n","        if method == 'none':\n","            return np.array(range(data.shape[1]))\n","        elif method == 'forward_selection':\n","            return self.forward_selection(data, labels, weights, num_features)\n","        elif method == 'highest_weights':\n","            clf = Ridge(alpha=0.01, fit_intercept=True,\n","                        random_state=self.random_state)\n","            clf.fit(data, labels, sample_weight=weights)\n","\n","            coef = clf.coef_\n","            if sp.sparse.issparse(data):\n","                coef = sp.sparse.csr_matrix(clf.coef_)\n","                weighted_data = coef.multiply(data[0])\n","                # Note: most efficient to slice the data before reversing\n","                sdata = len(weighted_data.data)\n","                argsort_data = np.abs(weighted_data.data).argsort()\n","                # Edge case where data is more sparse than requested number of feature importances\n","                # In that case, we just pad with zero-valued features\n","                if sdata < num_features:\n","                    nnz_indexes = argsort_data[::-1]\n","                    indices = weighted_data.indices[nnz_indexes]\n","                    num_to_pad = num_features - sdata\n","                    indices = np.concatenate((indices, np.zeros(num_to_pad, dtype=indices.dtype)))\n","                    indices_set = set(indices)\n","                    pad_counter = 0\n","                    for i in range(data.shape[1]):\n","                        if i not in indices_set:\n","                            indices[pad_counter + sdata] = i\n","                            pad_counter += 1\n","                            if pad_counter >= num_to_pad:\n","                                break\n","                else:\n","                    nnz_indexes = argsort_data[sdata - num_features:sdata][::-1]\n","                    indices = weighted_data.indices[nnz_indexes]\n","                return indices\n","            else:\n","                weighted_data = coef * data[0]\n","                feature_weights = sorted(\n","                    zip(range(data.shape[1]), weighted_data),\n","                    key=lambda x: np.abs(x[1]),\n","                    reverse=True)\n","                return np.array([x[0] for x in feature_weights[:num_features]])\n","        elif method == 'lasso_path':\n","            weighted_data = ((data - np.average(data, axis=0, weights=weights))\n","                             * np.sqrt(weights[:, np.newaxis]))\n","            weighted_labels = ((labels - np.average(labels, weights=weights))\n","                               * np.sqrt(weights))\n","            nonzero = range(weighted_data.shape[1])\n","            _, coefs = self.generate_lars_path(weighted_data,\n","                                               weighted_labels)\n","            for i in range(len(coefs.T) - 1, 0, -1):\n","                nonzero = coefs.T[i].nonzero()[0]\n","                if len(nonzero) <= num_features:\n","                    break\n","            used_features = nonzero\n","            return used_features\n","        elif method == 'auto':\n","            if num_features <= 6:\n","                n_method = 'forward_selection'\n","            else:\n","                n_method = 'highest_weights'\n","            return self.feature_selection(data, labels, weights,\n","                                          num_features, n_method)\n","\n","    def explain_instance_with_data(self,\n","                                   neighborhood_data,\n","                                   neighborhood_labels,\n","                                   distances,\n","                                   label,\n","                                   num_features,\n","                                   feature_selection='auto',\n","                                   model_regressor=None):\n","        \"\"\"Takes perturbed data, labels and distances, returns explanation.\n","        Args:\n","            neighborhood_data: perturbed data, 2d array. first element is\n","                               assumed to be the original data point.\n","            neighborhood_labels: corresponding perturbed labels. should have as\n","                                 many columns as the number of possible labels.\n","            distances: distances to original data point.\n","            label: label for which we want an explanation\n","            num_features: maximum number of features in explanation\n","            feature_selection: how to select num_features. options are:\n","                'forward_selection': iteratively add features to the model.\n","                    This is costly when num_features is high\n","                'highest_weights': selects the features that have the highest\n","                    product of absolute weight * original data point when\n","                    learning with all the features\n","                'lasso_path': chooses features based on the lasso\n","                    regularization path\n","                'none': uses all features, ignores num_features\n","                'auto': uses forward_selection if num_features <= 6, and\n","                    'highest_weights' otherwise.\n","            model_regressor: sklearn regressor to use in explanation.\n","                Defaults to Ridge regression if None. Must have\n","                model_regressor.coef_ and 'sample_weight' as a parameter\n","                to model_regressor.fit()\n","        Returns:\n","            (intercept, exp, score, local_pred):\n","            intercept is a float.\n","            exp is a sorted list of tuples, where each tuple (x,y) corresponds\n","            to the feature id (x) and the local weight (y). The list is sorted\n","            by decreasing absolute value of y.\n","            score is the R^2 value of the returned explanation\n","            local_pred is the prediction of the explanation model on the original instance\n","        \"\"\"\n","\n","        weights = self.kernel_fn(distances)\n","        labels_column = neighborhood_labels[:, label]\n","        used_features = self.feature_selection(neighborhood_data,\n","                                               labels_column,\n","                                               weights,\n","                                               num_features,\n","                                               feature_selection)\n","        if model_regressor is None:\n","            model_regressor = Ridge(alpha=1, fit_intercept=True,\n","                                    random_state=self.random_state)\n","            #model_regressor = LinearRegression(fit_intercept=True)\n","        easy_model = model_regressor\n","        easy_model.fit(neighborhood_data[:, used_features],\n","                       labels_column, sample_weight=weights)\n","        prediction_score = easy_model.score(\n","            neighborhood_data[:, used_features],\n","            labels_column, sample_weight=weights)\n","\n","        local_pred = easy_model.predict(neighborhood_data[0, used_features].reshape(1, -1))\n","\n","        if self.verbose:\n","            print('Neighborhood labels ', neighborhood_labels)\n","            print('Intercept', easy_model.intercept_)\n","            print('Prediction_local', local_pred,)\n","            print('Right:', neighborhood_labels[0, label])\n","            print('coefficients (these are the values that are printed as being the \\'weights\\' of the feature) ', easy_model.coef_)  # coefficients \n","        return (easy_model.intercept_,\n","                sorted(zip(used_features, easy_model.coef_),\n","                       key=lambda x: np.abs(x[1]), reverse=True),\n","                prediction_score, local_pred)"],"metadata":{"id":"aP8U5t4DKDsc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DOMAIN MAPPER & EXPLANATION "],"metadata":{"id":"maKw2k8F9o8u"}},{"cell_type":"code","source":["\"\"\"\n","Explanation class, with visualization functions.\n","\"\"\"\n","from io import open\n","import os\n","import os.path\n","import json\n","import string\n","import numpy as np\n","\n","from sklearn.utils import check_random_state\n","\n","\n","class LimeError(Exception):\n","    \"\"\"Raise for errors\"\"\"\n","\n","\n","def id_generator(size=15, random_state=None):\n","    \"\"\"Helper function to generate random div ids. This is useful for embedding\n","    HTML into ipython notebooks.\"\"\"\n","    chars = list(string.ascii_uppercase + string.digits)\n","    return ''.join(random_state.choice(chars, size, replace=True))\n","\n","\n","class DomainMapper(object):\n","    \"\"\"Class for mapping features to the specific domain.\n","    The idea is that there would be a subclass for each domain (text, tables,\n","    images, etc), so that we can have a general Explanation class, and separate\n","    out the specifics of visualizing features in here.\n","    \"\"\"\n","\n","    def __init__(self):\n","        pass\n","\n","    def map_exp_ids(self, exp, **kwargs):\n","        \"\"\"Maps the feature ids to concrete names.\n","        Default behaviour is the identity function. Subclasses can implement\n","        this as they see fit.\n","        Args:\n","            exp: list of tuples [(id, weight), (id,weight)]\n","            kwargs: optional keyword arguments\n","        Returns:\n","            exp: list of tuples [(name, weight), (name, weight)...]\n","        \"\"\"\n","        return exp\n","\n","    def visualize_instance_html(self,\n","                                exp,\n","                                label,\n","                                div_name,\n","                                exp_object_name,\n","                                **kwargs):\n","        \"\"\"Produces html for visualizing the instance.\n","        Default behaviour does nothing. Subclasses can implement this as they\n","        see fit.\n","        Args:\n","             exp: list of tuples [(id, weight), (id,weight)]\n","             label: label id (integer)\n","             div_name: name of div object to be used for rendering(in js)\n","             exp_object_name: name of js explanation object\n","             kwargs: optional keyword arguments\n","        Returns:\n","             js code for visualizing the instance\n","        \"\"\"\n","        return ''\n","\n","\n","class Explanation(object):\n","    \"\"\"Object returned by explainers.\"\"\"\n","\n","    def __init__(self,\n","                 domain_mapper,\n","                 mode='classification',\n","                 class_names=None,\n","                 random_state=None,\n","                 explanation_id=None):\n","        \"\"\"\n","        Initializer.\n","        Args:\n","            domain_mapper: must inherit from DomainMapper class\n","            type: \"classification\" or \"regression\"\n","            class_names: list of class names (only used for classification)\n","            random_state: an integer or numpy.RandomState that will be used to\n","                generate random numbers. If None, the random state will be\n","                initialized using the internal numpy seed.\n","        \"\"\"\n","        self.random_state = random_state\n","        self.mode = mode\n","        self.domain_mapper = domain_mapper\n","        self.local_exp = defaultdict(list)#\n","        self.intercept = defaultdict(list)#\n","        self.score = defaultdict(list)#\n","        self.local_pred = defaultdict(list)#\n","        self.explanation_id= explanation_id\n","        if mode == 'classification':\n","            self.class_names = class_names\n","            self.top_labels = None\n","            self.predict_proba = None\n","        elif mode == 'regression':\n","            self.class_names = ['negative', 'positive']\n","            self.predicted_value = None\n","            self.min_value = 0.0\n","            self.max_value = 1.0\n","            self.dummy_label = 1\n","        else:\n","            raise LimeError('Invalid explanation mode \"{}\". '\n","                            'Should be either \"classification\" '\n","                            'or \"regression\".'.format(mode))\n","\n","    def available_labels(self):\n","        \"\"\"\n","        Returns the list of classification labels for which we have any explanations.\n","        \"\"\"\n","        try:\n","            assert self.mode == \"classification\"\n","        except AssertionError:\n","            raise NotImplementedError('Not supported for regression explanations.')\n","        else:\n","            ans = self.top_labels if self.top_labels else self.local_exp.keys()\n","            return list(ans)\n","\n","    def as_list(self, label=1, **kwargs):\n","        \"\"\"Returns the explanation as a list.\n","        Args:\n","            label: desired label. If you ask for a label for which an\n","                explanation wasn't computed, will throw an exception.\n","                Will be ignored for regression explanations.\n","            kwargs: keyword arguments, passed to domain_mapper\n","        Returns:\n","            list of tuples (representation, weight), where representation is\n","            given by domain_mapper. Weight is a float.\n","        \"\"\"\n","        label_to_use = label if self.mode == \"classification\" else self.dummy_label\n","        ans = self.domain_mapper.map_exp_ids(self.local_exp[label_to_use], **kwargs)\n","        ans = [(x[0], float(x[1])) for x in ans]\n","        return ans\n","\n","    def as_map(self):\n","        \"\"\"Returns the map of explanations.\n","        Returns:\n","            Map from label to list of tuples (feature_id, weight).\n","        \"\"\"\n","        return self.local_exp\n","\n","    def as_pyplot_figure(self, label=1, figsize=(4,4), **kwargs):\n","        \"\"\"Returns the explanation as a pyplot figure.\n","        Will throw an error if you don't have matplotlib installed\n","        Args:\n","            label: desired label. If you ask for a label for which an\n","                   explanation wasn't computed, will throw an exception.\n","                   Will be ignored for regression explanations.\n","            figsize: desired size of pyplot in tuple format, defaults to (4,4).\n","            kwargs: keyword arguments, passed to domain_mapper\n","        Returns:\n","            pyplot figure (barchart).\n","        \"\"\"\n","        import matplotlib.pyplot as plt\n","        exp = self.as_list(label=label, **kwargs)\n","        fig = plt.figure(figsize=figsize)\n","        vals = [x[1] for x in exp]\n","        names = [x[0] for x in exp]\n","        vals.reverse()\n","        names.reverse()\n","        colors = ['C1' if x > 0 else 'C0' for x in vals] # originally negative=red and positive=green (coloring scheme)\n","        colors_set = set(colors)\n","        print('colors_set before ', colors_set)\n","        colors_set = ['positive' if c == 'C1' else 'negative' for c in colors_set]\n","        print('colors_set after ', colors_set)\n","        pos = np.arange(len(exp)) + .5\n","        print('pos values for plot are ', pos)\n","        print('vals ', vals)\n","        print('names ', names)\n","        vals_str = [str(round(val, 3)) for val in vals]\n","        print('vals_str ', vals_str)\n","        \n","        plt.figure(figsize=(15, 10))\n","        #plt.barh(pos, vals, color=colors) #this code works well but does not have legend or text in int\n","\n","        #colors = ['r', 'g', 'b']\n","        labels = colors_set \n","        legend_colors = list(set(colors))\n","        print(legend_colors)\n","        handles = [plt.Rectangle((0,0),1,1, color=legend_colors[label]) for label in range(len(labels))]\n","        print(handles)\n","       \n","        vals = [np.abs(num) if num  == 0 else num for num in vals] # removing the sign from 0 vals\n","        print('vals ', vals)\n","\n","        for i, v in enumerate(vals):\n","            plt.text(v, i+0.5, str(round(v, 3)), Bbox = dict(facecolor = 'grey', alpha =.8)) # https://www.geeksforgeeks.org/adding-value-labels-on-a-matplotlib-bar-chart/\n","        axx = plt.barh([i for i in pos], vals, align='center', color=colors) # this code appropriate legend\n","        plt.legend(handles, labels) # https://stackoverflow.com/questions/57340415/matplotlib-bar-plot-add-legend-from-categories-dataframe-column\n","\n","        plt.yticks(pos, names)\n","        if self.mode == \"classification\":\n","            title = 'Local explanation for class %s' % self.class_names[label]\n","        else:\n","            title = 'Local explanation'\n","        plt.title(title+' for test input '+str(self.explanation_id))\n","        #plt.legend()\n","        plt.xlabel('feature coefficient')\n","        plt.grid()\n","        plt.tight_layout()\n","\n","        return fig\n","\n","    def show_in_notebook(self,\n","                         labels=None,\n","                         predict_proba=True,\n","                         show_predicted_value=True,\n","                         **kwargs):\n","        \"\"\"Shows html explanation in ipython notebook.\n","        See as_html() for parameters.\n","        This will throw an error if you don't have IPython installed\"\"\"\n","\n","        from IPython.core.display import display, HTML\n","        display(HTML(self.as_html(labels=labels,\n","                                  predict_proba=predict_proba,\n","                                  show_predicted_value=show_predicted_value,\n","                                  **kwargs)))\n","\n","    def save_to_file(self,\n","                     file_path,\n","                     labels=None,\n","                     predict_proba=True,\n","                     show_predicted_value=True,\n","                     **kwargs):\n","        \"\"\"Saves html explanation to file. .\n","        Params:\n","            file_path: file to save explanations to\n","        See as_html() for additional parameters.\n","        \"\"\"\n","        file_ = open(file_path, 'w', encoding='utf8')\n","        file_.write(self.as_html(labels=labels,\n","                                 predict_proba=predict_proba,\n","                                 show_predicted_value=show_predicted_value,\n","                                 **kwargs))\n","        file_.close()\n","\n","    def as_html(self,\n","                labels=None,\n","                predict_proba=True,\n","                show_predicted_value=True,\n","                **kwargs):\n","        \"\"\"Returns the explanation as an html page.\n","        Args:\n","            labels: desired labels to show explanations for (as barcharts).\n","                If you ask for a label for which an explanation wasn't\n","                computed, will throw an exception. If None, will show\n","                explanations for all available labels. (only used for classification)\n","            predict_proba: if true, add  barchart with prediction probabilities\n","                for the top classes. (only used for classification)\n","            show_predicted_value: if true, add  barchart with expected value\n","                (only used for regression)\n","            kwargs: keyword arguments, passed to domain_mapper\n","        Returns:\n","            code for an html page, including javascript includes.\n","        \"\"\"\n","\n","        def jsonize(x):\n","            return json.dumps(x, ensure_ascii=False)\n","\n","        if labels is None and self.mode == \"classification\":\n","            labels = self.available_labels()\n","\n","\n","        #this_dir, _ = os.path.split(__file__) # this code gave error that __file__ not defined \n","        this_dir = '/usr/local/lib/python3.7/dist-packages/lime/' # intentional hardcoding of the path \n","        \n","        bundle = open(os.path.join(this_dir, 'bundle.js'),\n","                      encoding=\"utf8\").read()\n","\n","        out = u'''<html>\n","        <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF8\">\n","        <head><script>%s </script></head><body>''' % bundle\n","        random_id = id_generator(size=15, random_state=check_random_state(self.random_state))\n","        out += u'''\n","        <div class=\"lime top_div\" id=\"top_div%s\"></div>\n","        ''' % random_id\n","\n","        predict_proba_js = ''\n","        if self.mode == \"classification\" and predict_proba:\n","            predict_proba_js = u'''\n","            var pp_div = top_div.append('div')\n","                                .classed('lime predict_proba', true);\n","            var pp_svg = pp_div.append('svg').style('width', '100%%');\n","            var pp = new lime.PredictProba(pp_svg, %s, %s);\n","            ''' % (jsonize([str(x) for x in self.class_names]),\n","                   jsonize(list(self.predict_proba.astype(float))))\n","\n","        predict_value_js = ''\n","        if self.mode == \"regression\" and show_predicted_value:\n","            # reference self.predicted_value\n","            # (svg, predicted_value, min_value, max_value)\n","            predict_value_js = u'''\n","                    var pp_div = top_div.append('div')\n","                                        .classed('lime predicted_value', true);\n","                    var pp_svg = pp_div.append('svg').style('width', '100%%');\n","                    var pp = new lime.PredictedValue(pp_svg, %s, %s, %s);\n","                    ''' % (jsonize(float(self.predicted_value)),\n","                           jsonize(float(self.min_value)),\n","                           jsonize(float(self.max_value)))\n","\n","        exp_js = '''var exp_div;\n","            var exp = new lime.Explanation(%s);\n","        ''' % (jsonize([str(x) for x in self.class_names]))\n","\n","        if self.mode == \"classification\":\n","            for label in labels:\n","                exp = jsonize(self.as_list(label))\n","                exp_js += u'''\n","                exp_div = top_div.append('div').classed('lime explanation', true);\n","                exp.show(%s, %d, exp_div);\n","                ''' % (exp, label)\n","        else:\n","            exp = jsonize(self.as_list())\n","            exp_js += u'''\n","            exp_div = top_div.append('div').classed('lime explanation', true);\n","            exp.show(%s, %s, exp_div);\n","            ''' % (exp, self.dummy_label)\n","\n","        raw_js = '''var raw_div = top_div.append('div');'''\n","\n","        if self.mode == \"classification\":\n","            html_data = self.local_exp[labels[0]]\n","        else:\n","            html_data = self.local_exp[self.dummy_label]\n","\n","        raw_js += self.domain_mapper.visualize_instance_html(\n","                html_data,\n","                labels[0] if self.mode == \"classification\" else self.dummy_label,\n","                'raw_div',\n","                'exp',\n","                **kwargs)\n","        out += u'''\n","        <script>\n","        var top_div = d3.select('#top_div%s').classed('lime top_div', true);\n","        %s\n","        %s\n","        %s\n","        %s\n","        </script>\n","        ''' % (random_id, predict_proba_js, predict_value_js, exp_js, raw_js)\n","        out += u'</body></html>'\n","\n","        return out"],"metadata":{"id":"kqm0wmOFlr0U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## BASEDISCRETIZER & ITS DERIVATIVE CLASS"],"metadata":{"id":"AgyuWwez9vMl"}},{"cell_type":"code","source":["\"\"\"\n","Discretizers classes, to be used in lime_tabular\n","\"\"\"\n","import numpy as np\n","import sklearn\n","import sklearn.tree\n","import scipy\n","from sklearn.utils import check_random_state\n","from abc import ABCMeta, abstractmethod\n","\n","\n","class BaseDiscretizer():\n","    \"\"\"\n","    Abstract class - Build a class that inherits from this class to implement\n","    a custom discretizer.\n","    Method bins() is to be redefined in the child class, as it is the actual\n","    custom part of the discretizer.\n","    \"\"\"\n","\n","    __metaclass__ = ABCMeta  # abstract class\n","\n","    def __init__(self, data, categorical_features, feature_names, labels=None, random_state=None,\n","                 data_stats=None):\n","        \"\"\"Initializer\n","        Args:\n","            data: numpy 2d array\n","            categorical_features: list of indices (ints) corresponding to the\n","                categorical columns. These features will not be discretized.\n","                Everything else will be considered continuous, and will be\n","                discretized.\n","            categorical_names: map from int to list of names, where\n","                categorical_names[x][y] represents the name of the yth value of\n","                column x.\n","            feature_names: list of names (strings) corresponding to the columns\n","                in the training data.\n","            data_stats: must have 'means', 'stds', 'mins' and 'maxs', use this\n","                if you don't want these values to be computed from data\n","        \"\"\"\n","        print('Inside BaseDiscretizer __init__')\n","        self.to_discretize = ([x for x in range(data.shape[1])\n","                               if x not in categorical_features])\n","        print('to_discretize :', self.to_discretize)\n","        self.data_stats = data_stats\n","        self.names = defaultdict(list)#    solution taken from https://stackoverflow.com/questions/23297569/python-key-error-0-cant-find-dict-error-in-code \n","        self.lambdas = defaultdict(list)#\n","        self.means = defaultdict(list)#\n","        self.stds = defaultdict(list)#\n","        self.mins = defaultdict(list)#\n","        self.maxs = defaultdict(list)#\n","        self.random_state = check_random_state(random_state)\n","\n","        # To override when implementing a custom binning\n","        bins = self.bins(data, labels)\n","        bins = [np.unique(x) for x in bins]\n","        print('bins :', bins)\n","\n","        # Read the stats from data_stats if exists\n","        if data_stats:\n","            self.means = self.data_stats.get(\"means\")\n","            self.stds = self.data_stats.get(\"stds\")\n","            self.mins = self.data_stats.get(\"mins\")\n","            self.maxs = self.data_stats.get(\"maxs\")\n","\n","        for feature, qts in zip(self.to_discretize, bins):\n","            n_bins = qts.shape[0]  # Actually number of borders (= #bins-1)\n","            print(f'n_bins for feature ({feature}) \\'{feature_names[feature]}\\' and qts {qts} is {n_bins}')\n","            boundaries = np.min(data[:, feature]), np.max(data[:, feature])\n","            print(f'boundaries : {boundaries}')\n","            name = feature_names[feature]\n","            print(f'feature_names {name}')\n","\n","            self.names[feature] = ['%s <= %.2f' % (name, qts[0])]\n","            for i in range(n_bins - 1):\n","                self.names[feature].append('%.2f < %s <= %.2f' %\n","                                           (qts[i], name, qts[i + 1]))\n","                print('statements to be added')\n","                print('%.2f < %s <= %.2f' %(qts[i], name, qts[i + 1]))\n","\n","            self.names[feature].append('%s > %.2f' % (name, qts[n_bins - 1]))\n","            print('statements to be added')\n","            print('%s > %.2f' % (name, qts[n_bins - 1]))\n","\n","            self.lambdas[feature] = lambda x, qts=qts: np.searchsorted(qts, x)    # this is how searchsorted works : np.searchsorted([1,2,3,4,5], 3) : answer-> 2 (shape of output is same as second argument)\n","            print(f'lambdas : {self.lambdas[feature]}')\n","            print(f'data[:, features] {data[:, feature]}')\n","            print(f'qts : {qts}')\n","            discretized = self.lambdas[feature](data[:, feature])  # all np.searsorted does is attempt to identify those indices where the data[:,features] values could be inserted within the qts array \n","            print('discretized :', discretized)\n","            print('len of discretized :', len(discretized))\n","            # If data stats are provided no need to compute the below set of details\n","            if data_stats:\n","                continue\n","\n","            self.means[feature] = []\n","            self.stds[feature] = []\n","            for x in range(n_bins + 1):\n","                selection = data[discretized == x, feature]\n","                mean = 0 if len(selection) == 0 else np.mean(selection)\n","                self.means[feature].append(mean)\n","                std = 0 if len(selection) == 0 else np.std(selection)\n","                std += 0.00000000001\n","                self.stds[feature].append(std)\n","            self.mins[feature] = [boundaries[0]] + qts.tolist()\n","            self.maxs[feature] = qts.tolist() + [boundaries[1]]\n","\n","\n","            print(f'mins self.mins[feature] {self.mins[feature]}')\n","            print(f'maxs self.maxs[feature] {self.maxs[feature]}')\n","\n","    @abstractmethod\n","    def bins(self, data, labels):\n","        \"\"\"\n","        To be overridden\n","        Returns for each feature to discretize the boundaries\n","        that form each bin of the discretizer\n","        \"\"\"\n","        raise NotImplementedError(\"Must override bins() method\")\n","\n","    def discretize(self, data):\n","        \"\"\"Discretizes the data.\n","        Args:\n","            data: numpy 2d or 1d array\n","        Returns:\n","            numpy array of same dimension, discretized.\n","        \"\"\"\n","        ret = data.copy()\n","        for feature in self.lambdas:\n","            if len(data.shape) == 1:\n","                ret[feature] = int(self.lambdas[feature](ret[feature]))\n","            else:\n","                ret[:, feature] = self.lambdas[feature](\n","                    ret[:, feature]).astype(int)\n","        return ret\n","\n","    def get_undiscretize_values(self, feature, values):\n","        mins = np.array(self.mins[feature])[values]\n","        maxs = np.array(self.maxs[feature])[values]\n","\n","        means = np.array(self.means[feature])[values]\n","        stds = np.array(self.stds[feature])[values]\n","        minz = (mins - means) / stds\n","        maxz = (maxs - means) / stds\n","        min_max_unequal = (minz != maxz)\n","\n","        ret = minz\n","        ret[np.where(min_max_unequal)] = scipy.stats.truncnorm.rvs(\n","            minz[min_max_unequal],\n","            maxz[min_max_unequal],\n","            loc=means[min_max_unequal],\n","            scale=stds[min_max_unequal],\n","            random_state=self.random_state\n","        )\n","        return ret\n","\n","    def undiscretize(self, data):\n","        ret = data.copy()\n","        for feature in self.means:\n","            if len(data.shape) == 1:\n","                ret[feature] = self.get_undiscretize_values(\n","                    feature, ret[feature].astype(int).reshape(-1, 1)\n","                )\n","            else:\n","                ret[:, feature] = self.get_undiscretize_values(\n","                    feature, ret[:, feature].astype(int)\n","                )\n","        return ret\n","\n","\n","class StatsDiscretizer(BaseDiscretizer):\n","    \"\"\"\n","        Class to be used to supply the data stats info when discretize_continuous is true\n","    \"\"\"\n","\n","    def __init__(self, data, categorical_features, feature_names, labels=None, random_state=None,\n","                 data_stats=None):\n","\n","        BaseDiscretizer.__init__(self, data, categorical_features,\n","                                 feature_names, labels=labels,\n","                                 random_state=random_state,\n","                                 data_stats=data_stats)\n","\n","    def bins(self, data, labels):\n","        bins_from_stats = self.data_stats.get(\"bins\")\n","        bins = []\n","        if bins_from_stats is not None:\n","            for feature in self.to_discretize:\n","                bins_from_stats_feature = bins_from_stats.get(feature)\n","                if bins_from_stats_feature is not None:\n","                    qts = np.array(bins_from_stats_feature)\n","                    bins.append(qts)\n","        return bins\n","\n","\n","class QuartileDiscretizer(BaseDiscretizer):\n","    def __init__(self, data, categorical_features, feature_names, labels=None, random_state=None):\n","\n","        BaseDiscretizer.__init__(self, data, categorical_features,\n","                                 feature_names, labels=labels,\n","                                 random_state=random_state)\n","\n","    def bins(self, data, labels):\n","        bins = []\n","        for feature in self.to_discretize:\n","            qts = np.array(np.percentile(data[:, feature], [25, 50, 75]))\n","            bins.append(qts)\n","        return bins\n","\n","\n","class DecileDiscretizer(BaseDiscretizer):\n","    def __init__(self, data, categorical_features, feature_names, labels=None, random_state=None):\n","        BaseDiscretizer.__init__(self, data, categorical_features,\n","                                 feature_names, labels=labels,\n","                                 random_state=random_state)\n","\n","    def bins(self, data, labels):\n","        bins = []\n","        for feature in self.to_discretize:\n","            qts = np.array(np.percentile(data[:, feature],\n","                                         [10, 20, 30, 40, 50, 60, 70, 80, 90]))\n","            bins.append(qts)\n","        return bins\n","\n","\n","class EntropyDiscretizer(BaseDiscretizer):\n","    def __init__(self, data, categorical_features, feature_names, labels=None, random_state=None):\n","        if(labels is None):\n","            raise ValueError('Labels must be not None when using \\\n","                             EntropyDiscretizer')\n","        BaseDiscretizer.__init__(self, data, categorical_features,\n","                                 feature_names, labels=labels,\n","                                 random_state=random_state)\n","\n","    def bins(self, data, labels):\n","        bins = []\n","        for feature in self.to_discretize:\n","            # Entropy splitting / at most 8 bins so max_depth=3\n","            dt = sklearn.tree.DecisionTreeClassifier(criterion='entropy',\n","                                                     max_depth=3,\n","                                                     random_state=self.random_state)\n","            x = np.reshape(data[:, feature], (-1, 1))\n","            dt.fit(x, labels)\n","            qts = dt.tree_.threshold[np.where(dt.tree_.children_left > -1)]\n","\n","            if qts.shape[0] == 0:\n","                qts = np.array([np.median(data[:, feature])])\n","            else:\n","                qts = np.sort(qts)\n","\n","            bins.append(qts)\n","\n","        return bins"],"metadata":{"id":"w5FscdcA86XM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## TABLEDOMAINMAPPER & LIMETABULAREXPLAINER"],"metadata":{"id":"c82b38Pf99FH"}},{"cell_type":"code","source":["class TableDomainMapper(DomainMapper):\n","    \"\"\"Maps feature ids to names, generates table views, etc\"\"\"\n","\n","    def __init__(self, feature_names, feature_values, scaled_row,\n","                 categorical_features, discretized_feature_names=None,\n","                 feature_indexes=None):\n","        \"\"\"Init.\n","        Args:\n","            feature_names: list of feature names, in order\n","            feature_values: list of strings with the values of the original row\n","            scaled_row: scaled row\n","            categorical_features: list of categorical features ids (ints)\n","            feature_indexes: optional feature indexes used in the sparse case\n","        \"\"\"\n","        self.exp_feature_names = feature_names\n","        self.discretized_feature_names = discretized_feature_names\n","        self.feature_names = feature_names\n","        self.feature_values = feature_values\n","        self.feature_indexes = feature_indexes\n","        self.scaled_row = scaled_row\n","        if sp.sparse.issparse(scaled_row):\n","            self.all_categorical = False\n","        else:\n","            self.all_categorical = len(categorical_features) == len(scaled_row)\n","        self.categorical_features = categorical_features\n","\n","    def map_exp_ids(self, exp):\n","        \"\"\"Maps ids to feature names.\n","        Args:\n","            exp: list of tuples [(id, weight), (id,weight)]\n","        Returns:\n","            list of tuples (feature_name, weight)\n","        \"\"\"\n","        names = self.exp_feature_names\n","        if self.discretized_feature_names is not None:\n","            names = self.discretized_feature_names\n","        return [(names[x[0]], x[1]) for x in exp]\n","\n","    def visualize_instance_html(self,\n","                                exp,\n","                                label,\n","                                div_name,\n","                                exp_object_name,\n","                                show_table=True,\n","                                show_all=False):\n","        \"\"\"Shows the current example in a table format.\n","        Args:\n","             exp: list of tuples [(id, weight), (id,weight)]\n","             label: label id (integer)\n","             div_name: name of div object to be used for rendering(in js)\n","             exp_object_name: name of js explanation object\n","             show_table: if False, don't show table visualization.\n","             show_all: if True, show zero-weighted features in the table.\n","        \"\"\"\n","        if not show_table:\n","            return ''\n","        weights = [0] * len(self.feature_names)\n","        for x in exp:\n","            weights[x[0]] = x[1]\n","            print_weights = [round(t, 3) for t in weights]\n","            print('weights ', print_weights)\n","        if self.feature_indexes is not None:\n","            # Sparse case: only display the non-zero values and importances\n","            fnames = [self.exp_feature_names[i] for i in self.feature_indexes]\n","            print('fnames ', fnames)\n","            fweights = [weights[i] for i in self.feature_indexes]\n","            print('fweights ', fweights)\n","            if show_all:\n","                out_list = list(zip(fnames,\n","                                    self.feature_values,\n","                                    fweights))\n","            else:\n","                out_dict = dict(map(lambda x: (x[0], (x[1], x[2], x[3])),\n","                                zip(self.feature_indexes,\n","                                    fnames,\n","                                    self.feature_values,\n","                                    fweights)))\n","                out_list = [out_dict.get(x[0], (str(x[0]), 0.0, 0.0)) for x in exp]\n","        else:\n","            out_list = list(zip(self.exp_feature_names,\n","                                self.feature_values,\n","                                weights))\n","            if not show_all:\n","                out_list = [out_list[x[0]] for x in exp]\n","        ret = u'''\n","            %s.show_raw_tabular(%s, %d, %s);\n","        ''' % (exp_object_name, json.dumps(out_list, ensure_ascii=False), label, div_name)\n","        return ret\n","\n","\n","class LimeTabularExplainer(object):\n","    \"\"\"Explains predictions on tabular (i.e. matrix) data.\n","    For numerical features, perturb them by sampling from a Normal(0,1) and\n","    doing the inverse operation of mean-centering and scaling, according to the\n","    means and stds in the training data. For categorical features, perturb by\n","    sampling according to the training distribution, and making a binary\n","    feature that is 1 when the value is the same as the instance being\n","    explained.\"\"\"\n","\n","    def __init__(self,\n","                 training_data,\n","                 mode=\"classification\",\n","                 training_labels=None,\n","                 feature_names=None,\n","                 categorical_features=None,\n","                 categorical_names=None,\n","                 kernel_width=None,\n","                 kernel=None,\n","                 verbose=False,\n","                 class_names=None,\n","                 feature_selection='auto',\n","                 discretize_continuous=True,\n","                 discretizer='quartile',\n","                 sample_around_instance=False,\n","                 random_state=None,\n","                 training_data_stats=None):\n","        \"\"\"Init function.\n","        Args:\n","            training_data: numpy 2d array\n","            mode: \"classification\" or \"regression\"\n","            training_labels: labels for training data. Not required, but may be\n","                used by discretizer.\n","            feature_names: list of names (strings) corresponding to the columns\n","                in the training data.\n","            categorical_features: list of indices (ints) corresponding to the\n","                categorical columns. Everything else will be considered\n","                continuous. Values in these columns MUST be integers.\n","            categorical_names: map from int to list of names, where\n","                categorical_names[x][y] represents the name of the yth value of\n","                column x.\n","            kernel_width: kernel width for the exponential kernel.\n","                If None, defaults to sqrt (number of columns) * 0.75\n","            kernel: similarity kernel that takes euclidean distances and kernel\n","                width as input and outputs weights in (0,1). If None, defaults to\n","                an exponential kernel.\n","            verbose: if true, print local prediction values from linear model\n","            class_names: list of class names, ordered according to whatever the\n","                classifier is using. If not present, class names will be '0',\n","                '1', ...\n","            feature_selection: feature selection method. can be\n","                'forward_selection', 'lasso_path', 'none' or 'auto'.\n","                See function 'explain_instance_with_data' in lime_base.py for\n","                details on what each of the options does.\n","            discretize_continuous: if True, all non-categorical features will\n","                be discretized into quartiles.\n","            discretizer: only matters if discretize_continuous is True\n","                and data is not sparse. Options are 'quartile', 'decile',\n","                'entropy' or a BaseDiscretizer instance.\n","            sample_around_instance: if True, will sample continuous features\n","                in perturbed samples from a normal centered at the instance\n","                being explained. Otherwise, the normal is centered on the mean\n","                of the feature data.\n","            random_state: an integer or numpy.RandomState that will be used to\n","                generate random numbers. If None, the random state will be\n","                initialized using the internal numpy seed.\n","            training_data_stats: a dict object having the details of training data\n","                statistics. If None, training data information will be used, only matters\n","                if discretize_continuous is True. Must have the following keys:\n","                means\", \"mins\", \"maxs\", \"stds\", \"feature_values\",\n","                \"feature_frequencies\"\n","        \"\"\"\n","\n","        print('Inside __init__ of LimeTabularExplainer')\n","\n","        self.random_state = check_random_state(random_state)\n","        self.mode = mode\n","        self.categorical_names = categorical_names or defaultdict(list)#\n","        self.sample_around_instance = sample_around_instance\n","        self.training_data_stats = training_data_stats\n","    \n","        \n","        print('mode :', self.mode)\n","        print('sample_around_instance :', self.sample_around_instance)\n","        print('training_data_stats :', self.training_data_stats) \n","\n","        # Check and raise proper error in stats are supplied in non-descritized path\n","        if self.training_data_stats:\n","            self.validate_training_data_stats(self.training_data_stats)\n","\n","        if categorical_features is None:\n","            categorical_features = []\n","        if feature_names is None:\n","            feature_names = [str(i) for i in range(training_data.shape[1])]\n","\n","        self.categorical_features = list(categorical_features)\n","        self.feature_names = list(feature_names)\n","\n","        print('categorical_features :', categorical_features)\n","        print('feature_names :', feature_names)\n","        \n","        self.discretizer = None\n","        if discretize_continuous and not sp.sparse.issparse(training_data):\n","            # Set the discretizer if training data stats are provided\n","            if self.training_data_stats:\n","                discretizer = StatsDiscretizer(\n","                    training_data, self.categorical_features,\n","                    self.feature_names, labels=training_labels,\n","                    data_stats=self.training_data_stats,\n","                    random_state=self.random_state)\n","\n","            if discretizer == 'quartile':\n","                self.discretizer = QuartileDiscretizer(\n","                        training_data, self.categorical_features,\n","                        self.feature_names, labels=training_labels,\n","                        random_state=self.random_state)\n","            elif discretizer == 'decile':\n","                self.discretizer = DecileDiscretizer(\n","                        training_data, self.categorical_features,\n","                        self.feature_names, labels=training_labels,\n","                        random_state=self.random_state)\n","            elif discretizer == 'entropy':\n","                self.discretizer = EntropyDiscretizer(\n","                        training_data, self.categorical_features,\n","                        self.feature_names, labels=training_labels,\n","                        random_state=self.random_state)\n","            elif isinstance(discretizer, BaseDiscretizer):\n","                self.discretizer = discretizer\n","            else:\n","                raise ValueError('''Discretizer must be 'quartile',''' +\n","                                 ''' 'decile', 'entropy' or a''' +\n","                                 ''' BaseDiscretizer instance''')\n","            self.categorical_features = list(range(training_data.shape[1]))\n","\n","            print('discretizer object returned :', self.discretizer) \n","            print('discretizer in use :', discretizer)\n","            \n","            # Get the discretized_training_data when the stats are not provided\n","            if(self.training_data_stats is None):\n","                print('training_data_stats are not provided')\n","                discretized_training_data = self.discretizer.discretize(\n","                    training_data)\n","\n","        if kernel_width is None:\n","            kernel_width = np.sqrt(training_data.shape[1]) * .75\n","        kernel_width = float(kernel_width)\n","\n","        print('kernel_width to be used : ', kernel_width)\n","\n","        if kernel is None:\n","            def kernel(d, kernel_width):\n","                return np.sqrt(np.exp(-(d ** 2) / kernel_width ** 2))\n","\n","        kernel_fn = partial(kernel, kernel_width=kernel_width)\n","\n","        self.feature_selection = feature_selection\n","        self.base = LimeBase(kernel_fn, verbose, random_state=self.random_state)\n","        print('LimeBase object :', self.base)\n","        self.class_names = class_names\n","\n","        print('class_names :', class_names)\n","\n","        # Though set has no role to play if training data stats are provided\n","        self.scaler = sklearn.preprocessing.StandardScaler(with_mean=False)\n","        self.scaler.fit(training_data)\n","        self.feature_values = defaultdict(list)#\n","        self.feature_frequencies = defaultdict(list)#\n","\n","        for feature in self.categorical_features:\n","            if training_data_stats is None:\n","                if self.discretizer is not None:\n","                    column = discretized_training_data[:, feature]\n","                else:\n","                    column = training_data[:, feature]\n","\n","                feature_count = collections.Counter(column)\n","                values, frequencies = map(list, zip(*(sorted(feature_count.items()))))\n","            else:\n","                values = training_data_stats[\"feature_values\"][feature]\n","                frequencies = training_data_stats[\"feature_frequencies\"][feature]\n","\n","            self.feature_values[feature] = values\n","            self.feature_frequencies[feature] = (np.array(frequencies) /\n","                                                 float(sum(frequencies)))\n","            self.scaler.mean_[feature] = 0\n","            self.scaler.scale_[feature] = 1\n","\n","    @staticmethod\n","    def convert_and_round(values):\n","        return ['%.4f' % v for v in values]\n","\n","    @staticmethod\n","    def validate_training_data_stats(training_data_stats):\n","        \"\"\"\n","            Method to validate the structure of training data stats\n","        \"\"\"\n","        stat_keys = list(training_data_stats.keys())\n","        valid_stat_keys = [\"means\", \"mins\", \"maxs\", \"stds\", \"feature_values\", \"feature_frequencies\"]\n","        missing_keys = list(set(valid_stat_keys) - set(stat_keys))\n","        if len(missing_keys) > 0:\n","            raise Exception(\"Missing keys in training_data_stats. Details: %s\" % (missing_keys))\n","\n","    def explain_instance(self,\n","                         data_row,\n","                         predict_fn,\n","                         labels=(1,),\n","                         top_labels=None,\n","                         num_features=10,\n","                         num_samples=5000,\n","                         distance_metric='euclidean',\n","                         model_regressor=None,\n","                         sampling_method='gaussian',\n","                         id=None):\n","        \"\"\"Generates explanations for a prediction.\n","        First, we generate neighborhood data by randomly perturbing features\n","        from the instance (see __data_inverse). We then learn locally weighted\n","        linear models on this neighborhood data to explain each of the classes\n","        in an interpretable way (see lime_base.py).\n","        Args:\n","            data_row: 1d numpy array or scipy.sparse matrix, corresponding to a row\n","            predict_fn: prediction function. For classifiers, this should be a\n","                function that takes a numpy array and outputs prediction\n","                probabilities. For regressors, this takes a numpy array and\n","                returns the predictions. For ScikitClassifiers, this is\n","                `classifier.predict_proba()`. For ScikitRegressors, this\n","                is `regressor.predict()`. The prediction function needs to work\n","                on multiple feature vectors (the vectors randomly perturbed\n","                from the data_row).\n","            labels: iterable with labels to be explained.\n","            top_labels: if not None, ignore labels and produce explanations for\n","                the K labels with highest prediction probabilities, where K is\n","                this parameter.\n","            num_features: maximum number of features present in explanation\n","            num_samples: size of the neighborhood to learn the linear model\n","            distance_metric: the distance metric to use for weights.\n","            model_regressor: sklearn regressor to use in explanation. Defaults\n","                to Ridge regression in LimeBase. Must have model_regressor.coef_\n","                and 'sample_weight' as a parameter to model_regressor.fit()\n","            sampling_method: Method to sample synthetic data. Defaults to Gaussian\n","                sampling. Can also use Latin Hypercube Sampling.\n","        Returns:\n","            An Explanation object (see explanation.py) with the corresponding\n","            explanations.\n","        \"\"\"\n","        print('Inside the explain_instance function')\n","        if sp.sparse.issparse(data_row) and not sp.sparse.isspmatrix_csr(data_row):\n","            # Preventative code: if sparse, convert to csr format if not in csr format already\n","            data_row = data_row.tocsr()\n","\n","        print('data_row \\n', data_row)\n","        data, inverse = self.__data_inverse(data_row, num_samples, sampling_method)\n","        print('data \\n', data)\n","        print('data shape \\n', data.shape)\n","        print('inverse \\n', inverse)\n","        print('inverse shape \\n', inverse.shape)\n","        if sp.sparse.issparse(data):\n","            # Note in sparse case we don't subtract mean since data would become dense\n","            scaled_data = data.multiply(self.scaler.scale_)\n","            # Multiplying with csr matrix can return a coo sparse matrix\n","            if not sp.sparse.isspmatrix_csr(scaled_data):\n","                scaled_data = scaled_data.tocsr()\n","        else:\n","            scaled_data = (data - self.scaler.mean_) / self.scaler.scale_\n","        \n","        print('scaled data \\n', scaled_data)\n","        print('scaled data \\n', scaled_data.shape)\n","        distances = sklearn.metrics.pairwise_distances(\n","                scaled_data,\n","                scaled_data[0].reshape(1, -1),\n","                metric=distance_metric\n","        ).ravel()\n","        print('distances \\n', distances)\n","        print('len distances \\n', len(distances))\n","        yss = predict_fn(inverse)\n","        print('yss \\n ', yss)\n","        print('yss shape \\n', yss.shape)\n","\n","        # for classification, the model needs to provide a list of tuples - classes\n","        # along with prediction probabilities\n","        if self.mode == \"classification\":\n","            if len(yss.shape) == 1:\n","                raise NotImplementedError(\"LIME does not currently support \"\n","                                          \"classifier models without probability \"\n","                                          \"scores. If this conflicts with your \"\n","                                          \"use case, please let us know: \"\n","                                          \"https://github.com/datascienceinc/lime/issues/16\")\n","            elif len(yss.shape) == 2:\n","                if self.class_names is None:\n","                    self.class_names = [str(x) for x in range(yss[0].shape[0])]\n","                else:\n","                    self.class_names = list(self.class_names)\n","                if not np.allclose(yss.sum(axis=1), 1.0):\n","                    warnings.warn(\"\"\"\n","                    Prediction probabilties do not sum to 1, and\n","                    thus does not constitute a probability space.\n","                    Check that you classifier outputs probabilities\n","                    (Not log probabilities, or actual class predictions).\n","                    \"\"\")\n","            else:\n","                raise ValueError(\"Your model outputs \"\n","                                 \"arrays with {} dimensions\".format(len(yss.shape)))\n","\n","        # for regression, the output should be a one-dimensional array of predictions\n","        else:\n","            try:\n","                if len(yss.shape) != 1 and len(yss[0].shape) == 1:\n","                    yss = np.array([v[0] for v in yss])\n","                assert isinstance(yss, np.ndarray) and len(yss.shape) == 1\n","            except AssertionError:\n","                raise ValueError(\"Your model needs to output single-dimensional \\\n","                    numpyarrays, not arrays of {} dimensions\".format(yss.shape))\n","\n","            predicted_value = yss[0]\n","            print('predicted value \\n', predicted_value)\n","            min_y = min(yss)\n","            print('min_y value \\n', min_y)\n","            max_y = max(yss)\n","            print('max_y value \\n', max_y)\n","\n","            # add a dimension to be compatible with downstream machinery\n","            yss = yss[:, np.newaxis]\n","            print('yss new shape \\n', yss.shape)\n","\n","        feature_names = copy.deepcopy(self.feature_names)\n","        print('feature_names ', feature_names)\n","        if feature_names is None:\n","            print('feature_names is None')\n","            feature_names = [str(x) for x in range(data_row.shape[0])]\n","            print('feature_names after assignment ', feature_names)\n","\n","        if sp.sparse.issparse(data_row):\n","            values = self.convert_and_round(data_row.data)\n","            feature_indexes = data_row.indices\n","        else:\n","            values = self.convert_and_round(data_row)\n","            feature_indexes = None\n","\n","        for i in self.categorical_features:\n","            if self.discretizer is not None and i in self.discretizer.lambdas:\n","                continue\n","            name = int(data_row[i])\n","            print('name ', name)\n","            if i in self.categorical_names:\n","                name = self.categorical_names[i][name]\n","            feature_names[i] = '%s=%s' % (feature_names[i], name)\n","            values[i] = 'True'\n","        categorical_features = self.categorical_features\n","\n","        discretized_feature_names = None\n","        print('discretized feature names \\n', discretized_feature_names)\n","\n","        if self.discretizer is not None:\n","            print('discretizer is NOT none')\n","            categorical_features = range(data.shape[1])\n","            print('data_row before discretization ', data_row)\n","            print('data_row type ', type(data_row))\n","            print('data_row shape before discretization ', data_row.shape)\n","            discretized_instance = self.discretizer.discretize(data_row)\n","            print('discretized_instance after discretzation \\n', discretized_instance)  \n","            discretized_feature_names = copy.deepcopy(feature_names)\n","            print('discretized_feature_names \\n', discretized_feature_names)\n","            for f in self.discretizer.names:\n","                discretized_feature_names[f] = self.discretizer.names[f][int(\n","                        discretized_instance[f])]\n","\n","        print('discretized_feature_names \\n', discretized_feature_names)\n","        domain_mapper = TableDomainMapper(feature_names,\n","                                          values,\n","                                          scaled_data[0],\n","                                          categorical_features=categorical_features,\n","                                          discretized_feature_names=discretized_feature_names,\n","                                          feature_indexes=feature_indexes)\n","        print('domain_mapper object ', domain_mapper)\n","        print('domain_mapper feature names \\n ', domain_mapper.feature_names)\n","        print('scaled_data[0] ', scaled_data[0])\n","        print('discretized_feature_names \\n ',domain_mapper.discretized_feature_names)\n","        ret_exp = Explanation(domain_mapper,\n","                                          mode=self.mode,\n","                                          class_names=self.class_names,\n","                                          explanation_id=id)\n","        print('ret_exp object', ret_exp)\n","        print('local_exp object ', ret_exp.local_exp)\n","        print('ret_exp intercept \\n ', ret_exp.intercept)\n","\n","        if self.mode == \"classification\":\n","            ret_exp.predict_proba = yss[0]\n","            if top_labels:\n","                labels = np.argsort(yss[0])[-top_labels:]\n","                ret_exp.top_labels = list(labels)\n","                ret_exp.top_labels.reverse()\n","        else:\n","            print('regression')\n","            ret_exp.predicted_value = predicted_value\n","            ret_exp.min_value = min_y\n","            ret_exp.max_value = max_y\n","            print('ret_exp type', type(ret_exp))\n","            print('ret_exp predicted_value ', ret_exp.predicted_value)\n","            print('ret_exp min_value ', ret_exp.min_value)\n","            print('ret_exp max_value ', ret_exp.max_value)\n","            labels = [0]\n","\n","        for label in labels:\n","            print('labels ', label)\n","            print('scaled data is ', scaled_data)\n","            print('scaled data shape ', scaled_data.shape)\n","            print('yss is ', yss)\n","            print('yss shape ', yss.shape)\n","            print('distances ', distances)\n","            print('distances shape ', distances.shape)\n","            print()\n","            print('num features ', num_features)\n","            print('model regressor ', model_regressor)\n","            print('feature selection ', self.feature_selection)\n","            print()\n","            print(f'Printing the values for LABEL {label}')\n","            print('ret exp predicted value ', ret_exp.predicted_value)\n","            print('ret exp min value ', ret_exp.min_value)\n","            print('ret exp max value ', ret_exp.max_value)\n","            print('ret exp intercept ', ret_exp.intercept)\n","            print('ret exp intercept label ', ret_exp.intercept[label])\n","            print('ret exp local exp ', ret_exp.local_exp)\n","            print('ret exp local exp label ', ret_exp.local_exp[label])\n","            print('ret exp score ', ret_exp.score)\n","            print('ret exp score label ', ret_exp.score[label])\n","            print('ret exp local pred ', ret_exp.local_pred)\n","            print('type of ret exp local pred ', type(ret_exp.local_pred))\n","            print('ret exp loxal pred label ', ret_exp.local_pred[label])\n","            print()\n","            print(f'assignment for label {label}')\n","            (ret_exp.intercept[label],\n","            ret_exp.local_exp[label],\n","            ret_exp.score[label],\n","            ret_exp.local_pred[label]) = self.base.explain_instance_with_data(\n","                    scaled_data,\n","                    yss,\n","                    distances,\n","                    label,\n","                    num_features,\n","                    model_regressor=model_regressor,\n","                    feature_selection=self.feature_selection)\n","    \n","        if self.mode == \"regression\":\n","            ret_exp.intercept[1] = ret_exp.intercept[0]\n","            ret_exp.local_exp[1] = [x for x in ret_exp.local_exp[0]]\n","            ret_exp.local_exp[0] = [(i, -1 * j) for i, j in ret_exp.local_exp[1]]\n","\n","            print('ret_exp.intercept[1] ', ret_exp.intercept[0])\n","            print('ret_exp.local_exp[1] ', ret_exp.local_exp[1])\n","            print('ret_exp.local_exp[0] ', ret_exp.local_exp[0])\n","\n","        return ret_exp\n","\n","    def __data_inverse(self,\n","                       data_row,\n","                       num_samples,\n","                       sampling_method):\n","        \"\"\"Generates a neighborhood around a prediction.\n","        For numerical features, perturb them by sampling from a Normal(0,1) and\n","        doing the inverse operation of mean-centering and scaling, according to\n","        the means and stds in the training data. For categorical features,\n","        perturb by sampling according to the training distribution, and making\n","        a binary feature that is 1 when the value is the same as the instance\n","        being explained.\n","        Args:\n","            data_row: 1d numpy array, corresponding to a row\n","            num_samples: size of the neighborhood to learn the linear model\n","            sampling_method: 'gaussian' or 'lhs'\n","        Returns:\n","            A tuple (data, inverse), where:\n","                data: dense num_samples * K matrix, where categorical features\n","                are encoded with either 0 (not equal to the corresponding value\n","                in data_row) or 1. The first row is the original instance.\n","                inverse: same as data, except the categorical features are not\n","                binary, but categorical (as the original data)\n","        \"\"\"\n","        is_sparse = sp.sparse.issparse(data_row)\n","        if is_sparse:\n","            num_cols = data_row.shape[1]\n","            data = sp.sparse.csr_matrix((num_samples, num_cols), dtype=data_row.dtype)\n","        else:\n","            num_cols = data_row.shape[0]\n","            data = np.zeros((num_samples, num_cols))\n","        categorical_features = range(num_cols)\n","        if self.discretizer is None:\n","            instance_sample = data_row\n","            scale = self.scaler.scale_\n","            mean = self.scaler.mean_\n","            if is_sparse:\n","                # Perturb only the non-zero values\n","                non_zero_indexes = data_row.nonzero()[1]\n","                num_cols = len(non_zero_indexes)\n","                instance_sample = data_row[:, non_zero_indexes]\n","                scale = scale[non_zero_indexes]\n","                mean = mean[non_zero_indexes]\n","\n","            if sampling_method == 'gaussian':\n","                data = self.random_state.normal(0, 1, num_samples * num_cols\n","                                                ).reshape(num_samples, num_cols)\n","                data = np.array(data)\n","            elif sampling_method == 'lhs':\n","                data = lhs(num_cols, samples=num_samples\n","                           ).reshape(num_samples, num_cols)\n","                means = np.zeros(num_cols)\n","                stdvs = np.array([1]*num_cols)\n","                for i in range(num_cols):\n","                    data[:, i] = norm(loc=means[i], scale=stdvs[i]).ppf(data[:, i])\n","                data = np.array(data)\n","            else:\n","                warnings.warn('''Invalid input for sampling_method.\n","                                 Defaulting to Gaussian sampling.''', UserWarning)\n","                data = self.random_state.normal(0, 1, num_samples * num_cols\n","                                                ).reshape(num_samples, num_cols)\n","                data = np.array(data)\n","\n","            if self.sample_around_instance:\n","                data = data * scale + instance_sample\n","            else:\n","                data = data * scale + mean\n","            if is_sparse:\n","                if num_cols == 0:\n","                    data = sp.sparse.csr_matrix((num_samples,\n","                                                 data_row.shape[1]),\n","                                                dtype=data_row.dtype)\n","                else:\n","                    indexes = np.tile(non_zero_indexes, num_samples)\n","                    indptr = np.array(\n","                        range(0, len(non_zero_indexes) * (num_samples + 1),\n","                              len(non_zero_indexes)))\n","                    data_1d_shape = data.shape[0] * data.shape[1]\n","                    data_1d = data.reshape(data_1d_shape)\n","                    data = sp.sparse.csr_matrix(\n","                        (data_1d, indexes, indptr),\n","                        shape=(num_samples, data_row.shape[1]))\n","            categorical_features = self.categorical_features\n","            first_row = data_row\n","        else:\n","            first_row = self.discretizer.discretize(data_row)\n","        data[0] = data_row.copy()\n","        inverse = data.copy()\n","        for column in categorical_features:\n","            values = self.feature_values[column]\n","            freqs = self.feature_frequencies[column]\n","            inverse_column = self.random_state.choice(values, size=num_samples,\n","                                                      replace=True, p=freqs)\n","            binary_column = (inverse_column == first_row[column]).astype(int)\n","            binary_column[0] = 1\n","            inverse_column[0] = data[0, column]\n","            data[:, column] = binary_column\n","            inverse[:, column] = inverse_column\n","        if self.discretizer is not None:\n","            inverse[1:] = self.discretizer.undiscretize(inverse[1:])\n","        inverse[0] = data_row\n","        return data, inverse"],"metadata":{"id":"5eayhLlRy9bJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Setting flags for running explanation"],"metadata":{"id":"tOv7h5940yRU"}},{"cell_type":"code","source":["ensemble = True \n","dropout = False \n","dropconnect = False \n","flipout = False "],"metadata":{"id":"kTJFeQH01Fze"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Keras uncertainty specific imports "],"metadata":{"id":"UbgkFnCQ526A"}},{"cell_type":"code","source":["import numpy as np \n","import tensorflow as tf \n","from tensorflow.keras.models import load_model\n","import random\n","import pandas as pd \n","import os \n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","import math \n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Input\n","\n","import keras_uncertainty\n","from keras_uncertainty.models import StochasticRegressor, TwoHeadStochasticRegressor\n","from keras_uncertainty.models.DeepEnsembleClassifier import DeepEnsemble\n","\n","from keras_uncertainty.layers import DropConnectDense, VariationalDense, FlipoutDense, StochasticDropout\n","from keras_uncertainty.metrics import gaussian_interval_score\n","from keras_uncertainty.losses import regression_gaussian_nll_loss, regression_gaussian_beta_nll_loss\n","import matplotlib.pyplot as plt\n","\n","np.set_printoptions(suppress=True) \n","\n","import tensorflow as tf\n","tf.compat.v1.disable_eager_execution()\n","\n","# if eager execution is not disabled following error occurs:\n","# TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), \n","#dtype=tf.float32, name=None), name='Placeholder:0', description=\"created \n","#by layer 'tf.cast_4'\"), an intermediate Keras symbolic input/output, \n","#to a TF API that does not allow registering custom dispatchers, \n","#such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. \n","#Keras Functional model construction only supports TF API calls that \n","#*do* support dispatching, such as `tf.math.add` or `tf.reshape`. \n","#Other APIs cannot be called directly on symbolic Kerasinputs/outputs. \n","#You can work around this limitation by putting the operation in a custom \n","#Keras layer `call` and calling that layer on this symbolic input/output."],"metadata":{"id":"ulzQcfUzu8HJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645794222280,"user_tz":-60,"elapsed":2989,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"51f19e67-a995-43a0-f212-c82a4a8f1c4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Keras Uncertainty will use standalone Keras backend"]}]},{"cell_type":"markdown","source":["## Load Dataset"],"metadata":{"id":"gzjvMnaowZqd"}},{"cell_type":"code","source":["# load the california housing data from csv\n","train_file = '/content/sample_data/california_housing_train.csv'\n","test_file = '/content/sample_data/california_housing_test.csv'\n","\n","train_combined = pd.read_csv(train_file)\n","test = pd.read_csv(test_file)\n","\n","# split the data in validation and test (from test.csv)\n","train, val = train_test_split(train_combined, test_size=0.25)\n","\n","feature_names = list(train_combined.columns)\n","print(feature_names)\n","\n","# assign the target variable\n","target = 'median_house_value'\n","\n","# extract the target label in all sets\n","train_labels_df= train[target]\n","val_labels_df = val[target]\n","test_labels_df = test[target]\n","\n","# extract the data from all sets \n","train_data_df = train.drop(columns=target, axis=1)\n","val_data_df = val.drop(columns=target, axis=1)\n","test_data_df = test.drop(columns=target, axis=1)\n","\n","train_data_unnormalized = train_data_df.to_numpy()\n","train_labels_unnormalized = train_labels_df.to_numpy()\n","\n","val_data_unnormalized = val_data_df.to_numpy()\n","val_labels_unnormalized = val_labels_df.to_numpy()\n","\n","test_data_unnormalized = test_data_df.to_numpy()\n","test_labels_unnormalized = test_labels_df.to_numpy()\n","\n","# normalize the data using minmax \n","minmax = MinMaxScaler() \n","\n","train_data = minmax.fit_transform(train_data_unnormalized)\n","train_label_temp = np.expand_dims(train_labels_unnormalized, axis=1)\n","train_labels = minmax.fit_transform(train_label_temp)\n","\n","val_data = minmax.fit_transform(val_data_unnormalized)\n","val_label_temp = np.expand_dims(val_labels_unnormalized, axis=1)\n","val_labels = minmax.fit_transform(val_label_temp)\n","\n","test_data = minmax.fit_transform(test_data_unnormalized)\n","test_label_temp = np.expand_dims(test_labels_unnormalized, axis=1)\n","test_labels = minmax.fit_transform(test_label_temp)\n","\n","\n","print('Training data shape \\n', train_data.shape)\n","print('Training labels shape \\n', train_labels.shape)\n","#print('Training data \\n ', train_data)\n","#print('Training labels \\n ', train_labels)\n","\n","print('Validation data shape \\n ',val_data.shape)\n","print('Validation labels shape \\n ', val_labels.shape)\n","#print('Validation data \\n ', val_data)\n","#print('Validation labels \\n ', val_labels)\n","\n","print('Test data shape \\n ', test_data.shape)\n","print('Test labels shape \\n ', test_labels.shape)\n","#print('Test data \\n ', test_data)\n","#print('Test labels \\n ', test_labels)"],"metadata":{"id":"pO9E_83jinx9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645794222283,"user_tz":-60,"elapsed":26,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"19ac1465-c3af-4b0c-8bdd-2bddfc9cf751"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value']\n","Training data shape \n"," (12750, 8)\n","Training labels shape \n"," (12750, 1)\n","Validation data shape \n","  (4250, 8)\n","Validation labels shape \n","  (4250, 1)\n","Test data shape \n","  (3000, 8)\n","Test labels shape \n","  (3000, 1)\n"]}]},{"cell_type":"markdown","source":["## DeepEnsembleRegressor"],"metadata":{"id":"E21T-phMxY2E"}},{"cell_type":"code","source":["class DeepEnsembleRegressor(DeepEnsemble):\n","    \"\"\"\n","        Implementation of a Deep Ensemble for regression.\n","        Uses two models, one for training and another for inference/testing. The user has to provide a model function that returns\n","        the train and test models, and use the provided deep_ensemble_nll_loss for training.\n","    \"\"\"\n","    def __init__(self, model_fn=None, num_estimators=None, models=None):\n","        \"\"\"\n","            Builds a Deep Ensemble given a function to make model instances, and the number of estimators.\n","            For training it uses a model that only outputs the mean, while the loss uses both the mean and variance produced by the model.\n","            For testing, a model that shares weights with the training model is used, but the testing model outputs both mean and variance. The final\n","            prediction is made with a mixture of gaussians, where each gaussian is one trained model instance.\n","        \"\"\"\n","        super().__init__(model_fn=model_fn, num_estimators=num_estimators, models=models,\n","                         needs_test_estimators=True)\n","\n","    def fit(self, X, y, epochs=10, batch_size=32, **kwargs):\n","        \"\"\"\n","            Fits the Deep Ensemble, each estimator is fit independently on the same data.\n","        \"\"\"\n","\n","        for i in range(self.num_estimators):\n","            history = self.train_estimators[i].fit(X, y, epochs=epochs, batch_size=batch_size, **kwargs)\n","\n","\n","            #if not os.path.exists(path+'/results/ensemble'):\n","            #    os.makedirs(path+'/results/ensemble')\n","\n","            # plotting history for individual ensemble component \n","            plt.plot(range(epochs), history.history['loss'], label='training loss')\n","            plt.plot(range(epochs), history.history['val_loss'], label='val loss')\n","            plt.xlabel('epochs')\n","            plt.ylabel('loss')\n","            plt.title('Ensemble component '+str(i)+' loss plot')\n","            plt.legend()\n","            #plt.savefig(path+'results/ensemble/loss_plot_'+str(i)+'.pdf')\n","            plt.show()\n","\n","            plt.plot(range(epochs), history.history['mae'], label='training mae')\n","            plt.plot(range(epochs), history.history['val_mae'], label='val mae')\n","            plt.legend()\n","            plt.xlabel('epochs')\n","            plt.ylabel('mae')\n","            plt.title('Ensemble component '+str(i)+' mae plot') \n","            #plt.savefig(path+'results/ensemble/mae_plot_'+str(i)+'.pdf')\n","            plt.show()\n","            \n","            # saving the individual ensemble component \n","            #self.train_estimators[i].save(path+'results/ensemble/model_'+str(i)+'.h5')\n","    \n","    def fit_generator(self, generator, epochs=10, **kwargs):\n","        \"\"\"\n","            Fits the Deep Ensemble, each estimator is fit independently on the same data.\n","        \"\"\"\n","\n","        for i in range(self.num_estimators):\n","            self.train_estimators[i].fit_generator(generator, epochs=epochs, **kwargs)\n","            \n","\n","    def predict_mean(self, X, batch_size=32, output_scaler=None, num_ensembles=None, disentangle_uncertainty=False, **kwargs):\n","        \"\"\"\n","            Makes a prediction. Predictions from each estimator are used to build a gaussian mixture and its mean and standard deviation returned.\n","        \"\"\"\n","        \n","        means = []\n","        variances = []\n","\n","        if num_ensembles is None:\n","            estimators = self.test_estimators\n","        else:\n","            estimators = self.test_estimators[:num_ensembles]\n","\n","        if \"verbose\" not in kwargs:\n","            kwargs[\"verbose\"] = 0\n","\n","    \n","        for estimator in estimators:\n","            mean, var  = estimator.predict(X, batch_size=batch_size, **kwargs)\n","\n","            if output_scaler is not None:\n","                mean = output_scaler.inverse_transform(mean)\n","\n","                # This should work but not sure if its 100% correct\n","                # Its not clear how to do inverse scaling of the variance\n","                sqrt_var = np.sqrt(var)\n","                var = output_scaler.inverse_transform(sqrt_var)\n","                var = np.square(var)\n","\n","            means.append(mean)\n","            variances.append(var)\n","\n","        means = np.array(means)\n","        variances = np.array(variances)\n","        \n","        mixture_mean = np.mean(means, axis=0)\n","        mixture_var  = np.mean(variances + np.square(means), axis=0) - np.square(mixture_mean)\n","        mixture_var[mixture_var < 0.0] = 0.0\n","                \n","        if disentangle_uncertainty:\n","            epi_var = np.var(means, axis=0)\n","            ale_var = np.mean(variances, axis=0)\n","\n","            return mixture_mean, np.sqrt(ale_var), np.sqrt(epi_var)\n","\n","        #return mixture_mean, np.sqrt(mixture_var)\n","        return mixture_mean\n","\n","\n","    # INTENTIONALLY REPLICATING THE CODE BODY HOWEVER NOTICE THAT THE RETURN STATEMENTS ARE DIFFERENT FOR ALL THESE PREDICT FUNCTIONS (split the predict function into 3 parts: \n","    # predict_mean, predict_std and generate_....... so that these functions could be passed into the lime code to generate explanations)\n","    def predict_std(self, X, batch_size=32, output_scaler=None, num_ensembles=None, disentangle_uncertainty=False, **kwargs):\n","        \"\"\"\n","            Makes a prediction. Predictions from each estimator are used to build a gaussian mixture and its mean and standard deviation returned.\n","        \"\"\"\n","        \n","        means = []\n","        variances = []\n","\n","        if num_ensembles is None:\n","            estimators = self.test_estimators\n","        else:\n","            estimators = self.test_estimators[:num_ensembles]\n","\n","        if \"verbose\" not in kwargs:\n","            kwargs[\"verbose\"] = 0\n","\n","        for estimator in estimators:\n","            mean, var  = estimator.predict(X, batch_size=batch_size, **kwargs)\n","\n","            if output_scaler is not None:\n","                mean = output_scaler.inverse_transform(mean)\n","\n","                # This should work but not sure if its 100% correct\n","                # Its not clear how to do inverse scaling of the variance\n","                sqrt_var = np.sqrt(var)\n","                var = output_scaler.inverse_transform(sqrt_var)\n","                var = np.square(var)\n","\n","            means.append(mean)\n","            variances.append(var)\n","\n","        means = np.array(means)\n","        variances = np.array(variances)\n","        \n","        mixture_mean = np.mean(means, axis=0)\n","        mixture_var  = np.mean(variances + np.square(means), axis=0) - np.square(mixture_mean)\n","        mixture_var[mixture_var < 0.0] = 0.0\n","                \n","        if disentangle_uncertainty:\n","            epi_var = np.var(means, axis=0)\n","            ale_var = np.mean(variances, axis=0)\n","\n","            return mixture_mean, np.sqrt(ale_var), np.sqrt(epi_var)\n","\n","        #return mixture_mean, np.sqrt(mixture_var)\n","        return np.sqrt(mixture_var)\n","\n","\n","    # INTENTIONALLY REPLICATING THE CODE BODY HOWEVER NOTICE THAT THE RETURN STATEMENTS ARE DIFFERENT FOR ALL THESE PREDICT FUNCTIONS \n","    def generate_sample_from_predicted_mean_and_std(self, X, batch_size=32, output_scaler=None, num_ensembles=None, disentangle_uncertainty=False, **kwargs):\n","        \"\"\"\n","            Makes a prediction. Predictions from each estimator are used to build a gaussian mixture and its mean and standard deviation returned.\n","        \"\"\"\n","        \n","        means = []\n","        variances = []\n","\n","        if num_ensembles is None:\n","            estimators = self.test_estimators\n","        else:\n","            estimators = self.test_estimators[:num_ensembles]\n","\n","        if \"verbose\" not in kwargs:\n","            kwargs[\"verbose\"] = 0\n","\n","        for estimator in estimators:\n","            mean, var  = estimator.predict(X, batch_size=batch_size, **kwargs)\n","\n","            if output_scaler is not None:\n","                mean = output_scaler.inverse_transform(mean)\n","\n","                # This should work but not sure if its 100% correct\n","                # Its not clear how to do inverse scaling of the variance\n","                sqrt_var = np.sqrt(var)\n","                var = output_scaler.inverse_transform(sqrt_var)\n","                var = np.square(var)\n","            \n","            means.append(mean)\n","            variances.append(var)\n","\n","        means = np.array(means)\n","        variances = np.array(variances)\n","        \n","        mixture_mean = np.mean(means, axis=0)\n","        mixture_var  = np.mean(variances + np.square(means), axis=0) - np.square(mixture_mean)\n","        mixture_var[mixture_var < 0.0] = 0.0\n","                \n","        if disentangle_uncertainty:\n","            epi_var = np.var(means, axis=0)\n","            ale_var = np.mean(variances, axis=0)\n","\n","            return mixture_mean, np.sqrt(ale_var), np.sqrt(epi_var)\n","\n","        #return mixture_mean, np.sqrt(mixture_var)\n","        print('mean \\n', mean)\n","        print('std \\n', mixture_var)\n","\n","        sample = np.random.normal(mixture_mean, np.sqrt(mixture_var))\n","        print('sample : \\n', sample)\n","        print('mean sample : \\n', np.mean(sample))\n","        print('sample shape : \\n', sample.shape)\n","        return sample\n","\n","    def predict_generator(self, generator, steps=None, num_ensembles=None, **kwargs):\n","        \"\"\"\n","            Makes a prediction. Predictions from each estimator are used to build a gaussian mixture and its mean and standard deviation returned.\n","        \"\"\"\n","        \n","        means = []\n","        variances = []\n","\n","        if num_ensembles is None:\n","            estimators = self.test_estimators\n","        else:\n","            estimators = self.test_estimators[:num_ensembles]\n","\n","        for estimator in estimators:\n","            mean, var  = estimator.predict_generator(generator, steps=steps, **kwargs)\n","            means.append(mean)\n","            variances.append(var)\n","\n","        means = np.array(means)\n","        variances = np.array(variances)\n","        \n","        mixture_mean = np.mean(means, axis=0)\n","        mixture_var  = np.mean(variances + np.square(means), axis=0) - np.square(mixture_mean)\n","        mixture_var[mixture_var < 0.0] = 0.0\n","                \n","        return mixture_mean, np.sqrt(mixture_var)"],"metadata":{"id":"4R4zIVECxXTl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ensemble Explanation"],"metadata":{"id":"CzfEmCCj0V-e"}},{"cell_type":"code","source":["# ENSEMBLE MODEL\n","def train_ensemble_model(x_train, y_train, x_val, y_val, x_test, epochs, num_estimators):\n","    def model():\n","        # this model definition has been obtained from the hyperparameter optimization \n","        # not the last layer though\n","        inp = Input(shape=(8,))\n","        x = Dense(4, activation='tanh')(inp)\n","        x = Dense(4, activation='tanh')(x)\n","        x = Dense(4, activation='tanh')(x)\n","        x = Dense(4, activation='tanh')(x)\n","        x = Dense(4, activation='tanh')(x)\n","        mean = Dense(1, activation='softplus')(x)\n","        var = Dense(1, activation='softplus')(x)\n","\n","        train_model = Model(inp, mean)\n","        pred_model = Model(inp, [mean, var])\n","\n","        train_model.compile(loss=regression_gaussian_nll_loss(var), optimizer='sgd', metrics=['mae'])\n","        \n","        return train_model, pred_model\n","\n","    model = DeepEnsembleRegressor(model, num_estimators=num_estimators) \n","    model.fit(x_train, y_train, validation_data=(x_val, y_val), verbose=2, epochs=epochs)\n","    pred_mean = model.predict_mean(x_test)\n","    pred_std = model.predict_std(x_test)\n","    sample = model.generate_sample_from_predicted_mean_and_std(x_test)\n","       \n","    return pred_mean, pred_std, sample, model"],"metadata":{"id":"S99XcJHaMa6w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train_data_adjusted = np.expand_dims(train_data, axis=-1)\n","\n","\n","#print('Number of estimators in ensemble ', num_estimators)\n","prediction_mean, prediction_std, prediction_samples, ensemble_model = train_ensemble_model(train_data, train_labels, val_data, val_labels, test_data, epochs=2, num_estimators=2)\n","print('prediction mean :\\n', prediction_mean)\n","print('prediction std :\\n', prediction_std)\n","print('prediction samples :\\n', prediction_samples)\n","#print('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')"],"metadata":{"id":"tI7V3Ab7Cfum","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1645794232985,"user_tz":-60,"elapsed":9600,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"95b33718-7ef3-4dee-a4a4-8528ea4de3e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 12750 samples, validate on 4250 samples\n","Epoch 1/2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"output_type":"stream","name":"stdout","text":["12750/12750 - 1s - loss: -6.9264e-01 - mae: 0.1948 - val_loss: -8.1784e-01 - val_mae: 0.1857 - 1s/epoch - 99us/sample\n","Epoch 2/2\n","12750/12750 - 1s - loss: -8.2898e-01 - mae: 0.1897 - val_loss: -8.4767e-01 - val_mae: 0.1858 - 794ms/epoch - 62us/sample\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["Train on 12750 samples, validate on 4250 samples\n","Epoch 1/2\n","12750/12750 - 1s - loss: -5.4179e-01 - mae: 0.2261 - val_loss: -7.6416e-01 - val_mae: 0.1917 - 1s/epoch - 91us/sample\n","Epoch 2/2\n","12750/12750 - 1s - loss: -8.0343e-01 - mae: 0.1904 - val_loss: -8.3036e-01 - val_mae: 0.1864 - 943ms/epoch - 74us/sample\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]},{"output_type":"stream","name":"stdout","text":["mean \n"," [[0.4086678 ]\n"," [0.40178916]\n"," [0.40277785]\n"," ...\n"," [0.39903474]\n"," [0.40043527]\n"," [0.4072382 ]]\n","std \n"," [[0.11494827]\n"," [0.11478642]\n"," [0.11510794]\n"," ...\n"," [0.11596681]\n"," [0.11485112]\n"," [0.11463745]]\n","sample : \n"," [[1.17479938]\n"," [0.46630775]\n"," [0.51894137]\n"," ...\n"," [0.4096666 ]\n"," [0.13470966]\n"," [0.52042098]]\n","mean sample : \n"," 0.3976031572095636\n","sample shape : \n"," (3000, 1)\n","prediction mean :\n"," [[0.40176186]\n"," [0.39774603]\n"," [0.39858013]\n"," ...\n"," [0.39672443]\n"," [0.39699453]\n"," [0.40071657]]\n","prediction std :\n"," [[0.33904022]\n"," [0.33880144]\n"," [0.3392756 ]\n"," ...\n"," [0.340539  ]\n"," [0.3388969 ]\n"," [0.33858153]]\n","prediction samples :\n"," [[1.17479938]\n"," [0.46630775]\n"," [0.51894137]\n"," ...\n"," [0.4096666 ]\n"," [0.13470966]\n"," [0.52042098]]\n"]}]},{"cell_type":"code","source":["def lime_explanation_ensemble(train_input, train_labels, test_input, feature_names, model, pred_fn, flag):\n","    explainer = LimeTabularExplainer(training_data=train_input, \n","                                     mode='regression',\n","                                     training_labels=train_labels, \n","                                     feature_names=feature_names[:-1],\n","                                     verbose=True,\n","                                     random_state=0)\n","\n","    inputs_to_be_explained = test_input.shape[0]\n","    for i in range(inputs_to_be_explained):\n","        print('input data : ', test_input[i])\n","        exp = explainer.explain_instance(data_row=test_input[i], \n","                                         predict_fn=pred_fn, \n","                                         num_features=8,\n","                                         id=i)\n","        print('EXP OBJECT IS ', exp)\n","        exp.show_in_notebook(show_table=True)\n","        print('ATTRIBUTE OF THE EXPLANATIONS : ')\n","        print('class names ', exp.class_names)\n","        print('domain mapper ', exp.domain_mapper)\n","        print('dummy label ', exp.dummy_label)\n","        print('intercept ', exp.intercept)\n","        print('local exp[0] ', exp.local_exp[0])\n","        print('local exp[1] ', exp.local_exp[1])\n","        print('local pred ', exp.local_pred)\n","        print('max value ', exp.max_value)\n","        print('min value ', exp.min_value)\n","        print('mode ', exp.mode)\n","        print('random state ', exp.random_state)\n","        print('predicted value ', exp.predicted_value)\n","        print('score ', exp.score)\n","\n","        #print('Function values ')\n","        #print('HTML ')\n","        #print(exp.as_html(exp.dummy_label, True, True))\n","        print('explanation out as list ', exp.as_list(label=exp.dummy_label))\n","        exp.as_pyplot_figure(True)\n","        plt.savefig('/content/explanation_pyplot_'+str(i)+'.pdf')\n","        plt.show()\n","        print(f'PLOT {i} SAVED SUCCESSFULLY')\n","        #print(e)\n","        print('explanation as map ', exp.as_map())\n","        #plt.clf()\n","        print('COUNTER IS ', i)\n","        print('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n","\n","        #exp.available_labels()\n","\n","    print('This explanation is generated with ', flag, ' as input ')"],"metadata":{"id":"RFT0qFMU0hz4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# drawing a sample from the distribution that is defined by the pred_mean and pred_std \n","# explanation of pred_mean \n","\n","#print(test_input.shape)\n","#print(train_data.shape)\n","\n","#count = 1\n","\n","# Analysis of the input \n","num_of_samples_to_be_explained = 5\n","start_index = np.random.randint(0, test_data.shape[0])\n","print('start_index : ', start_index)\n","\n","test_input = test_data[start_index:start_index+num_of_samples_to_be_explained]\n","print('test_input shape :', test_input.shape)\n","\n","test_input_adj = np.expand_dims(test_input, axis=-1)\n","print('test_input_adj shape :', test_input_adj.shape)\n","\n","\n","lime_explanation_ensemble(train_data, \n","                          train_labels, \n","                          test_input, \n","                          feature_names, \n","                          ensemble_model, \n","                          ensemble_model.generate_sample_from_predicted_mean_and_std, \n","                          'SAMPLE')\n","\n","#print('feature_name ', feature_names) \n","#print('test input ', test_input)\n","#print('prediction sample ', ensemble_model.generate_sample_from_predicted_mean_and_std(test_input_adj))"],"metadata":{"id":"9xnMSJzg60V3","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1aLhiGSIp0nKnDvRscgRV_2N7aYGbz2lR","height":1000},"executionInfo":{"status":"ok","timestamp":1645794253802,"user_tz":-60,"elapsed":20506,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"outputId":"73cc0465-60f1-4692-c041-271f29663a57"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# probably this is how the limits (those besides the name of the features) are provided next to the features: \n","print('the quartiles next to the feature importance bar')\n","for feat in range(len(feature_names[:-1])):\n","    print(feature_names[feat])\n","    print(np.array(np.percentile(train_data[:, feat], [25, 50, 75])))"],"metadata":{"id":"erw8UxNk4QvY","executionInfo":{"status":"ok","timestamp":1645794253805,"user_tz":-60,"elapsed":47,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8543e42-a025-4090-99a7-f5bfe1bfa49d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["the quartiles next to the feature importance bar\n","longitude\n","[0.25423307 0.58366534 0.63247012]\n","latitude\n","[0.14680851 0.18085106 0.54893617]\n","housing_median_age\n","[0.33333333 0.54901961 0.70588235]\n","total_rooms\n","[0.03856597 0.05606959 0.08298405]\n","total_bedrooms\n","[0.05375754 0.07917352 0.11830316]\n","population\n","[0.02211385 0.03268029 0.04829171]\n","households\n","[0.05378832 0.07865818 0.11644496]\n","median_income\n","[0.14177046 0.20984883 0.29425111]\n"]}]},{"cell_type":"code","source":["# additional references \n","# https://colab.research.google.com/github/GoogleCloudPlatform/ml-on-gcp/blob/master/tutorials/explanations/ai-explanations-tabular.ipynb?hl=ko#scrollTo=BZiM7kywQy6j \n","# lime_image.ipynb\n","# theoretical explanation of how LIME actually works :\n","# https://cran.r-project.org/web/packages/lime/vignettes/Understanding_lime.html\n","# https://github.com/marcotcr/lime/issues/113\n","# https://colab.research.google.com/github/GoogleCloudPlatform/ml-on-gcp/blob/master/tutorials/explanations/ai-explanations-tabular.ipynb?hl=ko#scrollTo=qnMpW5Y9nv2l\n","#https://www.inovex.de/de/blog/lime-machine-learning-interpretability/\n","# https://algotech.netlify.app/blog/interpreting-black-box-regression-model-with-lime/#:~:text=There%20exist%20a%20method%20called,model%20locally%20around%20the%20prediction.\n","# https://coderzcolumn.com/tutorials/machine-learning/how-to-use-lime-to-understand-sklearn-models-predictions"],"metadata":{"id":"qNtJc5htrJv7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# video explaining lime (these provide a basic overview, not that useful)\n","# https://www.youtube.com/watch?v=C80SQe16Rao\n","# https://www.youtube.com/watch?v=GuAXlV3iBR4"],"metadata":{"id":"IlEglKnZIigk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","\n","# TESTBED FOR HISTOGRAM DETAILING\n","import random \n","import matplotlib.pyplot as plt\n","\n","cont = 1\n","\n","for i in range(cont):\n","    \n","    #exp = self.as_list(label=label, **kwargs)\n","    fig = plt.figure(figsize=(15, 5))\n","    #vals = [-0.0015642910097497709, -0.006193702109735619, 0.007176534335879772, \n","    #        -0.0075631914531472675, -0.011606796695305309, 0.013962026656112023, \n","    #        -0.017696851420039194, -0.0246349957951464]\n","    vals = [random.randrange(-50, 50, 8) for i in range(8)]\n","    print(vals)\n","    names = ['0.33 < housing_median_age <= 0.55', 'total_rooms > 0.08', 'median_income > 0.29', 'population > 0.06', 'longitude <= 0.25', 'households > 0.10', '0.18 < latitude <= 0.55', 'total_bedrooms > 0.10']\n","    vals.reverse()\n","    names.reverse()\n","    print('names ', names)\n","    colors = ['C1' if x > 0 else 'C0' for x in vals] # originally negative=red and positive=green (coloring scheme)\n","    colors_set = set(colors)\n","    print('colors_set before ', colors_set)\n","    colors_set = ['positive' if c == 'C1' else 'negative' for c in colors_set]\n","    print('colors_set after ', colors_set)\n","    pos_o = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5]\n","    pos = [i + .5 for i in pos_o]\n","    print('pos values for plot are ', pos)\n","    print('vals ', vals)\n","    vals_str = [str(round(val, 3)) for val in vals]\n","    print('vals_str ', vals_str)\n","\n","    plt.figure(figsize=(15, 10))\n","    #plt.barh(pos, vals, color=colors) #this code works well but does not have legend or text in int\n","\n","    for i, v in enumerate(vals):\n","        plt.text(v, i+1, str(v), Bbox = dict(facecolor = 'grey', alpha =.8))\n","    axx = plt.barh([i for i in pos], vals, align='center', color=colors) # this code appropriate legend\n","    plt.grid()\n","    plt.yticks(pos, names)\n","\n","    labels = colors_set \n","    print(labels)     \n","    print(colors)\n","    legend_colors = list(set(colors))\n","    print(set(colors) )\n","    handles = [plt.Rectangle((0,0),1,1, color=legend_colors[label]) for label in range(len(labels))]\n","    print(handles)\n","    plt.legend(handles, labels)\n","    plt.show()\n"," '''"],"metadata":{"id":"YNHDY_QcDZ2W","executionInfo":{"status":"ok","timestamp":1645805249916,"user_tz":-60,"elapsed":28,"user":{"displayName":"Mihir Mulye","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjt-UFuHMJLt42FC-zaYNS5lke3QC-GYFy34wxbQw=s64","userId":"03370256418408681216"}},"colab":{"base_uri":"https://localhost:8080/","height":239},"outputId":"11d7b64e-e4fd-4fda-ee1d-f7a9d21b2ea3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\n\\n# TESTBED FOR HISTOGRAM DETAILING\\nimport random \\nimport matplotlib.pyplot as plt\\n\\ncont = 1\\n\\nfor i in range(cont):\\n    \\n    #exp = self.as_list(label=label, **kwargs)\\n    fig = plt.figure(figsize=(15, 5))\\n    #vals = [-0.0015642910097497709, -0.006193702109735619, 0.007176534335879772, \\n    #        -0.0075631914531472675, -0.011606796695305309, 0.013962026656112023, \\n    #        -0.017696851420039194, -0.0246349957951464]\\n    vals = [random.randrange(-50, 50, 8) for i in range(8)]\\n    print(vals)\\n    names = ['0.33 < housing_median_age <= 0.55', 'total_rooms > 0.08', 'median_income > 0.29', 'population > 0.06', 'longitude <= 0.25', 'households > 0.10', '0.18 < latitude <= 0.55', 'total_bedrooms > 0.10']\\n    vals.reverse()\\n    names.reverse()\\n    print('names ', names)\\n    colors = ['C1' if x > 0 else 'C0' for x in vals] # originally negative=red and positive=green (coloring scheme)\\n    colors_set = set(colors)\\n    print('colors_set before ', colors_set)\\n    colors_set = ['positive' if c == 'C1' else 'negative' for c in colors_set]\\n    print('colors_set after ', colors_set)\\n    pos_o = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5]\\n    pos = [i + .5 for i in pos_o]\\n    print('pos values for plot are ', pos)\\n    print('vals ', vals)\\n    vals_str = [str(round(val, 3)) for val in vals]\\n    print('vals_str ', vals_str)\\n\\n    plt.figure(figsize=(15, 10))\\n    #plt.barh(pos, vals, color=colors) #this code works well but does not have legend or text in int\\n\\n    for i, v in enumerate(vals):\\n        plt.text(v, i+1, str(v), Bbox = dict(facecolor = 'grey', alpha =.8))\\n    axx = plt.barh([i for i in pos], vals, align='center', color=colors) # this code appropriate legend\\n    plt.grid()\\n    plt.yticks(pos, names)\\n\\n    labels = colors_set \\n    print(labels)     \\n    print(colors)\\n    legend_colors = list(set(colors))\\n    print(set(colors) )\\n    handles = [plt.Rectangle((0,0),1,1, color=legend_colors[label]) for label in range(len(labels))]\\n    print(handles)\\n    plt.legend(handles, labels)\\n    plt.show()\\n \""]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":[""],"metadata":{"id":"PMOlr3ypovrS"},"execution_count":null,"outputs":[]}]}